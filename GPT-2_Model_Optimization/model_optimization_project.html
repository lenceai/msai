<!DOCTYPE html>

<html lang="en">
<head><meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>model_optimization_project</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<style type="text/css">
    pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .pm { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation.Marker */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/* tiny scrollbar */

.jp-scrollbar-tiny {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
  scrollbar-width: thin;
}

/* tiny scrollbar */

.jp-scrollbar-tiny::-webkit-scrollbar,
.jp-scrollbar-tiny::-webkit-scrollbar-corner {
  background-color: transparent;
  height: 4px;
  width: 4px;
}

.jp-scrollbar-tiny::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:horizontal {
  border-left: 0 solid transparent;
  border-right: 0 solid transparent;
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:vertical {
  border-top: 0 solid transparent;
  border-bottom: 0 solid transparent;
}

/*
 * Lumino
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
}

.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.lm-AccordionPanel[data-orientation='horizontal'] > .lm-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-CommandPalette-search {
  flex: 0 0 auto;
}

.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}

.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}

.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}

.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-close-icon {
  border: 1px solid transparent;
  background-color: transparent;
  position: absolute;
  z-index: 1;
  right: 3%;
  top: 0;
  bottom: 0;
  margin: auto;
  padding: 7px 0;
  display: none;
  vertical-align: middle;
  outline: 0;
  cursor: pointer;
}
.lm-close-icon:after {
  content: 'X';
  display: block;
  width: 15px;
  height: 15px;
  text-align: center;
  color: #000;
  font-weight: normal;
  font-size: 12px;
  cursor: pointer;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-DockPanel {
  z-index: 0;
}

.lm-DockPanel-widget {
  z-index: 0;
}

.lm-DockPanel-tabBar {
  z-index: 1;
}

.lm-DockPanel-handle {
  z-index: 2;
}

.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}

.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}

.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}

.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}

.lm-Menu-item {
  display: table-row;
}

.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}

.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}

.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}

.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}

.lm-MenuBar-item {
  box-sizing: border-box;
}

.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}

.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}

.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}

.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}

.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-SplitPanel-child {
  z-index: 0;
}

.lm-SplitPanel-handle {
  z-index: 1;
}

.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
  align-items: flex-end;
}

.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
  align-items: flex-end;
}

.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}

.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}

.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}

.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
  touch-action: none; /* Disable native Drag/Drop */
}

.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}

.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}

.lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
}

.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar-addButton.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}

.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}

.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

.lm-TabBar-tabLabel .lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
  background: inherit;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabPanel-tabBar {
  z-index: 1;
}

.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
}

.jp-Collapse-header {
  padding: 1px 12px;
  background-color: var(--jp-layout-color1);
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  align-items: center;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  text-transform: uppercase;
  user-select: none;
}

.jp-Collapser-icon {
  height: 16px;
}

.jp-Collapse-header-collapsed .jp-Collapser-icon {
  transform: rotate(-90deg);
  margin: auto 0;
}

.jp-Collapser-title {
  line-height: 25px;
}

.jp-Collapse-contents {
  padding: 0 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add-above: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5MikiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik00Ljc1IDQuOTMwNjZINi42MjVWNi44MDU2NkM2LjYyNSA3LjAxMTkxIDYuNzkzNzUgNy4xODA2NiA3IDcuMTgwNjZDNy4yMDYyNSA3LjE4MDY2IDcuMzc1IDcuMDExOTEgNy4zNzUgNi44MDU2NlY0LjkzMDY2SDkuMjVDOS40NTYyNSA0LjkzMDY2IDkuNjI1IDQuNzYxOTEgOS42MjUgNC41NTU2NkM5LjYyNSA0LjM0OTQxIDkuNDU2MjUgNC4xODA2NiA5LjI1IDQuMTgwNjZINy4zNzVWMi4zMDU2NkM3LjM3NSAyLjA5OTQxIDcuMjA2MjUgMS45MzA2NiA3IDEuOTMwNjZDNi43OTM3NSAxLjkzMDY2IDYuNjI1IDIuMDk5NDEgNi42MjUgMi4zMDU2NlY0LjE4MDY2SDQuNzVDNC41NDM3NSA0LjE4MDY2IDQuMzc1IDQuMzQ5NDEgNC4zNzUgNC41NTU2NkM0LjM3NSA0Ljc2MTkxIDQuNTQzNzUgNC45MzA2NiA0Ljc1IDQuOTMwNjZaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC43Ii8+CjwvZz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTExLjUgOS41VjExLjVMMi41IDExLjVWOS41TDExLjUgOS41Wk0xMiA4QzEyLjU1MjMgOCAxMyA4LjQ0NzcyIDEzIDlWMTJDMTMgMTIuNTUyMyAxMi41NTIzIDEzIDEyIDEzTDIgMTNDMS40NDc3MiAxMyAxIDEyLjU1MjMgMSAxMlY5QzEgOC40NDc3MiAxLjQ0NzcxIDggMiA4TDEyIDhaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5MiI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KC0xIDAgMCAxIDEwIDEuNTU1NjYpIi8+CjwvY2xpcFBhdGg+CjwvZGVmcz4KPC9zdmc+Cg==);
  --jp-icon-add-below: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5OCkiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik05LjI1IDEwLjA2OTNMNy4zNzUgMTAuMDY5M0w3LjM3NSA4LjE5NDM0QzcuMzc1IDcuOTg4MDkgNy4yMDYyNSA3LjgxOTM0IDcgNy44MTkzNEM2Ljc5Mzc1IDcuODE5MzQgNi42MjUgNy45ODgwOSA2LjYyNSA4LjE5NDM0TDYuNjI1IDEwLjA2OTNMNC43NSAxMC4wNjkzQzQuNTQzNzUgMTAuMDY5MyA0LjM3NSAxMC4yMzgxIDQuMzc1IDEwLjQ0NDNDNC4zNzUgMTAuNjUwNiA0LjU0Mzc1IDEwLjgxOTMgNC43NSAxMC44MTkzTDYuNjI1IDEwLjgxOTNMNi42MjUgMTIuNjk0M0M2LjYyNSAxMi45MDA2IDYuNzkzNzUgMTMuMDY5MyA3IDEzLjA2OTNDNy4yMDYyNSAxMy4wNjkzIDcuMzc1IDEyLjkwMDYgNy4zNzUgMTIuNjk0M0w3LjM3NSAxMC44MTkzTDkuMjUgMTAuODE5M0M5LjQ1NjI1IDEwLjgxOTMgOS42MjUgMTAuNjUwNiA5LjYyNSAxMC40NDQzQzkuNjI1IDEwLjIzODEgOS40NTYyNSAxMC4wNjkzIDkuMjUgMTAuMDY5M1oiIGZpbGw9IiM2MTYxNjEiIHN0cm9rZT0iIzYxNjE2MSIgc3Ryb2tlLXdpZHRoPSIwLjciLz4KPC9nPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMi41IDUuNUwyLjUgMy41TDExLjUgMy41TDExLjUgNS41TDIuNSA1LjVaTTIgN0MxLjQ0NzcyIDcgMSA2LjU1MjI4IDEgNkwxIDNDMSAyLjQ0NzcyIDEuNDQ3NzIgMiAyIDJMMTIgMkMxMi41NTIzIDIgMTMgMi40NDc3MiAxMyAzTDEzIDZDMTMgNi41NTIyOSAxMi41NTIzIDcgMTIgN0wyIDdaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5OCI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KDEgMS43NDg0NmUtMDcgMS43NDg0NmUtMDcgLTEgNCAxMy40NDQzKSIvPgo8L2NsaXBQYXRoPgo8L2RlZnM+Cjwvc3ZnPgo=);
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bell: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE2IDE2IiB2ZXJzaW9uPSIxLjEiPgogICA8cGF0aCBjbGFzcz0ianAtaWNvbjIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMzMzMzMzIgogICAgICBkPSJtOCAwLjI5Yy0xLjQgMC0yLjcgMC43My0zLjYgMS44LTEuMiAxLjUtMS40IDMuNC0xLjUgNS4yLTAuMTggMi4yLTAuNDQgNC0yLjMgNS4zbDAuMjggMS4zaDVjMC4wMjYgMC42NiAwLjMyIDEuMSAwLjcxIDEuNSAwLjg0IDAuNjEgMiAwLjYxIDIuOCAwIDAuNTItMC40IDAuNi0xIDAuNzEtMS41aDVsMC4yOC0xLjNjLTEuOS0wLjk3LTIuMi0zLjMtMi4zLTUuMy0wLjEzLTEuOC0wLjI2LTMuNy0xLjUtNS4yLTAuODUtMS0yLjItMS44LTMuNi0xLjh6bTAgMS40YzAuODggMCAxLjkgMC41NSAyLjUgMS4zIDAuODggMS4xIDEuMSAyLjcgMS4yIDQuNCAwLjEzIDEuNyAwLjIzIDMuNiAxLjMgNS4yaC0xMGMxLjEtMS42IDEuMi0zLjQgMS4zLTUuMiAwLjEzLTEuNyAwLjMtMy4zIDEuMi00LjQgMC41OS0wLjcyIDEuNi0xLjMgMi41LTEuM3ptLTAuNzQgMTJoMS41Yy0wLjAwMTUgMC4yOCAwLjAxNSAwLjc5LTAuNzQgMC43OS0wLjczIDAuMDAxNi0wLjcyLTAuNTMtMC43NC0wLjc5eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-bug-dot: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiPgogICAgICAgIDxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMTcuMTkgOEgyMFYxMEgxNy45MUMxNy45NiAxMC4zMyAxOCAxMC42NiAxOCAxMVYxMkgyMFYxNEgxOC41SDE4VjE0LjAyNzVDMTUuNzUgMTQuMjc2MiAxNCAxNi4xODM3IDE0IDE4LjVDMTQgMTkuMjA4IDE0LjE2MzUgMTkuODc3OSAxNC40NTQ5IDIwLjQ3MzlDMTMuNzA2MyAyMC44MTE3IDEyLjg3NTcgMjEgMTIgMjFDOS43OCAyMSA3Ljg1IDE5Ljc5IDYuODEgMThINFYxNkg2LjA5QzYuMDQgMTUuNjcgNiAxNS4zNCA2IDE1VjE0SDRWMTJINlYxMUM2IDEwLjY2IDYuMDQgMTAuMzMgNi4wOSAxMEg0VjhINi44MUM3LjI2IDcuMjIgNy44OCA2LjU1IDguNjIgNi4wNEw3IDQuNDFMOC40MSAzTDEwLjU5IDUuMTdDMTEuMDQgNS4wNiAxMS41MSA1IDEyIDVDMTIuNDkgNSAxMi45NiA1LjA2IDEzLjQyIDUuMTdMMTUuNTkgM0wxNyA0LjQxTDE1LjM3IDYuMDRDMTYuMTIgNi41NSAxNi43NCA3LjIyIDE3LjE5IDhaTTEwIDE2SDE0VjE0SDEwVjE2Wk0xMCAxMkgxNFYxMEgxMFYxMloiIGZpbGw9IiM2MTYxNjEiLz4KICAgICAgICA8cGF0aCBkPSJNMjIgMTguNUMyMiAyMC40MzMgMjAuNDMzIDIyIDE4LjUgMjJDMTYuNTY3IDIyIDE1IDIwLjQzMyAxNSAxOC41QzE1IDE2LjU2NyAxNi41NjcgMTUgMTguNSAxNUMyMC40MzMgMTUgMjIgMTYuNTY3IDIyIDE4LjVaIiBmaWxsPSIjNjE2MTYxIi8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yMCA4aC0yLjgxYy0uNDUtLjc4LTEuMDctMS40NS0xLjgyLTEuOTZMMTcgNC40MSAxNS41OSAzbC0yLjE3IDIuMTdDMTIuOTYgNS4wNiAxMi40OSA1IDEyIDVjLS40OSAwLS45Ni4wNi0xLjQxLjE3TDguNDEgMyA3IDQuNDFsMS42MiAxLjYzQzcuODggNi41NSA3LjI2IDcuMjIgNi44MSA4SDR2MmgyLjA5Yy0uMDUuMzMtLjA5LjY2LS4wOSAxdjFINHYyaDJ2MWMwIC4zNC4wNC42Ny4wOSAxSDR2MmgyLjgxYzEuMDQgMS43OSAyLjk3IDMgNS4xOSAzczQuMTUtMS4yMSA1LjE5LTNIMjB2LTJoLTIuMDljLjA1LS4zMy4wOS0uNjYuMDktMXYtMWgydi0yaC0ydi0xYzAtLjM0LS4wNC0uNjctLjA5LTFIMjBWOHptLTYgOGgtNHYtMmg0djJ6bTAtNGgtNHYtMmg0djJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-build: url(data:image/svg+xml;base64,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);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik05IDE2LjE3TDQuODMgMTJsLTEuNDIgMS40MUw5IDE5IDIxIDdsLTEuNDEtMS40MXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBzaGFwZS1yZW5kZXJpbmc9Imdlb21ldHJpY1ByZWNpc2lvbiI+CiAgICA8cGF0aCBkPSJNNi41OSwzLjQxTDIsOEw2LjU5LDEyLjZMOCwxMS4xOEw0LjgyLDhMOCw0LjgyTDYuNTksMy40MU0xMi40MSwzLjQxTDExLDQuODJMMTQuMTgsOEwxMSwxMS4xOEwxMi40MSwxMi42TDE3LDhMMTIuNDEsMy40MU0yMS41OSwxMS41OUwxMy41LDE5LjY4TDkuODMsMTZMOC40MiwxNy40MUwxMy41LDIyLjVMMjMsMTNMMjEuNTksMTEuNTlaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTExLjQgMTguNkw2LjggMTRMMTEuNCA5LjRMMTAgOEw0IDE0TDEwIDIwTDExLjQgMTguNlpNMTYuNiAxOC42TDIxLjIgMTRMMTYuNiA5LjRMMTggOEwyNCAxNEwxOCAyMEwxNi42IDE4LjZWMTguNloiLz4KCTwvZz4KPC9zdmc+Cg==);
  --jp-icon-collapse-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNNiAxM3YyaDh2LTJ6IiAvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1jb25zb2xlLWljb24tYmFja2dyb3VuZC1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtY29uc29sZS1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIj4KICAgIDxwYXRoIGQ9Ik0xMDUgMTI3LjNoNDB2MTIuOGgtNDB6TTUxLjEgNzdMNzQgOTkuOWwtMjMuMyAyMy4zIDEwLjUgMTAuNSAyMy4zLTIzLjNMOTUgOTkuOSA4NC41IDg5LjQgNjEuNiA2Ni41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copyright: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+CiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0xMS44OCw5LjE0YzEuMjgsMC4wNiwxLjYxLDEuMTUsMS42MywxLjY2aDEuNzljLTAuMDgtMS45OC0xLjQ5LTMuMTktMy40NS0zLjE5QzkuNjQsNy42MSw4LDksOCwxMi4xNCBjMCwxLjk0LDAuOTMsNC4yNCwzLjg0LDQuMjRjMi4yMiwwLDMuNDEtMS42NSwzLjQ0LTIuOTVoLTEuNzljLTAuMDMsMC41OS0wLjQ1LDEuMzgtMS42MywxLjQ0QzEwLjU1LDE0LjgzLDEwLDEzLjgxLDEwLDEyLjE0IEMxMCw5LjI1LDExLjI4LDkuMTYsMTEuODgsOS4xNHogTTEyLDJDNi40OCwyLDIsNi40OCwyLDEyczQuNDgsMTAsMTAsMTBzMTAtNC40OCwxMC0xMFMxNy41MiwyLDEyLDJ6IE0xMiwyMGMtNC40MSwwLTgtMy41OS04LTggczMuNTktOCw4LThzOCwzLjU5LDgsOFMxNi40MSwyMCwxMiwyMHoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-delete: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2cHgiIGhlaWdodD0iMTZweCI+CiAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIiAvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjI2MjYyIiBkPSJNNiAxOWMwIDEuMS45IDIgMiAyaDhjMS4xIDAgMi0uOSAyLTJWN0g2djEyek0xOSA0aC0zLjVsLTEtMWgtNWwtMSAxSDV2MmgxNFY0eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-duplicate: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTIuNzk5OTggMC44NzVIOC44OTU4MkM5LjIwMDYxIDAuODc1IDkuNDQ5OTggMS4xMzkxNCA5LjQ0OTk4IDEuNDYxOThDOS40NDk5OCAxLjc4NDgyIDkuMjAwNjEgMi4wNDg5NiA4Ljg5NTgyIDIuMDQ4OTZIMy4zNTQxNUMzLjA0OTM2IDIuMDQ4OTYgMi43OTk5OCAyLjMxMzEgMi43OTk5OCAyLjYzNTk0VjkuNjc5NjlDMi43OTk5OCAxMC4wMDI1IDIuNTUwNjEgMTAuMjY2NyAyLjI0NTgyIDEwLjI2NjdDMS45NDEwMyAxMC4yNjY3IDEuNjkxNjUgMTAuMDAyNSAxLjY5MTY1IDkuNjc5NjlWMi4wNDg5NkMxLjY5MTY1IDEuNDAzMjggMi4xOTA0IDAuODc1IDIuNzk5OTggMC44NzVaTTUuMzY2NjUgMTEuOVY0LjU1SDExLjA4MzNWMTEuOUg1LjM2NjY1Wk00LjE0MTY1IDQuMTQxNjdDNC4xNDE2NSAzLjY5MDYzIDQuNTA3MjggMy4zMjUgNC45NTgzMiAzLjMyNUgxMS40OTE3QzExLjk0MjcgMy4zMjUgMTIuMzA4MyAzLjY5MDYzIDEyLjMwODMgNC4xNDE2N1YxMi4zMDgzQzEyLjMwODMgMTIuNzU5NCAxMS45NDI3IDEzLjEyNSAxMS40OTE3IDEzLjEyNUg0Ljk1ODMyQzQuNTA3MjggMTMuMTI1IDQuMTQxNjUgMTIuNzU5NCA0LjE0MTY1IDEyLjMwODNWNC4xNDE2N1oiIGZpbGw9IiM2MTYxNjEiLz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNOS40MzU3NCA4LjI2NTA3SDguMzY0MzFWOS4zMzY1QzguMzY0MzEgOS40NTQzNSA4LjI2Nzg4IDkuNTUwNzggOC4xNTAwMiA5LjU1MDc4QzguMDMyMTcgOS41NTA3OCA3LjkzNTc0IDkuNDU0MzUgNy45MzU3NCA5LjMzNjVWOC4yNjUwN0g2Ljg2NDMxQzYuNzQ2NDUgOC4yNjUwNyA2LjY1MDAyIDguMTY4NjQgNi42NTAwMiA4LjA1MDc4QzYuNjUwMDIgNy45MzI5MiA2Ljc0NjQ1IDcuODM2NSA2Ljg2NDMxIDcuODM2NUg3LjkzNTc0VjYuNzY1MDdDNy45MzU3NCA2LjY0NzIxIDguMDMyMTcgNi41NTA3OCA4LjE1MDAyIDYuNTUwNzhDOC4yNjc4OCA2LjU1MDc4IDguMzY0MzEgNi42NDcyMSA4LjM2NDMxIDYuNzY1MDdWNy44MzY1SDkuNDM1NzRDOS41NTM2IDcuODM2NSA5LjY1MDAyIDcuOTMyOTIgOS42NTAwMiA4LjA1MDc4QzkuNjUwMDIgOC4xNjg2NCA5LjU1MzYgOC4yNjUwNyA5LjQzNTc0IDguMjY1MDdaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC41Ii8+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-error: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj48Y2lyY2xlIGN4PSIxMiIgY3k9IjE5IiByPSIyIi8+PHBhdGggZD0iTTEwIDNoNHYxMmgtNHoiLz48L2c+CjxwYXRoIGZpbGw9Im5vbmUiIGQ9Ik0wIDBoMjR2MjRIMHoiLz4KPC9zdmc+Cg==);
  --jp-icon-expand-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNMTEgMTBIOXYzSDZ2MmgzdjNoMnYtM2gzdi0yaC0zeiIgLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-dot: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWRvdCIgZmlsbD0iI0ZGRiI+CiAgICA8Y2lyY2xlIGN4PSIxOCIgY3k9IjE3IiByPSIzIj48L2NpcmNsZT4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-filter: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-folder-favorite: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgwVjB6IiBmaWxsPSJub25lIi8+PHBhdGggY2xhc3M9ImpwLWljb24zIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzYxNjE2MSIgZD0iTTIwIDZoLThsLTItMkg0Yy0xLjEgMC0yIC45LTIgMnYxMmMwIDEuMS45IDIgMiAyaDE2YzEuMSAwIDItLjkgMi0yVjhjMC0xLjEtLjktMi0yLTJ6bS0yLjA2IDExTDE1IDE1LjI4IDEyLjA2IDE3bC43OC0zLjMzLTIuNTktMi4yNCAzLjQxLS4yOUwxNSA4bDEuMzQgMy4xNCAzLjQxLjI5LTIuNTkgMi4yNC43OCAzLjMzeiIvPgo8L3N2Zz4K);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-home: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPjxwYXRoIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xMCAyMHYtNmg0djZoNXYtOGgzTDEyIDMgMiAxMmgzdjh6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-info: url(data:image/svg+xml;base64,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);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaW5zcGVjdG9yLWljb24tY29sb3IganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtanNvbi1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0Y5QTgyNSI+CiAgICA8cGF0aCBkPSJNMjAuMiAxMS44Yy0xLjYgMC0xLjcuNS0xLjcgMSAwIC40LjEuOS4xIDEuMy4xLjUuMS45LjEgMS4zIDAgMS43LTEuNCAyLjMtMy41IDIuM2gtLjl2LTEuOWguNWMxLjEgMCAxLjQgMCAxLjQtLjggMC0uMyAwLS42LS4xLTEgMC0uNC0uMS0uOC0uMS0xLjIgMC0xLjMgMC0xLjggMS4zLTItMS4zLS4yLTEuMy0uNy0xLjMtMiAwLS40LjEtLjguMS0xLjIuMS0uNC4xLS43LjEtMSAwLS44LS40LS43LTEuNC0uOGgtLjVWNC4xaC45YzIuMiAwIDMuNS43IDMuNSAyLjMgMCAuNC0uMS45LS4xIDEuMy0uMS41LS4xLjktLjEgMS4zIDAgLjUuMiAxIDEuNyAxdjEuOHpNMS44IDEwLjFjMS42IDAgMS43LS41IDEuNy0xIDAtLjQtLjEtLjktLjEtMS4zLS4xLS41LS4xLS45LS4xLTEuMyAwLTEuNiAxLjQtMi4zIDMuNS0yLjNoLjl2MS45aC0uNWMtMSAwLTEuNCAwLTEuNC44IDAgLjMgMCAuNi4xIDEgMCAuMi4xLjYuMSAxIDAgMS4zIDAgMS44LTEuMyAyQzYgMTEuMiA2IDExLjcgNiAxM2MwIC40LS4xLjgtLjEgMS4yLS4xLjMtLjEuNy0uMSAxIDAgLjguMy44IDEuNC44aC41djEuOWgtLjljLTIuMSAwLTMuNS0uNi0zLjUtMi4zIDAtLjQuMS0uOS4xLTEuMy4xLS41LjEtLjkuMS0xLjMgMC0uNS0uMi0xLTEuNy0xdi0xLjl6Ii8+CiAgICA8Y2lyY2xlIGN4PSIxMSIgY3k9IjEzLjgiIHI9IjIuMSIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSI4LjIiIHI9IjIuMSIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-julia: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDMyNSAzMDAiPgogIDxnIGNsYXNzPSJqcC1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjY2IzYzMzIj4KICAgIDxwYXRoIGQ9Ik0gMTUwLjg5ODQzOCAyMjUgQyAxNTAuODk4NDM4IDI2Ni40MjE4NzUgMTE3LjMyMDMxMiAzMDAgNzUuODk4NDM4IDMwMCBDIDM0LjQ3NjU2MiAzMDAgMC44OTg0MzggMjY2LjQyMTg3NSAwLjg5ODQzOCAyMjUgQyAwLjg5ODQzOCAxODMuNTc4MTI1IDM0LjQ3NjU2MiAxNTAgNzUuODk4NDM4IDE1MCBDIDExNy4zMjAzMTIgMTUwIDE1MC44OTg0MzggMTgzLjU3ODEyNSAxNTAuODk4NDM4IDIyNSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzM4OTgyNiI+CiAgICA8cGF0aCBkPSJNIDIzNy41IDc1IEMgMjM3LjUgMTE2LjQyMTg3NSAyMDMuOTIxODc1IDE1MCAxNjIuNSAxNTAgQyAxMjEuMDc4MTI1IDE1MCA4Ny41IDExNi40MjE4NzUgODcuNSA3NSBDIDg3LjUgMzMuNTc4MTI1IDEyMS4wNzgxMjUgMCAxNjIuNSAwIEMgMjAzLjkyMTg3NSAwIDIzNy41IDMzLjU3ODEyNSAyMzcuNSA3NSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzk1NThiMiI+CiAgICA8cGF0aCBkPSJNIDMyNC4xMDE1NjIgMjI1IEMgMzI0LjEwMTU2MiAyNjYuNDIxODc1IDI5MC41MjM0MzggMzAwIDI0OS4xMDE1NjIgMzAwIEMgMjA3LjY3OTY4OCAzMDAgMTc0LjEwMTU2MiAyNjYuNDIxODc1IDE3NC4xMDE1NjIgMjI1IEMgMTc0LjEwMTU2MiAxODMuNTc4MTI1IDIwNy42Nzk2ODggMTUwIDI0OS4xMDE1NjIgMTUwIEMgMjkwLjUyMzQzOCAxNTAgMzI0LjEwMTU2MiAxODMuNTc4MTI1IDMyNC4xMDE1NjIgMjI1Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgPGcgY2xhc3M9ImpwLWp1cHl0ZXItaWNvbi1jb2xvciIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,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);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launch: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMzIgMzIiIHdpZHRoPSIzMiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yNiwyOEg2YTIuMDAyNywyLjAwMjcsMCwwLDEtMi0yVjZBMi4wMDI3LDIuMDAyNywwLDAsMSw2LDRIMTZWNkg2VjI2SDI2VjE2aDJWMjZBMi4wMDI3LDIuMDAyNywwLDAsMSwyNiwyOFoiLz4KICAgIDxwb2x5Z29uIHBvaW50cz0iMjAgMiAyMCA0IDI2LjU4NiA0IDE4IDEyLjU4NiAxOS40MTQgMTQgMjggNS40MTQgMjggMTIgMzAgMTIgMzAgMiAyMCAyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4K);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-move-down: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMTIuNDcxIDcuNTI4OTlDMTIuNzYzMiA3LjIzNjg0IDEyLjc2MzIgNi43NjMxNiAxMi40NzEgNi40NzEwMVY2LjQ3MTAxQzEyLjE3OSA2LjE3OTA1IDExLjcwNTcgNi4xNzg4NCAxMS40MTM1IDYuNDcwNTRMNy43NSAxMC4xMjc1VjEuNzVDNy43NSAxLjMzNTc5IDcuNDE0MjEgMSA3IDFWMUM2LjU4NTc5IDEgNi4yNSAxLjMzNTc5IDYuMjUgMS43NVYxMC4xMjc1TDIuNTk3MjYgNi40NjgyMkMyLjMwMzM4IDYuMTczODEgMS44MjY0MSA2LjE3MzU5IDEuNTMyMjYgNi40Njc3NFY2LjQ2Nzc0QzEuMjM4MyA2Ljc2MTcgMS4yMzgzIDcuMjM4MyAxLjUzMjI2IDcuNTMyMjZMNi4yOTI4OSAxMi4yOTI5QzYuNjgzNDIgMTIuNjgzNCA3LjMxNjU4IDEyLjY4MzQgNy43MDcxMSAxMi4yOTI5TDEyLjQ3MSA3LjUyODk5WiIgZmlsbD0iIzYxNjE2MSIvPgo8L3N2Zz4K);
  --jp-icon-move-up: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMS41Mjg5OSA2LjQ3MTAxQzEuMjM2ODQgNi43NjMxNiAxLjIzNjg0IDcuMjM2ODQgMS41Mjg5OSA3LjUyODk5VjcuNTI4OTlDMS44MjA5NSA3LjgyMDk1IDIuMjk0MjYgNy44MjExNiAyLjU4NjQ5IDcuNTI5NDZMNi4yNSAzLjg3MjVWMTIuMjVDNi4yNSAxMi42NjQyIDYuNTg1NzkgMTMgNyAxM1YxM0M3LjQxNDIxIDEzIDcuNzUgMTIuNjY0MiA3Ljc1IDEyLjI1VjMuODcyNUwxMS40MDI3IDcuNTMxNzhDMTEuNjk2NiA3LjgyNjE5IDEyLjE3MzYgNy44MjY0MSAxMi40Njc3IDcuNTMyMjZWNy41MzIyNkMxMi43NjE3IDcuMjM4MyAxMi43NjE3IDYuNzYxNyAxMi40Njc3IDYuNDY3NzRMNy43MDcxMSAxLjcwNzExQzcuMzE2NTggMS4zMTY1OCA2LjY4MzQyIDEuMzE2NTggNi4yOTI4OSAxLjcwNzExTDEuNTI4OTkgNi40NzEwMVoiIGZpbGw9IiM2MTYxNjEiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtbm90ZWJvb2staWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-numbering: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTQgMTlINlYxOS41SDVWMjAuNUg2VjIxSDRWMjJIN1YxOEg0VjE5Wk01IDEwSDZWNkg0VjdINVYxMFpNNCAxM0g1LjhMNCAxNS4xVjE2SDdWMTVINS4yTDcgMTIuOVYxMkg0VjEzWk05IDdWOUgyM1Y3SDlaTTkgMjFIMjNWMTlIOVYyMVpNOSAxNUgyM1YxM0g5VjE1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-offline-bolt: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDIuMDJjLTUuNTEgMC05Ljk4IDQuNDctOS45OCA5Ljk4czQuNDcgOS45OCA5Ljk4IDkuOTggOS45OC00LjQ3IDkuOTgtOS45OFMxNy41MSAyLjAyIDEyIDIuMDJ6TTExLjQ4IDIwdi02LjI2SDhMMTMgNHY2LjI2aDMuMzVMMTEuNDggMjB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-pdf: url(data:image/svg+xml;base64,PHN2ZwogICB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMiAyMiIgd2lkdGg9IjE2Ij4KICAgIDxwYXRoIHRyYW5zZm9ybT0icm90YXRlKDQ1KSIgY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0ZGMkEyQSIKICAgICAgIGQ9Im0gMjIuMzQ0MzY5LC0zLjAxNjM2NDIgaCA1LjYzODYwNCB2IDEuNTc5MjQzMyBoIC0zLjU0OTIyNyB2IDEuNTA4NjkyOTkgaCAzLjMzNzU3NiBWIDEuNjUwODE1NCBoIC0zLjMzNzU3NiB2IDMuNDM1MjYxMyBoIC0yLjA4OTM3NyB6IG0gLTcuMTM2NDQ0LDEuNTc5MjQzMyB2IDQuOTQzOTU0MyBoIDAuNzQ4OTIgcSAxLjI4MDc2MSwwIDEuOTUzNzAzLC0wLjYzNDk1MzUgMC42NzgzNjksLTAuNjM0OTUzNSAwLjY3ODM2OSwtMS44NDUxNjQxIDAsLTEuMjA0NzgzNTUgLTAuNjcyOTQyLC0xLjgzNDMxMDExIC0wLjY3Mjk0MiwtMC42Mjk1MjY1OSAtMS45NTkxMywtMC42Mjk1MjY1OSB6IG0gLTIuMDg5Mzc3LC0xLjU3OTI0MzMgaCAyLjIwMzM0MyBxIDEuODQ1MTY0LDAgMi43NDYwMzksMC4yNjU5MjA3IDAuOTA2MzAxLDAuMjYwNDkzNyAxLjU1MjEwOCwwLjg5MDAyMDMgMC41Njk4MywwLjU0ODEyMjMgMC44NDY2MDUsMS4yNjQ0ODAwNiAwLjI3Njc3NCwwLjcxNjM1NzgxIDAuMjc2Nzc0LDEuNjIyNjU4OTQgMCwwLjkxNzE1NTEgLTAuMjc2Nzc0LDEuNjM4OTM5OSAtMC4yNzY3NzUsMC43MTYzNTc4IC0wLjg0NjYwNSwxLjI2NDQ4IC0wLjY1MTIzNCwwLjYyOTUyNjYgLTEuNTYyOTYyLDAuODk1NDQ3MyAtMC45MTE3MjgsMC4yNjA0OTM3IC0yLjczNTE4NSwwLjI2MDQ5MzcgaCAtMi4yMDMzNDMgeiBtIC04LjE0NTg1NjUsMCBoIDMuNDY3ODIzIHEgMS41NDY2ODE2LDAgMi4zNzE1Nzg1LDAuNjg5MjIzIDAuODMwMzI0LDAuNjgzNzk2MSAwLjgzMDMyNCwxLjk1MzcwMzE0IDAsMS4yNzUzMzM5NyAtMC44MzAzMjQsMS45NjQ1NTcwNiBRIDkuOTg3MTk2MSwyLjI3NDkxNSA4LjQ0MDUxNDUsMi4yNzQ5MTUgSCA3LjA2MjA2ODQgViA1LjA4NjA3NjcgSCA0Ljk3MjY5MTUgWiBtIDIuMDg5Mzc2OSwxLjUxNDExOTkgdiAyLjI2MzAzOTQzIGggMS4xNTU5NDEgcSAwLjYwNzgxODgsMCAwLjkzODg2MjksLTAuMjkzMDU1NDcgMC4zMzEwNDQxLC0wLjI5ODQ4MjQxIDAuMzMxMDQ0MSwtMC44NDExNzc3MiAwLC0wLjU0MjY5NTMxIC0wLjMzMTA0NDEsLTAuODM1NzUwNzQgLTAuMzMxMDQ0MSwtMC4yOTMwNTU1IC0wLjkzODg2MjksLTAuMjkzMDU1NSB6IgovPgo8L3N2Zz4K);
  --jp-icon-python: url(data:image/svg+xml;base64,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);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-redo: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZD0iTTE4LjQgMTAuNkMxNi41NSA4Ljk5IDE0LjE1IDggMTEuNSA4Yy00LjY1IDAtOC41OCAzLjAzLTkuOTYgNy4yMkwzLjkgMTZjMS4wNS0zLjE5IDQuMDUtNS41IDcuNi01LjUgMS45NSAwIDMuNzMuNzIgNS4xMiAxLjg4TDEzIDE2aDlWN2wtMy42IDMuNnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-share: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTSAxOCAyIEMgMTYuMzU0OTkgMiAxNSAzLjM1NDk5MDQgMTUgNSBDIDE1IDUuMTkwOTUyOSAxNS4wMjE3OTEgNS4zNzcxMjI0IDE1LjA1NjY0MSA1LjU1ODU5MzggTCA3LjkyMTg3NSA5LjcyMDcwMzEgQyA3LjM5ODUzOTkgOS4yNzc4NTM5IDYuNzMyMDc3MSA5IDYgOSBDIDQuMzU0OTkwNCA5IDMgMTAuMzU0OTkgMyAxMiBDIDMgMTMuNjQ1MDEgNC4zNTQ5OTA0IDE1IDYgMTUgQyA2LjczMjA3NzEgMTUgNy4zOTg1Mzk5IDE0LjcyMjE0NiA3LjkyMTg3NSAxNC4yNzkyOTcgTCAxNS4wNTY2NDEgMTguNDM5NDUzIEMgMTUuMDIxNTU1IDE4LjYyMTUxNCAxNSAxOC44MDgzODYgMTUgMTkgQyAxNSAyMC42NDUwMSAxNi4zNTQ5OSAyMiAxOCAyMiBDIDE5LjY0NTAxIDIyIDIxIDIwLjY0NTAxIDIxIDE5IEMgMjEgMTcuMzU0OTkgMTkuNjQ1MDEgMTYgMTggMTYgQyAxNy4yNjc0OCAxNiAxNi42MDE1OTMgMTYuMjc5MzI4IDE2LjA3ODEyNSAxNi43MjI2NTYgTCA4Ljk0MzM1OTQgMTIuNTU4NTk0IEMgOC45NzgyMDk1IDEyLjM3NzEyMiA5IDEyLjE5MDk1MyA5IDEyIEMgOSAxMS44MDkwNDcgOC45NzgyMDk1IDExLjYyMjg3OCA4Ljk0MzM1OTQgMTEuNDQxNDA2IEwgMTYuMDc4MTI1IDcuMjc5Mjk2OSBDIDE2LjYwMTQ2IDcuNzIyMTQ2MSAxNy4yNjc5MjMgOCAxOCA4IEMgMTkuNjQ1MDEgOCAyMSA2LjY0NTAwOTYgMjEgNSBDIDIxIDMuMzU0OTkwNCAxOS42NDUwMSAyIDE4IDIgeiBNIDE4IDQgQyAxOC41NjQxMjkgNCAxOSA0LjQzNTg3MDYgMTkgNSBDIDE5IDUuNTY0MTI5NCAxOC41NjQxMjkgNiAxOCA2IEMgMTcuNDM1ODcxIDYgMTcgNS41NjQxMjk0IDE3IDUgQyAxNyA0LjQzNTg3MDYgMTcuNDM1ODcxIDQgMTggNCB6IE0gNiAxMSBDIDYuNTY0MTI5NCAxMSA3IDExLjQzNTg3MSA3IDEyIEMgNyAxMi41NjQxMjkgNi41NjQxMjk0IDEzIDYgMTMgQyA1LjQzNTg3MDYgMTMgNSAxMi41NjQxMjkgNSAxMiBDIDUgMTEuNDM1ODcxIDUuNDM1ODcwNiAxMSA2IDExIHogTSAxOCAxOCBDIDE4LjU2NDEyOSAxOCAxOSAxOC40MzU4NzEgMTkgMTkgQyAxOSAxOS41NjQxMjkgMTguNTY0MTI5IDIwIDE4IDIwIEMgMTcuNDM1ODcxIDIwIDE3IDE5LjU2NDEyOSAxNyAxOSBDIDE3IDE4LjQzNTg3MSAxNy40MzU4NzEgMTggMTggMTggeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-table-rows: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMSw4SDNWNGgxOFY4eiBNMjEsMTBIM3Y0aDE4VjEweiBNMjEsMTZIM3Y0aDE4VjE2eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-tag: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjgiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCA0MyAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTI4LjgzMzIgMTIuMzM0TDMyLjk5OTggMTYuNTAwN0wzNy4xNjY1IDEyLjMzNEgyOC44MzMyWiIvPgoJCTxwYXRoIGQ9Ik0xNi4yMDk1IDIxLjYxMDRDMTUuNjg3MyAyMi4xMjk5IDE0Ljg0NDMgMjIuMTI5OSAxNC4zMjQ4IDIxLjYxMDRMNi45ODI5IDE0LjcyNDVDNi41NzI0IDE0LjMzOTQgNi4wODMxMyAxMy42MDk4IDYuMDQ3ODYgMTMuMDQ4MkM1Ljk1MzQ3IDExLjUyODggNi4wMjAwMiA4LjYxOTQ0IDYuMDY2MjEgNy4wNzY5NUM2LjA4MjgxIDYuNTE0NzcgNi41NTU0OCA2LjA0MzQ3IDcuMTE4MDQgNi4wMzA1NUM5LjA4ODYzIDUuOTg0NzMgMTMuMjYzOCA1LjkzNTc5IDEzLjY1MTggNi4zMjQyNUwyMS43MzY5IDEzLjYzOUMyMi4yNTYgMTQuMTU4NSAyMS43ODUxIDE1LjQ3MjQgMjEuMjYyIDE1Ljk5NDZMMTYuMjA5NSAyMS42MTA0Wk05Ljc3NTg1IDguMjY1QzkuMzM1NTEgNy44MjU2NiA4LjYyMzUxIDcuODI1NjYgOC4xODI4IDguMjY1QzcuNzQzNDYgOC43MDU3MSA3Ljc0MzQ2IDkuNDE3MzMgOC4xODI4IDkuODU2NjdDOC42MjM4MiAxMC4yOTY0IDkuMzM1ODIgMTAuMjk2NCA5Ljc3NTg1IDkuODU2NjdDMTAuMjE1NiA5LjQxNzMzIDEwLjIxNTYgOC43MDUzMyA5Ljc3NTg1IDguMjY1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtdGV4dC1lZGl0b3ItaWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xNSAxNUgzdjJoMTJ2LTJ6bTAtOEgzdjJoMTJWN3pNMyAxM2gxOHYtMkgzdjJ6bTAgOGgxOHYtMkgzdjJ6TTMgM3YyaDE4VjNIM3oiLz4KPC9zdmc+Cg==);
  --jp-icon-toc: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik03LDVIMjFWN0g3VjVNNywxM1YxMUgyMVYxM0g3TTQsNC41QTEuNSwxLjUgMCAwLDEgNS41LDZBMS41LDEuNSAwIDAsMSA0LDcuNUExLjUsMS41IDAgMCwxIDIuNSw2QTEuNSwxLjUgMCAwLDEgNCw0LjVNNCwxMC41QTEuNSwxLjUgMCAwLDEgNS41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMy41QTEuNSwxLjUgMCAwLDEgMi41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMC41TTcsMTlWMTdIMjFWMTlIN000LDE2LjVBMS41LDEuNSAwIDAsMSA1LjUsMThBMS41LDEuNSAwIDAsMSA0LDE5LjVBMS41LDEuNSAwIDAsMSAyLjUsMThBMS41LDEuNSAwIDAsMSA0LDE2LjVaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tree-view: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMiAxMVYzaC03djNIOVYzSDJ2OGg3VjhoMnYxMGg0djNoN3YtOGgtN3YzaC0yVjhoMnYzeiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-user: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE2IDdhNCA0IDAgMTEtOCAwIDQgNCAwIDAxOCAwek0xMiAxNGE3IDcgMCAwMC03IDdoMTRhNyA3IDAgMDAtNy03eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-users: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZlcnNpb249IjEuMSIgdmlld0JveD0iMCAwIDM2IDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogPGcgY2xhc3M9ImpwLWljb24zIiB0cmFuc2Zvcm09Im1hdHJpeCgxLjczMjcgMCAwIDEuNzMyNyAtMy42MjgyIC4wOTk1NzcpIiBmaWxsPSIjNjE2MTYxIj4KICA8cGF0aCB0cmFuc2Zvcm09Im1hdHJpeCgxLjUsMCwwLDEuNSwwLC02KSIgZD0ibTEyLjE4NiA3LjUwOThjLTEuMDUzNSAwLTEuOTc1NyAwLjU2NjUtMi40Nzg1IDEuNDEwMiAwLjc1MDYxIDAuMzEyNzcgMS4zOTc0IDAuODI2NDggMS44NzMgMS40NzI3aDMuNDg2M2MwLTEuNTkyLTEuMjg4OS0yLjg4MjgtMi44ODA5LTIuODgyOHoiLz4KICA8cGF0aCBkPSJtMjAuNDY1IDIuMzg5NWEyLjE4ODUgMi4xODg1IDAgMCAxLTIuMTg4NCAyLjE4ODUgMi4xODg1IDIuMTg4NSAwIDAgMS0yLjE4ODUtMi4xODg1IDIuMTg4NSAyLjE4ODUgMCAwIDEgMi4xODg1LTIuMTg4NSAyLjE4ODUgMi4xODg1IDAgMCAxIDIuMTg4NCAyLjE4ODV6Ii8+CiAgPHBhdGggdHJhbnNmb3JtPSJtYXRyaXgoMS41LDAsMCwxLjUsMCwtNikiIGQ9Im0zLjU4OTggOC40MjE5Yy0xLjExMjYgMC0yLjAxMzcgMC45MDExMS0yLjAxMzcgMi4wMTM3aDIuODE0NWMwLjI2Nzk3LTAuMzczMDkgMC41OTA3LTAuNzA0MzUgMC45NTg5OC0wLjk3ODUyLTAuMzQ0MzMtMC42MTY4OC0xLjAwMzEtMS4wMzUyLTEuNzU5OC0xLjAzNTJ6Ii8+CiAgPHBhdGggZD0ibTYuOTE1NCA0LjYyM2ExLjUyOTQgMS41Mjk0IDAgMCAxLTEuNTI5NCAxLjUyOTQgMS41Mjk0IDEuNTI5NCAwIDAgMS0xLjUyOTQtMS41Mjk0IDEuNTI5NCAxLjUyOTQgMCAwIDEgMS41Mjk0LTEuNTI5NCAxLjUyOTQgMS41Mjk0IDAgMCAxIDEuNTI5NCAxLjUyOTR6Ii8+CiAgPHBhdGggZD0ibTYuMTM1IDEzLjUzNWMwLTMuMjM5MiAyLjYyNTktNS44NjUgNS44NjUtNS44NjUgMy4yMzkyIDAgNS44NjUgMi42MjU5IDUuODY1IDUuODY1eiIvPgogIDxjaXJjbGUgY3g9IjEyIiBjeT0iMy43Njg1IiByPSIyLjk2ODUiLz4KIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-word: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KIDxnIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzQxNDE0MSI+CiAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiA8L2c+CiA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSguNDMgLjA0MDEpIiBmaWxsPSIjZmZmIj4KICA8cGF0aCBkPSJtNC4xNCA4Ljc2cTAuMDY4Mi0xLjg5IDIuNDItMS44OSAxLjE2IDAgMS42OCAwLjQyIDAuNTY3IDAuNDEgMC41NjcgMS4xNnYzLjQ3cTAgMC40NjIgMC41MTQgMC40NjIgMC4xMDMgMCAwLjItMC4wMjMxdjAuNzE0cS0wLjM5OSAwLjEwMy0wLjY1MSAwLjEwMy0wLjQ1MiAwLTAuNjkzLTAuMjItMC4yMzEtMC4yLTAuMjg0LTAuNjYyLTAuOTU2IDAuODcyLTIgMC44NzItMC45MDMgMC0xLjQ3LTAuNDcyLTAuNTI1LTAuNDcyLTAuNTI1LTEuMjYgMC0wLjI2MiAwLjA0NTItMC40NzIgMC4wNTY3LTAuMjIgMC4xMTYtMC4zNzggMC4wNjgyLTAuMTY4IDAuMjMxLTAuMzA0IDAuMTU4LTAuMTQ3IDAuMjYyLTAuMjQyIDAuMTE2LTAuMDkxNCAwLjM2OC0wLjE2OCAwLjI2Mi0wLjA5MTQgMC4zOTktMC4xMjYgMC4xMzYtMC4wNDUyIDAuNDcyLTAuMTAzIDAuMzM2LTAuMDU3OCAwLjUwNC0wLjA3OTggMC4xNTgtMC4wMjMxIDAuNTY3LTAuMDc5OCAwLjU1Ni0wLjA2ODIgMC43NzctMC4yMjEgMC4yMi0wLjE1MiAwLjIyLTAuNDQxdi0wLjI1MnEwLTAuNDMtMC4zNTctMC42NjItMC4zMzYtMC4yMzEtMC45NzYtMC4yMzEtMC42NjIgMC0wLjk5OCAwLjI2Mi0wLjMzNiAwLjI1Mi0wLjM5OSAwLjc5OHptMS44OSAzLjY4cTAuNzg4IDAgMS4yNi0wLjQxIDAuNTA0LTAuNDIgMC41MDQtMC45MDN2LTEuMDVxLTAuMjg0IDAuMTM2LTAuODYxIDAuMjMxLTAuNTY3IDAuMDkxNC0wLjk4NyAwLjE1OC0wLjQyIDAuMDY4Mi0wLjc2NiAwLjMyNi0wLjMzNiAwLjI1Mi0wLjMzNiAwLjcwNHQwLjMwNCAwLjcwNCAwLjg2MSAwLjI1MnoiIHN0cm9rZS13aWR0aD0iMS4wNSIvPgogIDxwYXRoIGQ9Im0xMCA0LjU2aDAuOTQ1djMuMTVxMC42NTEtMC45NzYgMS44OS0wLjk3NiAxLjE2IDAgMS44OSAwLjg0IDAuNjgyIDAuODQgMC42ODIgMi4zMSAwIDEuNDctMC43MDQgMi40Mi0wLjcwNCAwLjg4Mi0xLjg5IDAuODgyLTEuMjYgMC0xLjg5LTEuMDJ2MC43NjZoLTAuODV6bTIuNjIgMy4wNHEtMC43NDYgMC0xLjE2IDAuNjQtMC40NTIgMC42My0wLjQ1MiAxLjY4IDAgMS4wNSAwLjQ1MiAxLjY4dDEuMTYgMC42M3EwLjc3NyAwIDEuMjYtMC42MyAwLjQ5NC0wLjY0IDAuNDk0LTEuNjggMC0xLjA1LTAuNDcyLTEuNjgtMC40NjItMC42NC0xLjI2LTAuNjR6IiBzdHJva2Utd2lkdGg9IjEuMDUiLz4KICA8cGF0aCBkPSJtMi43MyAxNS44IDEzLjYgMC4wMDgxYzAuMDA2OSAwIDAtMi42IDAtMi42IDAtMC4wMDc4LTEuMTUgMC0xLjE1IDAtMC4wMDY5IDAtMC4wMDgzIDEuNS0wLjAwODMgMS41LTJlLTMgLTAuMDAxNC0xMS4zLTAuMDAxNC0xMS4zLTAuMDAxNGwtMC4wMDU5Mi0xLjVjMC0wLjAwNzgtMS4xNyAwLjAwMTMtMS4xNyAwLjAwMTN6IiBzdHJva2Utd2lkdGg9Ii45NzUiLz4KIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddAboveIcon {
  background-image: var(--jp-icon-add-above);
}

.jp-AddBelowIcon {
  background-image: var(--jp-icon-add-below);
}

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}

.jp-BellIcon {
  background-image: var(--jp-icon-bell);
}

.jp-BugDotIcon {
  background-image: var(--jp-icon-bug-dot);
}

.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}

.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}

.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}

.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}

.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}

.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}

.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}

.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}

.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}

.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}

.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}

.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}

.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}

.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}

.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}

.jp-CodeCheckIcon {
  background-image: var(--jp-icon-code-check);
}

.jp-CodeIcon {
  background-image: var(--jp-icon-code);
}

.jp-CollapseAllIcon {
  background-image: var(--jp-icon-collapse-all);
}

.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}

.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}

.jp-CopyrightIcon {
  background-image: var(--jp-icon-copyright);
}

.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}

.jp-DeleteIcon {
  background-image: var(--jp-icon-delete);
}

.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}

.jp-DuplicateIcon {
  background-image: var(--jp-icon-duplicate);
}

.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}

.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}

.jp-ErrorIcon {
  background-image: var(--jp-icon-error);
}

.jp-ExpandAllIcon {
  background-image: var(--jp-icon-expand-all);
}

.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}

.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}

.jp-FileIcon {
  background-image: var(--jp-icon-file);
}

.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}

.jp-FilterDotIcon {
  background-image: var(--jp-icon-filter-dot);
}

.jp-FilterIcon {
  background-image: var(--jp-icon-filter);
}

.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}

.jp-FolderFavoriteIcon {
  background-image: var(--jp-icon-folder-favorite);
}

.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}

.jp-HomeIcon {
  background-image: var(--jp-icon-home);
}

.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}

.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}

.jp-InfoIcon {
  background-image: var(--jp-icon-info);
}

.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}

.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}

.jp-JuliaIcon {
  background-image: var(--jp-icon-julia);
}

.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}

.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}

.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}

.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}

.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}

.jp-LaunchIcon {
  background-image: var(--jp-icon-launch);
}

.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}

.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}

.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}

.jp-ListIcon {
  background-image: var(--jp-icon-list);
}

.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}

.jp-MoveDownIcon {
  background-image: var(--jp-icon-move-down);
}

.jp-MoveUpIcon {
  background-image: var(--jp-icon-move-up);
}

.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}

.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}

.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}

.jp-NumberingIcon {
  background-image: var(--jp-icon-numbering);
}

.jp-OfflineBoltIcon {
  background-image: var(--jp-icon-offline-bolt);
}

.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}

.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}

.jp-PdfIcon {
  background-image: var(--jp-icon-pdf);
}

.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}

.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}

.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}

.jp-RedoIcon {
  background-image: var(--jp-icon-redo);
}

.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}

.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}

.jp-RunIcon {
  background-image: var(--jp-icon-run);
}

.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}

.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}

.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}

.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}

.jp-ShareIcon {
  background-image: var(--jp-icon-share);
}

.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}

.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}

.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}

.jp-TableRowsIcon {
  background-image: var(--jp-icon-table-rows);
}

.jp-TagIcon {
  background-image: var(--jp-icon-tag);
}

.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}

.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}

.jp-TocIcon {
  background-image: var(--jp-icon-toc);
}

.jp-TreeViewIcon {
  background-image: var(--jp-icon-tree-view);
}

.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}

.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}

.jp-UserIcon {
  background-image: var(--jp-icon-user);
}

.jp-UsersIcon {
  background-image: var(--jp-icon-users);
}

.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}

.jp-WordIcon {
  background-image: var(--jp-icon-word);
}

.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.lm-TabBar .lm-TabBar-addButton {
  align-items: center;
  display: flex;
  padding: 4px;
  padding-bottom: 5px;
  margin-right: 1px;
  background-color: var(--jp-layout-color2);
}

.lm-TabBar .lm-TabBar-addButton:hover {
  background-color: var(--jp-layout-color1);
}

.lm-DockPanel-tabBar .lm-TabBar-tab {
  width: var(--jp-private-horizontal-tab-width);
}

.lm-DockPanel-tabBar .lm-TabBar-content {
  flex: unset;
}

.lm-DockPanel-tabBar[data-orientation='horizontal'] {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}

/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}

.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}

.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}

.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}

.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}

.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}

.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}

.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}

.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}

/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}

.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}

.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}

.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}

.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}

.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}

.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}

/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

.jp-icon-dot[fill] {
  fill: var(--jp-warn-color0);
}

.jp-jupyter-icon-color[fill] {
  fill: var(--jp-jupyter-icon-color, var(--jp-warn-color0));
}

.jp-notebook-icon-color[fill] {
  fill: var(--jp-notebook-icon-color, var(--jp-warn-color0));
}

.jp-json-icon-color[fill] {
  fill: var(--jp-json-icon-color, var(--jp-warn-color1));
}

.jp-console-icon-color[fill] {
  fill: var(--jp-console-icon-color, white);
}

.jp-console-icon-background-color[fill] {
  fill: var(--jp-console-icon-background-color, var(--jp-brand-color1));
}

.jp-terminal-icon-color[fill] {
  fill: var(--jp-terminal-icon-color, var(--jp-layout-color2));
}

.jp-terminal-icon-background-color[fill] {
  fill: var(
    --jp-terminal-icon-background-color,
    var(--jp-inverse-layout-color2)
  );
}

.jp-text-editor-icon-color[fill] {
  fill: var(--jp-text-editor-icon-color, var(--jp-inverse-layout-color3));
}

.jp-inspector-icon-color[fill] {
  fill: var(--jp-inspector-icon-color, var(--jp-inverse-layout-color3));
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* stylelint-disable selector-max-class, selector-max-compound-selectors */

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}

.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* stylelint-enable selector-max-class, selector-max-compound-selectors */

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) .jp-icon-hoverShow-content {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FormGroup-content fieldset {
  border: none;
  padding: 0;
  min-width: 0;
  width: 100%;
}

/* stylelint-disable selector-max-type */

.jp-FormGroup-content fieldset .jp-inputFieldWrapper input,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper select,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper textarea {
  font-size: var(--jp-content-font-size2);
  border-color: var(--jp-input-border-color);
  border-style: solid;
  border-radius: var(--jp-border-radius);
  border-width: 1px;
  padding: 6px 8px;
  background: none;
  color: var(--jp-ui-font-color0);
  height: inherit;
}

.jp-FormGroup-content fieldset input[type='checkbox'] {
  position: relative;
  top: 2px;
  margin-left: 0;
}

.jp-FormGroup-content button.jp-mod-styled {
  cursor: pointer;
}

.jp-FormGroup-content .checkbox label {
  cursor: pointer;
  font-size: var(--jp-content-font-size1);
}

.jp-FormGroup-content .jp-root > fieldset > legend {
  display: none;
}

.jp-FormGroup-content .jp-root > fieldset > p {
  display: none;
}

/** copy of `input.jp-mod-styled:focus` style */
.jp-FormGroup-content fieldset input:focus,
.jp-FormGroup-content fieldset select:focus {
  -moz-outline-radius: unset;
  outline: var(--jp-border-width) solid var(--md-blue-500);
  outline-offset: -1px;
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-FormGroup-content fieldset input:hover:not(:focus),
.jp-FormGroup-content fieldset select:hover:not(:focus) {
  background-color: var(--jp-border-color2);
}

/* stylelint-enable selector-max-type */

.jp-FormGroup-content .checkbox .field-description {
  /* Disable default description field for checkbox:
   because other widgets do not have description fields,
   we add descriptions to each widget on the field level.
  */
  display: none;
}

.jp-FormGroup-content #root__description {
  display: none;
}

.jp-FormGroup-content .jp-modifiedIndicator {
  width: 5px;
  background-color: var(--jp-brand-color2);
  margin-top: 0;
  margin-left: calc(var(--jp-private-settingeditor-modifier-indent) * -1);
  flex-shrink: 0;
}

.jp-FormGroup-content .jp-modifiedIndicator.jp-errorIndicator {
  background-color: var(--jp-error-color0);
  margin-right: 0.5em;
}

/* RJSF ARRAY style */

.jp-arrayFieldWrapper legend {
  font-size: var(--jp-content-font-size2);
  color: var(--jp-ui-font-color0);
  flex-basis: 100%;
  padding: 4px 0;
  font-weight: var(--jp-content-heading-font-weight);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-arrayFieldWrapper .field-description {
  padding: 4px 0;
  white-space: pre-wrap;
}

.jp-arrayFieldWrapper .array-item {
  width: 100%;
  border: 1px solid var(--jp-border-color2);
  border-radius: 4px;
  margin: 4px;
}

.jp-ArrayOperations {
  display: flex;
  margin-left: 8px;
}

.jp-ArrayOperationsButton {
  margin: 2px;
}

.jp-ArrayOperationsButton .jp-icon3[fill] {
  fill: var(--jp-ui-font-color0);
}

button.jp-ArrayOperationsButton.jp-mod-styled:disabled {
  cursor: not-allowed;
  opacity: 0.5;
}

/* RJSF form validation error */

.jp-FormGroup-content .validationErrors {
  color: var(--jp-error-color0);
}

/* Hide panel level error as duplicated the field level error */
.jp-FormGroup-content .panel.errors {
  display: none;
}

/* RJSF normal content (settings-editor) */

.jp-FormGroup-contentNormal {
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-FormGroup-contentItem {
  margin-left: 7px;
  color: var(--jp-ui-font-color0);
}

.jp-FormGroup-contentNormal .jp-FormGroup-description {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-default {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-fieldLabel {
  font-size: var(--jp-content-font-size1);
  font-weight: normal;
  min-width: 120px;
}

.jp-FormGroup-contentNormal fieldset:not(:first-child) {
  margin-left: 7px;
}

.jp-FormGroup-contentNormal .field-array-of-string .array-item {
  /* Display `jp-ArrayOperations` buttons side-by-side with content except
    for small screens where flex-wrap will place them one below the other.
  */
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-objectFieldWrapper .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

/* RJSF compact content (metadata-form) */

.jp-FormGroup-content.jp-FormGroup-contentCompact {
  width: 100%;
}

.jp-FormGroup-contentCompact .form-group {
  display: flex;
  padding: 0.5em 0.2em 0.5em 0;
}

.jp-FormGroup-contentCompact
  .jp-FormGroup-compactTitle
  .jp-FormGroup-description {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color2);
}

.jp-FormGroup-contentCompact .jp-FormGroup-fieldLabel {
  padding-bottom: 0.3em;
}

.jp-FormGroup-contentCompact .jp-inputFieldWrapper .form-control {
  width: 100%;
  box-sizing: border-box;
}

.jp-FormGroup-contentCompact .jp-arrayFieldWrapper .jp-FormGroup-compactTitle {
  padding-bottom: 7px;
}

.jp-FormGroup-contentCompact
  .jp-objectFieldWrapper
  .jp-objectFieldWrapper
  .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

.jp-FormGroup-contentCompact ul.error-detail {
  margin-block-start: 0.5em;
  margin-block-end: 0.5em;
  padding-inline-start: 1em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-SidePanel {
  display: flex;
  flex-direction: column;
  min-width: var(--jp-sidebar-min-width);
  overflow-y: auto;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size1);
}

.jp-SidePanel-header {
  flex: 0 0 auto;
  display: flex;
  border-bottom: var(--jp-border-width) solid var(--jp-border-color2);
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin: 0;
  padding: 2px;
  text-transform: uppercase;
}

.jp-SidePanel-toolbar {
  flex: 0 0 auto;
}

.jp-SidePanel-content {
  flex: 1 1 auto;
}

.jp-SidePanel-toolbar,
.jp-AccordionPanel-toolbar {
  height: var(--jp-private-toolbar-height);
}

.jp-SidePanel-toolbar.jp-Toolbar-micro {
  display: none;
}

.lm-AccordionPanel .jp-AccordionPanel-title {
  box-sizing: border-box;
  line-height: 25px;
  margin: 0;
  display: flex;
  align-items: center;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  font-size: var(--jp-ui-font-size0);
}

.jp-AccordionPanel-title {
  cursor: pointer;
  user-select: none;
  -moz-user-select: none;
  -webkit-user-select: none;
  text-transform: uppercase;
}

.lm-AccordionPanel[data-orientation='horizontal'] > .jp-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleLabel {
  user-select: none;
  text-overflow: ellipsis;
  white-space: nowrap;
  overflow: hidden;
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleCollapser {
  transform: rotate(-90deg);
  margin: auto 0;
  height: 16px;
}

.jp-AccordionPanel-title.lm-mod-expanded .lm-AccordionPanel-titleCollapser {
  transform: rotate(0deg);
}

.lm-AccordionPanel .jp-AccordionPanel-toolbar {
  background: none;
  box-shadow: none;
  border: none;
  margin-left: auto;
}

.lm-AccordionPanel .lm-SplitPanel-handle:hover {
  background: var(--jp-layout-color3);
}

.jp-text-truncated {
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent::before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent::after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }

  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }

  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input[type='checkbox'].jp-mod-styled {
  appearance: checkbox;
  -webkit-appearance: checkbox;
  -moz-appearance: checkbox;
  height: auto;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper:not(.multiple) {
  height: 28px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

select.jp-mod-styled:not([multiple]) {
  height: 32px;
}

select.jp-mod-styled[multiple] {
  max-height: 200px;
  overflow-y: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-switch {
  display: flex;
  align-items: center;
  padding-left: 4px;
  padding-right: 4px;
  font-size: var(--jp-ui-font-size1);
  background-color: transparent;
  color: var(--jp-ui-font-color1);
  border: none;
  height: 20px;
}

.jp-switch:hover {
  background-color: var(--jp-layout-color2);
}

.jp-switch-label {
  margin-right: 5px;
  font-family: var(--jp-ui-font-family);
}

.jp-switch-track {
  cursor: pointer;
  background-color: var(--jp-switch-color, var(--jp-border-color1));
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 34px;
  height: 16px;
  width: 35px;
  position: relative;
}

.jp-switch-track::before {
  content: '';
  position: absolute;
  height: 10px;
  width: 10px;
  margin: 3px;
  left: 0;
  background-color: var(--jp-ui-inverse-font-color1);
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 50%;
}

.jp-switch[aria-checked='true'] .jp-switch-track {
  background-color: var(--jp-switch-true-position-color, var(--jp-warn-color0));
}

.jp-switch[aria-checked='true'] .jp-switch-track::before {
  /* track width (35) - margins (3 + 3) - thumb width (10) */
  left: 19px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 8;
  overflow-x: hidden;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0;
  margin: 0;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0 6px;
  margin: 0;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent > span {
  padding: 0;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar.jp-Toolbar-micro {
  padding: 0;
  min-height: 0;
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar {
  border: none;
  box-shadow: none;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-WindowedPanel-outer {
  position: relative;
  overflow-y: auto;
}

.jp-WindowedPanel-inner {
  position: relative;
}

.jp-WindowedPanel-window {
  position: absolute;
  left: 0;
  right: 0;
  overflow: visible;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

body {
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
}

/* Disable native link decoration styles everywhere outside of dialog boxes */
a {
  text-decoration: unset;
  color: unset;
}

a:hover {
  text-decoration: unset;
  color: unset;
}

/* Accessibility for links inside dialog box text */
.jp-Dialog-content a {
  text-decoration: revert;
  color: var(--jp-content-link-color);
}

.jp-Dialog-content a:hover {
  text-decoration: revert;
}

/* Styles for ui-components */
.jp-Button {
  color: var(--jp-ui-font-color2);
  border-radius: var(--jp-border-radius);
  padding: 0 12px;
  font-size: var(--jp-ui-font-size1);

  /* Copy from blueprint 3 */
  display: inline-flex;
  flex-direction: row;
  border: none;
  cursor: pointer;
  align-items: center;
  justify-content: center;
  text-align: left;
  vertical-align: middle;
  min-height: 30px;
  min-width: 30px;
}

.jp-Button:disabled {
  cursor: not-allowed;
}

.jp-Button:empty {
  padding: 0 !important;
}

.jp-Button.jp-mod-small {
  min-height: 24px;
  min-width: 24px;
  font-size: 12px;
  padding: 0 7px;
}

/* Use our own theme for hover styles */
.jp-Button.jp-mod-minimal:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Button.jp-mod-minimal {
  background: none;
}

.jp-InputGroup {
  display: block;
  position: relative;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border: none;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
  padding-bottom: 0;
  padding-top: 0;
  padding-left: 10px;
  padding-right: 28px;
  position: relative;
  width: 100%;
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  font-size: 14px;
  font-weight: 400;
  height: 30px;
  line-height: 30px;
  outline: none;
  vertical-align: middle;
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input:disabled {
  cursor: not-allowed;
  resize: block;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input:disabled ~ span {
  cursor: not-allowed;
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color2);
}

.jp-InputGroupAction {
  position: absolute;
  bottom: 1px;
  right: 0;
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
  cursor: not-allowed;
  resize: block;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled ~ span {
  cursor: not-allowed;
}

/* Use our own theme for hover and option styles */
/* stylelint-disable-next-line selector-max-type */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}

select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-StatusBar-Widget {
  display: flex;
  align-items: center;
  background: var(--jp-layout-color2);
  min-height: var(--jp-statusbar-height);
  justify-content: space-between;
  padding: 0 10px;
}

.jp-StatusBar-Left {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-StatusBar-Middle {
  display: flex;
  align-items: center;
}

.jp-StatusBar-Right {
  display: flex;
  align-items: center;
  flex-direction: row-reverse;
}

.jp-StatusBar-Item {
  max-height: var(--jp-statusbar-height);
  margin: 0 2px;
  height: var(--jp-statusbar-height);
  white-space: nowrap;
  text-overflow: ellipsis;
  color: var(--jp-ui-font-color1);
  padding: 0 6px;
}

.jp-mod-highlighted:hover {
  background-color: var(--jp-layout-color3);
}

.jp-mod-clicked {
  background-color: var(--jp-brand-color1);
}

.jp-mod-clicked:hover {
  background-color: var(--jp-brand-color0);
}

.jp-mod-clicked .jp-StatusBar-TextItem {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-StatusBar-HoverItem {
  box-shadow: '0px 4px 4px rgba(0, 0, 0, 0.25)';
}

.jp-StatusBar-TextItem {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  line-height: 24px;
  color: var(--jp-ui-font-color1);
}

.jp-StatusBar-GroupItem {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-Statusbar-ProgressCircle svg {
  display: block;
  margin: 0 auto;
  width: 16px;
  height: 24px;
  align-self: normal;
}

.jp-Statusbar-ProgressCircle path {
  fill: var(--jp-inverse-layout-color3);
}

.jp-Statusbar-ProgressBar-progress-bar {
  height: 10px;
  width: 100px;
  border: solid 0.25px var(--jp-brand-color2);
  border-radius: 3px;
  overflow: hidden;
  align-self: center;
}

.jp-Statusbar-ProgressBar-progress-bar > div {
  background-color: var(--jp-brand-color2);
  background-image: linear-gradient(
    -45deg,
    rgba(255, 255, 255, 0.2) 25%,
    transparent 25%,
    transparent 50%,
    rgba(255, 255, 255, 0.2) 50%,
    rgba(255, 255, 255, 0.2) 75%,
    transparent 75%,
    transparent
  );
  background-size: 40px 40px;
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 14px;
  color: #fff;
  text-align: center;
  animation: jp-Statusbar-ExecutionTime-progress-bar 2s linear infinite;
}

.jp-Statusbar-ProgressBar-progress-bar p {
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
  font-size: var(--jp-ui-font-size1);
  line-height: 10px;
  width: 100px;
}

@keyframes jp-Statusbar-ExecutionTime-progress-bar {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 40px 40px;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Modal variant
|----------------------------------------------------------------------------*/

.jp-ModalCommandPalette {
  position: absolute;
  z-index: 10000;
  top: 38px;
  left: 30%;
  margin: 0;
  padding: 4px;
  width: 40%;
  box-shadow: var(--jp-elevation-z4);
  border-radius: 4px;
  background: var(--jp-layout-color0);
}

.jp-ModalCommandPalette .lm-CommandPalette {
  max-height: 40vh;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-close-icon::after {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-header {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item {
  margin-left: 4px;
  margin-right: 4px;
}

.jp-ModalCommandPalette
  .lm-CommandPalette
  .lm-CommandPalette-item.lm-mod-disabled {
  display: none;
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-SearchIconGroup {
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  padding: 5px 5px 1px;
}

.jp-SearchIconGroup svg {
  height: 20px;
  width: 20px;
}

.jp-SearchIconGroup .jp-icon3[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color2);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item.lm-mod-active {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item.lm-mod-active .lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-inverse-font-color0);
}

.lm-CommandPalette-item.lm-mod-active .jp-icon-selectable[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.6;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty::after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0;
  left: 0;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px 24px 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
  resize: both;
}

.jp-Dialog-content.jp-Dialog-content-small {
  max-width: 500px;
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus {
  outline: 1px solid var(--jp-accept-color-normal, var(--jp-brand-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus {
  outline: 1px solid var(--jp-warn-color-normal, var(--jp-error-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline: 1px solid var(--jp-reject-color-normal, var(--md-grey-600));
}

button.jp-Dialog-close-button {
  padding: 0;
  height: 100%;
  min-width: unset;
  min-height: unset;
}

.jp-Dialog-header {
  display: flex;
  justify-content: space-between;
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color1);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  align-items: center;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-checkbox {
  padding-right: 5px;
}

.jp-Dialog-checkbox > input:focus-visible {
  outline: 1px solid var(--jp-input-active-border-color);
  outline-offset: 1px;
}

.jp-Dialog-spacer {
  flex: 1 1 auto;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Input-Boolean-Dialog {
  flex-direction: row-reverse;
  align-items: end;
  width: 100%;
}

.jp-Input-Boolean-Dialog > label {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error {
  padding: 6px;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error > pre {
  width: auto;
  padding: 10px;
  background: var(--jp-error-color3);
  border: var(--jp-border-width) solid var(--jp-error-color1);
  border-radius: var(--jp-border-radius);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  white-space: pre-wrap;
  word-wrap: break-word;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;
  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;
  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #a0f;
  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;
  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;
  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;
  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;
  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;
  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;
  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;
  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;
  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;
  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ff0;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;
  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;
  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;
  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;
  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;
  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;
  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

:root {
  /* This is the padding value to fill the gaps between lines containing spans with background color. */
  --jp-private-code-span-padding: calc(
    (var(--jp-code-line-height) - 1) * var(--jp-code-font-size) / 2
  );
}

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0;
  padding: 0;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}

.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}

.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}

.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}

.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}

.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}

.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}

.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}

.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}

.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}

.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}

.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}

.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}

.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}

.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}

.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}

.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);

  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

/* stylelint-disable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0;
}

/* stylelint-enable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  table-layout: fixed;
  margin-left: auto;
  margin-bottom: 1em;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}

[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}

.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}

.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}

.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}

.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}

.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}

.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}

.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}

.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: var(--jp-ui-font-size0);
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-cursor-backdrop {
  position: fixed;
  width: 200px;
  height: 200px;
  margin-top: -100px;
  margin-left: -100px;
  will-change: transform;
  z-index: 100;
}

.lm-mod-drag-image {
  will-change: transform;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-lineFormSearch {
  padding: 4px 12px;
  background-color: var(--jp-layout-color2);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
  font-size: var(--jp-ui-font-size1);
}

.jp-lineFormCaption {
  font-size: var(--jp-ui-font-size0);
  line-height: var(--jp-ui-font-size1);
  margin-top: 4px;
  color: var(--jp-ui-font-color0);
}

.jp-baseLineForm {
  border: none;
  border-radius: 0;
  position: absolute;
  background-size: 16px;
  background-repeat: no-repeat;
  background-position: center;
  outline: none;
}

.jp-lineFormButtonContainer {
  top: 4px;
  right: 8px;
  height: 24px;
  padding: 0 12px;
  width: 12px;
}

.jp-lineFormButtonIcon {
  top: 0;
  right: 0;
  background-color: var(--jp-brand-color1);
  height: 100%;
  width: 100%;
  box-sizing: border-box;
  padding: 4px 6px;
}

.jp-lineFormButton {
  top: 0;
  right: 0;
  background-color: transparent;
  height: 100%;
  width: 100%;
  box-sizing: border-box;
}

.jp-lineFormWrapper {
  overflow: hidden;
  padding: 0 8px;
  border: 1px solid var(--jp-border-color0);
  background-color: var(--jp-input-active-background);
  height: 22px;
}

.jp-lineFormWrapperFocusWithin {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-lineFormInput {
  background: transparent;
  width: 200px;
  height: 100%;
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  line-height: 28px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/
.jp-DocumentSearch-input {
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  font-size: var(--jp-ui-font-size1);
  background-color: var(--jp-layout-color0);
  font-family: var(--jp-ui-font-family);
  padding: 2px 1px;
  resize: none;
}

.jp-DocumentSearch-overlay {
  position: absolute;
  background-color: var(--jp-toolbar-background);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  border-left: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  top: 0;
  right: 0;
  z-index: 7;
  min-width: 405px;
  padding: 2px;
  font-size: var(--jp-ui-font-size1);

  --jp-private-document-search-button-height: 20px;
}

.jp-DocumentSearch-overlay button {
  background-color: var(--jp-toolbar-background);
  outline: 0;
}

.jp-DocumentSearch-overlay button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-overlay button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-overlay-row {
  display: flex;
  align-items: center;
  margin-bottom: 2px;
}

.jp-DocumentSearch-button-content {
  display: inline-block;
  cursor: pointer;
  box-sizing: border-box;
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-button-content svg {
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-input-wrapper {
  border: var(--jp-border-width) solid var(--jp-border-color0);
  display: flex;
  background-color: var(--jp-layout-color0);
  margin: 2px;
}

.jp-DocumentSearch-input-wrapper:focus-within {
  border-color: var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper {
  all: initial;
  overflow: hidden;
  display: inline-block;
  border: none;
  box-sizing: border-box;
}

.jp-DocumentSearch-toggle-wrapper {
  width: 14px;
  height: 14px;
}

.jp-DocumentSearch-button-wrapper {
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
}

.jp-DocumentSearch-toggle-wrapper:focus,
.jp-DocumentSearch-button-wrapper:focus {
  outline: var(--jp-border-width) solid
    var(--jp-cell-editor-active-border-color);
  outline-offset: -1px;
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper,
.jp-DocumentSearch-button-content:focus {
  outline: none;
}

.jp-DocumentSearch-toggle-placeholder {
  width: 5px;
}

.jp-DocumentSearch-input-button::before {
  display: block;
  padding-top: 100%;
}

.jp-DocumentSearch-input-button-off {
  opacity: var(--jp-search-toggle-off-opacity);
}

.jp-DocumentSearch-input-button-off:hover {
  opacity: var(--jp-search-toggle-hover-opacity);
}

.jp-DocumentSearch-input-button-on {
  opacity: var(--jp-search-toggle-on-opacity);
}

.jp-DocumentSearch-index-counter {
  padding-left: 10px;
  padding-right: 10px;
  user-select: none;
  min-width: 35px;
  display: inline-block;
}

.jp-DocumentSearch-up-down-wrapper {
  display: inline-block;
  padding-right: 2px;
  margin-left: auto;
  white-space: nowrap;
}

.jp-DocumentSearch-spacer {
  margin-left: auto;
}

.jp-DocumentSearch-up-down-wrapper button {
  outline: 0;
  border: none;
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
  vertical-align: middle;
  margin: 1px 5px 2px;
}

.jp-DocumentSearch-up-down-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-up-down-button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-filter-button {
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-filter-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled:hover {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-search-options {
  padding: 0 8px;
  margin-left: 3px;
  width: 100%;
  display: grid;
  justify-content: start;
  grid-template-columns: 1fr 1fr;
  align-items: center;
  justify-items: stretch;
}

.jp-DocumentSearch-search-filter-disabled {
  color: var(--jp-ui-font-color2);
}

.jp-DocumentSearch-search-filter {
  display: flex;
  align-items: center;
  user-select: none;
}

.jp-DocumentSearch-regex-error {
  color: var(--jp-error-color0);
}

.jp-DocumentSearch-replace-button-wrapper {
  overflow: hidden;
  display: inline-block;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color0);
  margin: auto 2px;
  padding: 1px 4px;
  height: calc(var(--jp-private-document-search-button-height) + 2px);
}

.jp-DocumentSearch-replace-button-wrapper:focus {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-replace-button {
  display: inline-block;
  text-align: center;
  cursor: pointer;
  box-sizing: border-box;
  color: var(--jp-ui-font-color1);

  /* height - 2 * (padding of wrapper) */
  line-height: calc(var(--jp-private-document-search-button-height) - 2px);
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-replace-button:focus {
  outline: none;
}

.jp-DocumentSearch-replace-wrapper-class {
  margin-left: 14px;
  display: flex;
}

.jp-DocumentSearch-replace-toggle {
  border: none;
  background-color: var(--jp-toolbar-background);
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-replace-toggle:hover {
  background-color: var(--jp-layout-color2);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.cm-editor {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;

  /* Changed to auto to autogrow */
}

.cm-editor pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .cm-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

.jp-CodeMirrorEditor {
  cursor: text;
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.cm-editor.jp-mod-readOnly .cm-cursor {
  display: none;
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.cm-searching,
.cm-searching span {
  /* `.cm-searching span`: we need to override syntax highlighting */
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.cm-searching::selection,
.cm-searching span::selection {
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.jp-current-match > .cm-searching,
.jp-current-match > .cm-searching span,
.cm-searching > .jp-current-match,
.cm-searching > .jp-current-match span {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.jp-current-match > .cm-searching::selection,
.cm-searching > .jp-current-match::selection,
.jp-current-match > .cm-searching span::selection {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.cm-trailingspace {
  background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAYAAAB4ka1VAAAAsElEQVQIHQGlAFr/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7+r3zKmT0/+pk9P/7+r3zAAAAAAAAAAABAAAAAAAAAAA6OPzM+/q9wAAAAAA6OPzMwAAAAAAAAAAAgAAAAAAAAAAGR8NiRQaCgAZIA0AGR8NiQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQyoYJ/SY80UAAAAASUVORK5CYII=);
  background-position: center left;
  background-repeat: repeat-x;
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/* Styles for shared cursors (remote cursor locations and selected ranges) */
.jp-CodeMirrorEditor .cm-ySelectionCaret {
  position: relative;
  border-left: 1px solid black;
  margin-left: -1px;
  margin-right: -1px;
  box-sizing: border-box;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret > .cm-ySelectionInfo {
  white-space: nowrap;
  position: absolute;
  top: -1.15em;
  padding-bottom: 0.05em;
  left: -1px;
  font-size: 0.95em;
  font-family: var(--jp-ui-font-family);
  font-weight: bold;
  line-height: normal;
  user-select: none;
  color: white;
  padding-left: 2px;
  padding-right: 2px;
  z-index: 101;
  transition: opacity 0.3s ease-in-out;
}

.jp-CodeMirrorEditor .cm-ySelectionInfo {
  transition-delay: 0.7s;
  opacity: 0;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret:hover > .cm-ySelectionInfo {
  opacity: 1;
  transition-delay: 0s;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser .jp-SidePanel-content {
  display: flex;
  flex-direction: column;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  flex-wrap: wrap;
  row-gap: 12px;
  border-bottom: none;
  height: auto;
  margin: 8px 12px 0;
  box-shadow: none;
  padding: 0;
  justify-content: flex-start;
}

.jp-FileBrowser-Panel {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 8px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0 2px;
  padding: 0 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  padding-left: 0;
  padding-right: 2px;
  align-items: center;
  height: unset;
}

.jp-FileBrowser-toolbar > .jp-Toolbar-item .jp-ToolbarButtonComponent {
  width: 40px;
}

/*-----------------------------------------------------------------------------
| Other styles
|----------------------------------------------------------------------------*/

.jp-FileDialog.jp-mod-conflict input {
  color: var(--jp-error-color1);
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

.jp-LastModified-hidden {
  display: none;
}

.jp-FileSize-hidden {
  display: none;
}

.jp-FileBrowser .lm-AccordionPanel > h3:first-child {
  display: none;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  align-items: center;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-DirListing-headerItem.jp-id-filesize {
  flex: 0 0 75px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-id-narrow {
  display: none;
  flex: 0 0 5px;
  padding: 4px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
  color: var(--jp-border-color2);
}

.jp-DirListing-narrow .jp-id-narrow {
  display: block;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-content mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.jp-DirListing-content .jp-DirListing-item.jp-mod-selected mark {
  color: var(--jp-ui-inverse-font-color0);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  align-items: center;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-checkboxWrapper {
  /* Increases hit area of checkbox. */
  padding: 4px;
}

.jp-DirListing-header
  .jp-DirListing-checkboxWrapper
  + .jp-DirListing-headerItem {
  padding-left: 4px;
}

.jp-DirListing-content .jp-DirListing-checkboxWrapper {
  position: relative;
  left: -4px;
  margin: -4px 0 -4px -8px;
}

.jp-DirListing-checkboxWrapper.jp-mod-visible {
  visibility: visible;
}

/* For devices that support hovering, hide checkboxes until hovered, selected...
*/
@media (hover: hover) {
  .jp-DirListing-checkboxWrapper {
    visibility: hidden;
  }

  .jp-DirListing-item:hover .jp-DirListing-checkboxWrapper,
  .jp-DirListing-item.jp-mod-selected .jp-DirListing-checkboxWrapper {
    visibility: visible;
  }
}

.jp-DirListing-item[data-is-dot] {
  opacity: 75%;
}

.jp-DirListing-item.jp-mod-selected {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemText:focus {
  outline-width: 2px;
  outline-color: var(--jp-inverse-layout-color1);
  outline-style: solid;
  outline-offset: 1px;
}

.jp-DirListing-item.jp-mod-selected .jp-DirListing-itemText:focus {
  outline-color: var(--jp-layout-color1);
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-itemFileSize {
  flex: 0 0 90px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon::before {
  color: var(--jp-success-color1);
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.jp-mod-running.jp-mod-selected
  .jp-DirListing-itemIcon::before {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-OutputPrompt {
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-OutputArea-prompt {
  display: table-cell;
  vertical-align: top;
}

.jp-OutputArea-output {
  display: table-cell;
  width: 100%;
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea .jp-RenderedText {
  padding-left: 1ch;
}

/**
 * Prompt overlay.
 */

.jp-OutputArea-promptOverlay {
  position: absolute;
  top: 0;
  width: var(--jp-cell-prompt-width);
  height: 100%;
  opacity: 0.5;
}

.jp-OutputArea-promptOverlay:hover {
  background: var(--jp-layout-color2);
  box-shadow: inset 0 0 1px var(--jp-inverse-layout-color0);
  cursor: zoom-out;
}

.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay:hover {
  cursor: zoom-in;
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0;
  padding: 0;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

.jp-TrimmedOutputs pre {
  background: var(--jp-layout-color3);
  font-size: calc(var(--jp-code-font-size) * 1.4);
  text-align: center;
  text-transform: uppercase;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/* Hide empty lines in the output area, for instance due to cleared widgets */
.jp-OutputArea-prompt:empty {
  padding: 0;
  border: 0;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0;
  width: 100%;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
  border-top: var(--jp-border-width) solid transparent;
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;

  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;

  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0 0.25em;
  margin: 0 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input::placeholder {
  opacity: 0;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

.jp-Stdin-input:focus::placeholder {
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

@media print {
  .jp-OutputArea-child {
    break-inside: avoid-page;
  }
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-OutputPrompt {
    display: table-row;
    text-align: left;
  }

  .jp-OutputArea-child .jp-OutputArea-output {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }
}

/* Trimmed outputs warning */
.jp-TrimmedOutputs > a {
  margin: 10px;
  text-decoration: none;
  cursor: pointer;
}

.jp-TrimmedOutputs > a:hover {
  text-decoration: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Table of Contents
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toc-active-width: 4px;
}

.jp-TableOfContents {
  display: flex;
  flex-direction: column;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  height: 100%;
}

.jp-TableOfContents-placeholder {
  text-align: center;
}

.jp-TableOfContents-placeholderContent {
  color: var(--jp-content-font-color2);
  padding: 8px;
}

.jp-TableOfContents-placeholderContent > h3 {
  margin-bottom: var(--jp-content-heading-margin-bottom);
}

.jp-TableOfContents .jp-SidePanel-content {
  overflow-y: auto;
}

.jp-TableOfContents-tree {
  margin: 4px;
}

.jp-TableOfContents ol {
  list-style-type: none;
}

/* stylelint-disable-next-line selector-max-type */
.jp-TableOfContents li > ol {
  /* Align left border with triangle icon center */
  padding-left: 11px;
}

.jp-TableOfContents-content {
  /* left margin for the active heading indicator */
  margin: 0 0 0 var(--jp-private-toc-active-width);
  padding: 0;
  background-color: var(--jp-layout-color1);
}

.jp-tocItem {
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-tocItem-heading {
  display: flex;
  cursor: pointer;
}

.jp-tocItem-heading:hover {
  background-color: var(--jp-layout-color2);
}

.jp-tocItem-content {
  display: block;
  padding: 4px 0;
  white-space: nowrap;
  text-overflow: ellipsis;
  overflow-x: hidden;
}

.jp-tocItem-collapser {
  height: 20px;
  margin: 2px 2px 0;
  padding: 0;
  background: none;
  border: none;
  cursor: pointer;
}

.jp-tocItem-collapser:hover {
  background-color: var(--jp-layout-color3);
}

/* Active heading indicator */

.jp-tocItem-heading::before {
  content: ' ';
  background: transparent;
  width: var(--jp-private-toc-active-width);
  height: 24px;
  position: absolute;
  left: 0;
  border-radius: var(--jp-border-radius);
}

.jp-tocItem-heading.jp-tocItem-active::before {
  background-color: var(--jp-brand-color1);
}

.jp-tocItem-heading:hover.jp-tocItem-active::before {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;

  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0;
  bottom: 0;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Hiding collapsers in print mode.

Note: input and output wrappers have "display: block" propery in print mode.
*/

@media print {
  .jp-Collapser {
    display: none;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0;
  width: 100%;
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-InputArea-editor {
  display: table-cell;
  overflow: hidden;
  vertical-align: top;

  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  background: var(--jp-cell-editor-background);
}

.jp-InputPrompt {
  display: table-cell;
  vertical-align: top;
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-InputArea-editor {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }

  .jp-InputPrompt {
    display: table-row;
    text-align: left;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: table;
  table-layout: fixed;
  width: 100%;
}

.jp-Placeholder-prompt {
  display: table-cell;
  box-sizing: border-box;
}

.jp-Placeholder-content {
  display: table-cell;
  padding: 4px 6px;
  border: 1px solid transparent;
  border-radius: 0;
  background: none;
  box-sizing: border-box;
  cursor: pointer;
}

.jp-Placeholder-contentContainer {
  display: flex;
}

.jp-Placeholder-content:hover,
.jp-InputPlaceholder > .jp-Placeholder-content:hover {
  border-color: var(--jp-layout-color3);
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

.jp-PlaceholderText {
  white-space: nowrap;
  overflow-x: hidden;
  color: var(--jp-inverse-layout-color3);
  font-family: var(--jp-code-font-family);
}

.jp-InputPlaceholder > .jp-Placeholder-content {
  border-color: var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0;
  margin: 0;

  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 24em;
  margin-left: var(--jp-private-cell-scrolling-output-offset);
  resize: vertical;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea[style*='height'] {
  max-height: unset;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea::after {
  content: ' ';
  box-shadow: inset 0 0 6px 2px rgb(0 0 0 / 30%);
  width: 100%;
  height: 100%;
  position: sticky;
  bottom: 0;
  top: 0;
  margin-top: -50%;
  float: left;
  display: block;
  pointer-events: none;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-child {
  padding-top: 6px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  width: calc(
    var(--jp-cell-prompt-width) - var(--jp-private-cell-scrolling-output-offset)
  );
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay {
  left: calc(-1 * var(--jp-private-cell-scrolling-output-offset));
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  display: table-cell;
  width: 100%;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

/* collapseHeadingButton (show always if hiddenCellsButton is _not_ shown) */
.jp-collapseHeadingButton {
  display: flex;
  min-height: var(--jp-cell-collapser-min-height);
  font-size: var(--jp-code-font-size);
  position: absolute;
  background-color: transparent;
  background-size: 25px;
  background-repeat: no-repeat;
  background-position-x: center;
  background-position-y: top;
  background-image: var(--jp-icon-caret-down);
  right: 0;
  top: 0;
  bottom: 0;
}

.jp-collapseHeadingButton.jp-mod-collapsed {
  background-image: var(--jp-icon-caret-right);
}

/*
 set the container font size to match that of content
 so that the nested collapse buttons have the right size
*/
.jp-MarkdownCell .jp-InputPrompt {
  font-size: var(--jp-content-font-size1);
}

/*
  Align collapseHeadingButton with cell top header
  The font sizes are identical to the ones in packages/rendermime/style/base.css
*/
.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='1'] {
  font-size: var(--jp-content-font-size5);
  background-position-y: calc(0.3 * var(--jp-content-font-size5));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='2'] {
  font-size: var(--jp-content-font-size4);
  background-position-y: calc(0.3 * var(--jp-content-font-size4));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='3'] {
  font-size: var(--jp-content-font-size3);
  background-position-y: calc(0.3 * var(--jp-content-font-size3));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='4'] {
  font-size: var(--jp-content-font-size2);
  background-position-y: calc(0.3 * var(--jp-content-font-size2));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='5'] {
  font-size: var(--jp-content-font-size1);
  background-position-y: top;
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='6'] {
  font-size: var(--jp-content-font-size0);
  background-position-y: top;
}

/* collapseHeadingButton (show only on (hover,active) if hiddenCellsButton is shown) */
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-collapseHeadingButton {
  display: none;
}

.jp-Notebook.jp-mod-showHiddenCellsButton
  :is(.jp-MarkdownCell:hover, .jp-mod-active)
  .jp-collapseHeadingButton {
  display: flex;
}

/* showHiddenCellsButton (only show if jp-mod-showHiddenCellsButton is set, which
is a consequence of the showHiddenCellsButton option in Notebook Settings)*/
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton {
  margin-left: calc(var(--jp-cell-prompt-width) + 2 * var(--jp-code-padding));
  margin-top: var(--jp-code-padding);
  border: 1px solid var(--jp-border-color2);
  background-color: var(--jp-border-color3) !important;
  color: var(--jp-content-font-color0) !important;
  display: flex;
}

.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton:hover {
  background-color: var(--jp-border-color2) !important;
}

.jp-showHiddenCellsButton {
  display: none;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Using block instead of flex to allow the use of the break-inside CSS property for
cell outputs.
*/

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-notebook-toolbar-padding: 2px 5px 2px 2px;
}

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: var(--jp-notebook-toolbar-padding);

  /* disable paint containment from lumino 2.0 default strict CSS containment */
  contain: style size !important;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

.jp-Toolbar-responsive-popup {
  position: absolute;
  height: fit-content;
  display: flex;
  flex-direction: row;
  flex-wrap: wrap;
  justify-content: flex-end;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: var(--jp-notebook-toolbar-padding);
  z-index: 1;
  right: 0;
  top: 0;
}

.jp-Toolbar > .jp-Toolbar-responsive-opener {
  margin-left: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-Notebook-ExecutionIndicator {
  position: relative;
  display: inline-block;
  height: 100%;
  z-index: 9997;
}

.jp-Notebook-ExecutionIndicator-tooltip {
  visibility: hidden;
  height: auto;
  width: max-content;
  width: -moz-max-content;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color1);
  text-align: justify;
  border-radius: 6px;
  padding: 0 5px;
  position: fixed;
  display: table;
}

.jp-Notebook-ExecutionIndicator-tooltip.up {
  transform: translateX(-50%) translateY(-100%) translateY(-32px);
}

.jp-Notebook-ExecutionIndicator-tooltip.down {
  transform: translateX(calc(-100% + 16px)) translateY(5px);
}

.jp-Notebook-ExecutionIndicator-tooltip.hidden {
  display: none;
}

.jp-Notebook-ExecutionIndicator:hover .jp-Notebook-ExecutionIndicator-tooltip {
  visibility: visible;
}

.jp-Notebook-ExecutionIndicator span {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  color: var(--jp-ui-font-color1);
  line-height: 24px;
  display: block;
}

.jp-Notebook-ExecutionIndicator-progress-bar {
  display: flex;
  justify-content: center;
  height: 100%;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*
 * Execution indicator
 */
.jp-tocItem-content::after {
  content: '';

  /* Must be identical to form a circle */
  width: 12px;
  height: 12px;
  background: none;
  border: none;
  position: absolute;
  right: 0;
}

.jp-tocItem-content[data-running='0']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background: none;
}

.jp-tocItem-content[data-running='1']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background-color: var(--jp-inverse-layout-color3);
}

.jp-tocItem-content[data-running='0'],
.jp-tocItem-content[data-running='1'] {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Notebook-footer {
  height: 27px;
  margin-left: calc(
    var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
      var(--jp-cell-padding)
  );
  width: calc(
    100% -
      (
        var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
          var(--jp-cell-padding) + var(--jp-cell-padding)
      )
  );
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  color: var(--jp-ui-font-color3);
  margin-top: 6px;
  background: none;
  cursor: pointer;
}

.jp-Notebook-footer:focus {
  border-color: var(--jp-cell-editor-active-border-color);
}

/* For devices that support hovering, hide footer until hover */
@media (hover: hover) {
  .jp-Notebook-footer {
    opacity: 0;
  }

  .jp-Notebook-footer:focus,
  .jp-Notebook-footer:hover {
    opacity: 1;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-side-by-side-output-size: 1fr;
  --jp-side-by-side-resized-cell: var(--jp-side-by-side-output-size);
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

/* stylelint-disable selector-max-class */

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-MainAreaWidget-ContainStrict .jp-Notebook * {
  contain: strict;
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* cell is dirty */
.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt {
  color: var(--jp-warn-color1);
}

.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt::before {
  color: var(--jp-warn-color1);
  content: '';
}

.jp-Notebook .jp-Cell.jp-mod-active.jp-mod-dirty .jp-Collapser {
  background: var(--jp-warn-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: block;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-ActiveCellTool {
  padding: 12px 0;
  display: flex;
}

.jp-ActiveCellTool-Content {
  flex: 1 1 auto;
}

.jp-ActiveCellTool .jp-ActiveCellTool-CellContent {
  background: var(--jp-cell-editor-background);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  min-height: 29px;
}

.jp-ActiveCellTool .jp-InputPrompt {
  min-width: calc(var(--jp-cell-prompt-width) * 0.75);
}

.jp-ActiveCellTool-CellContent > pre {
  padding: 5px 4px;
  margin: 0;
  white-space: normal;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label,
.jp-NumberSetter label {
  line-height: 1.4;
}

.jp-NotebookTools .jp-select-wrapper {
  margin-top: 4px;
  margin-bottom: 0;
}

.jp-NumberSetter input {
  width: 100%;
  margin-top: 4px;
}

.jp-NotebookTools .jp-Collapse {
  margin-top: 16px;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Side-by-side Mode (.jp-mod-sideBySide)
|----------------------------------------------------------------------------*/
.jp-mod-sideBySide.jp-Notebook .jp-Notebook-cell {
  margin-top: 3em;
  margin-bottom: 3em;
  margin-left: 5%;
  margin-right: 5%;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell {
  display: grid;
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-output-size)
    );
  grid-template-rows: auto minmax(0, 1fr) auto;
  grid-template-areas:
    'header header header'
    'input handle output'
    'footer footer footer';
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell.jp-mod-resizedCell {
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-resized-cell)
    );
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellHeader {
  grid-area: header;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-inputWrapper {
  grid-area: input;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-outputWrapper {
  /* overwrite the default margin (no vertical separation needed in side by side move */
  margin-top: 0;
  grid-area: output;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellFooter {
  grid-area: footer;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle {
  grid-area: handle;
  user-select: none;
  display: block;
  height: 100%;
  cursor: ew-resize;
  padding: 0 var(--jp-cell-padding);
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle::after {
  content: '';
  display: block;
  background: var(--jp-border-color2);
  height: 100%;
  width: 5px;
}

.jp-mod-sideBySide.jp-Notebook
  .jp-CodeCell.jp-mod-resizedCell
  .jp-CellResizeHandle::after {
  background: var(--jp-border-color0);
}

.jp-CellResizeHandle {
  display: none;
}

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Cell-Placeholder {
  padding-left: 55px;
}

.jp-Cell-Placeholder-wrapper {
  background: #fff;
  border: 1px solid;
  border-color: #e5e6e9 #dfe0e4 #d0d1d5;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  margin: 10px 15px;
}

.jp-Cell-Placeholder-wrapper-inner {
  padding: 15px;
  position: relative;
}

.jp-Cell-Placeholder-wrapper-body {
  background-repeat: repeat;
  background-size: 50% auto;
}

.jp-Cell-Placeholder-wrapper-body div {
  background: #f6f7f8;
  background-image: -webkit-linear-gradient(
    left,
    #f6f7f8 0%,
    #edeef1 20%,
    #f6f7f8 40%,
    #f6f7f8 100%
  );
  background-repeat: no-repeat;
  background-size: 800px 104px;
  height: 104px;
  position: absolute;
  right: 15px;
  left: 15px;
  top: 15px;
}

div.jp-Cell-Placeholder-h1 {
  top: 20px;
  height: 20px;
  left: 15px;
  width: 150px;
}

div.jp-Cell-Placeholder-h2 {
  left: 15px;
  top: 50px;
  height: 10px;
  width: 100px;
}

div.jp-Cell-Placeholder-content-1,
div.jp-Cell-Placeholder-content-2,
div.jp-Cell-Placeholder-content-3 {
  left: 15px;
  right: 15px;
  height: 10px;
}

div.jp-Cell-Placeholder-content-1 {
  top: 100px;
}

div.jp-Cell-Placeholder-content-2 {
  top: 120px;
}

div.jp-Cell-Placeholder-content-3 {
  top: 140px;
}

</style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0 2px 1px -1px var(--jp-shadow-umbra-color),
    0 1px 1px 0 var(--jp-shadow-penumbra-color),
    0 1px 3px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0 3px 1px -2px var(--jp-shadow-umbra-color),
    0 2px 2px 0 var(--jp-shadow-penumbra-color),
    0 1px 5px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0 2px 4px -1px var(--jp-shadow-umbra-color),
    0 4px 5px 0 var(--jp-shadow-penumbra-color),
    0 1px 10px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0 3px 5px -1px var(--jp-shadow-umbra-color),
    0 6px 10px 0 var(--jp-shadow-penumbra-color),
    0 1px 18px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0 5px 5px -3px var(--jp-shadow-umbra-color),
    0 8px 10px 1px var(--jp-shadow-penumbra-color),
    0 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0 7px 8px -4px var(--jp-shadow-umbra-color),
    0 12px 17px 2px var(--jp-shadow-penumbra-color),
    0 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0 8px 10px -5px var(--jp-shadow-umbra-color),
    0 16px 24px 2px var(--jp-shadow-penumbra-color),
    0 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0 10px 13px -6px var(--jp-shadow-umbra-color),
    0 20px 31px 3px var(--jp-shadow-penumbra-color),
    0 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0 11px 15px -7px var(--jp-shadow-umbra-color),
    0 24px 38px 3px var(--jp-shadow-penumbra-color),
    0 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-inverse-border-color: var(--md-grey-600);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;
  --jp-ui-font-family: system-ui, -apple-system, blinkmacsystemfont, 'Segoe UI',
    helvetica, arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;
  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);
  --jp-content-link-color: var(--md-blue-900);
  --jp-content-font-family: system-ui, -apple-system, blinkmacsystemfont,
    'Segoe UI', helvetica, arial, sans-serif, 'Apple Color Emoji',
    'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: menlo, consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-900);
  --jp-brand-color1: var(--md-blue-700);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);
  --jp-accent-color0: var(--md-green-900);
  --jp-accent-color1: var(--md-green-700);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-900);
  --jp-warn-color1: var(--md-orange-700);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);
  --jp-error-color0: var(--md-red-900);
  --jp-error-color1: var(--md-red-700);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);
  --jp-success-color0: var(--md-green-900);
  --jp-success-color1: var(--md-green-700);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);
  --jp-info-color0: var(--md-cyan-900);
  --jp-info-color1: var(--md-cyan-700);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;
  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;
  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);
  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: var(--jp-code-font-family-default);
  --jp-cell-prompt-letter-spacing: 0;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);

  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;

  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Statusbar specific styles */

  --jp-statusbar-height: 24px;

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-inverse-border-color);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: rgb(0, 54, 109);
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #a2f;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #a2f;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /*
    RTC user specific colors.
    These colors are used for the cursor, username in the editor,
    and the icon of the user.
  */

  --jp-collaborator-color1: #ffad8e;
  --jp-collaborator-color2: #dac83d;
  --jp-collaborator-color3: #72dd76;
  --jp-collaborator-color4: #00e4d0;
  --jp-collaborator-color5: #45d4ff;
  --jp-collaborator-color6: #e2b1ff;
  --jp-collaborator-color7: #ff9de6;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 250px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);

  /* Button colors */
  --jp-accept-color-normal: var(--md-blue-700);
  --jp-accept-color-hover: var(--md-blue-800);
  --jp-accept-color-active: var(--md-blue-900);
  --jp-warn-color-normal: var(--md-red-700);
  --jp-warn-color-hover: var(--md-red-800);
  --jp-warn-color-active: var(--md-red-900);
  --jp-reject-color-normal: var(--md-grey-600);
  --jp-reject-color-hover: var(--md-grey-700);
  --jp-reject-color-active: var(--md-grey-800);

  /* File or activity icons and switch semantic variables */
  --jp-jupyter-icon-color: #f37626;
  --jp-notebook-icon-color: #f37626;
  --jp-json-icon-color: var(--md-orange-700);
  --jp-console-icon-background-color: var(--md-blue-700);
  --jp-console-icon-color: white;
  --jp-terminal-icon-background-color: var(--md-grey-800);
  --jp-terminal-icon-color: var(--md-grey-200);
  --jp-text-editor-icon-color: var(--md-grey-700);
  --jp-inspector-icon-color: var(--md-grey-700);
  --jp-switch-color: var(--md-grey-400);
  --jp-switch-true-position-color: var(--md-orange-900);
}
</style>
<style type="text/css">
/* Force rendering true colors when outputing to pdf */
* {
  -webkit-print-color-adjust: exact;
}

/* Misc */
a.anchor-link {
  display: none;
}

/* Input area styling */
.jp-InputArea {
  overflow: hidden;
}

.jp-InputArea-editor {
  overflow: hidden;
}

.cm-editor.cm-s-jupyter .highlight pre {
/* weird, but --jp-code-padding defined to be 5px but 4px horizontal padding is hardcoded for pre.cm-line */
  padding: var(--jp-code-padding) 4px;
  margin: 0;

  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
  color: inherit;

}

.jp-OutputArea-output pre {
  line-height: inherit;
  font-family: inherit;
}

.jp-RenderedText pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
}

/* Hiding the collapser by default */
.jp-Collapser {
  display: none;
}

@page {
    margin: 0.5in; /* Margin for each printed piece of paper */
}

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}
</style>
<!-- Load mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"> </script>
<!-- MathJax configuration -->
<script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                messageStyle: 'none',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
<!-- End of mathjax configuration --><script type="module">
  document.addEventListener("DOMContentLoaded", async () => {
    const diagrams = document.querySelectorAll(".jp-Mermaid > pre.mermaid");
    // do not load mermaidjs if not needed
    if (!diagrams.length) {
      return;
    }
    const mermaid = (await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs")).default;
    const parser = new DOMParser();

    mermaid.initialize({
      maxTextSize: 100000,
      maxEdges: 100000,
      startOnLoad: false,
      fontFamily: window
        .getComputedStyle(document.body)
        .getPropertyValue("--jp-ui-font-family"),
      theme: document.querySelector("body[data-jp-theme-light='true']")
        ? "default"
        : "dark",
    });

    let _nextMermaidId = 0;

    function makeMermaidImage(svg) {
      const img = document.createElement("img");
      const doc = parser.parseFromString(svg, "image/svg+xml");
      const svgEl = doc.querySelector("svg");
      const { maxWidth } = svgEl?.style || {};
      const firstTitle = doc.querySelector("title");
      const firstDesc = doc.querySelector("desc");

      img.setAttribute("src", `data:image/svg+xml,${encodeURIComponent(svg)}`);
      if (maxWidth) {
        img.width = parseInt(maxWidth);
      }
      if (firstTitle) {
        img.setAttribute("alt", firstTitle.textContent);
      }
      if (firstDesc) {
        const caption = document.createElement("figcaption");
        caption.className = "sr-only";
        caption.textContent = firstDesc.textContent;
        return [img, caption];
      }
      return [img];
    }

    async function makeMermaidError(text) {
      let errorMessage = "";
      try {
        await mermaid.parse(text);
      } catch (err) {
        errorMessage = `${err}`;
      }

      const result = document.createElement("details");
      result.className = 'jp-RenderedMermaid-Details';
      const summary = document.createElement("summary");
      summary.className = 'jp-RenderedMermaid-Summary';
      const pre = document.createElement("pre");
      const code = document.createElement("code");
      code.innerText = text;
      pre.appendChild(code);
      summary.appendChild(pre);
      result.appendChild(summary);

      const warning = document.createElement("pre");
      warning.innerText = errorMessage;
      result.appendChild(warning);
      return [result];
    }

    async function renderOneMarmaid(src) {
      const id = `jp-mermaid-${_nextMermaidId++}`;
      const parent = src.parentNode;
      let raw = src.textContent.trim();
      const el = document.createElement("div");
      el.style.visibility = "hidden";
      document.body.appendChild(el);
      let results = null;
      let output = null;
      try {
        let { svg } = await mermaid.render(id, raw, el);
        svg = cleanMermaidSvg(svg);
        results = makeMermaidImage(svg);
        output = document.createElement("figure");
        results.map(output.appendChild, output);
      } catch (err) {
        parent.classList.add("jp-mod-warning");
        results = await makeMermaidError(raw);
        output = results[0];
      } finally {
        el.remove();
      }
      parent.classList.add("jp-RenderedMermaid");
      parent.appendChild(output);
    }


    /**
     * Post-process to ensure mermaid diagrams contain only valid SVG and XHTML.
     */
    function cleanMermaidSvg(svg) {
      return svg.replace(RE_VOID_ELEMENT, replaceVoidElement);
    }


    /**
     * A regular expression for all void elements, which may include attributes and
     * a slash.
     *
     * @see https://developer.mozilla.org/en-US/docs/Glossary/Void_element
     *
     * Of these, only `<br>` is generated by Mermaid in place of `\n`,
     * but _any_ "malformed" tag will break the SVG rendering entirely.
     */
    const RE_VOID_ELEMENT =
      /<\s*(area|base|br|col|embed|hr|img|input|link|meta|param|source|track|wbr)\s*([^>]*?)\s*>/gi;

    /**
     * Ensure a void element is closed with a slash, preserving any attributes.
     */
    function replaceVoidElement(match, tag, rest) {
      rest = rest.trim();
      if (!rest.endsWith('/')) {
        rest = `${rest} /`;
      }
      return `<${tag} ${rest}>`;
    }

    void Promise.all([...diagrams].map(renderOneMarmaid));
  });
</script>
<style>
  .jp-Mermaid:not(.jp-RenderedMermaid) {
    display: none;
  }

  .jp-RenderedMermaid {
    overflow: auto;
    display: flex;
  }

  .jp-RenderedMermaid.jp-mod-warning {
    width: auto;
    padding: 0.5em;
    margin-top: 0.5em;
    border: var(--jp-border-width) solid var(--jp-warn-color2);
    border-radius: var(--jp-border-radius);
    color: var(--jp-ui-font-color1);
    font-size: var(--jp-ui-font-size1);
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .jp-RenderedMermaid figure {
    margin: 0;
    overflow: auto;
    max-width: 100%;
  }

  .jp-RenderedMermaid img {
    max-width: 100%;
  }

  .jp-RenderedMermaid-Details > pre {
    margin-top: 1em;
  }

  .jp-RenderedMermaid-Summary {
    color: var(--jp-warn-color2);
  }

  .jp-RenderedMermaid:not(.jp-mod-warning) pre {
    display: none;
  }

  .jp-RenderedMermaid-Summary > pre {
    display: inline-block;
    white-space: normal;
  }
</style>
<!-- End of mermaid configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">
<main>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="%F0%9F%94%8D-Project-Overview"> Project Overview<a class="anchor-link" href="#%F0%9F%94%8D-Project-Overview"></a></h1><p>This notebook presents a complete end-to-end optimization and deployment pipeline for a GPT-2-style small language model (SLM), with the goal of achieving efficient inference on resource-constrained environments.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="%F0%9F%93%A6-Part-1:-Load-&amp;-Profile-GPT-2-in-FP16-on-GPU-(NVIDIA-T4)"> Part 1: Load &amp; Profile GPT-2 in FP16 on GPU (NVIDIA T4)<a class="anchor-link" href="#%F0%9F%93%A6-Part-1:-Load-&amp;-Profile-GPT-2-in-FP16-on-GPU-(NVIDIA-T4)"></a></h2><ul>
<li><p><strong>Objective</strong>: Load the GPT-2 model with half-precision (FP16) to reduce memory footprint and accelerate inference.</p>
</li>
<li><p><strong>Hardware</strong>: NVIDIA T4 GPU (16 GB GDDR6).</p>
</li>
<li><p><strong>Tasks</strong>:</p>
<ul>
<li>Load a pretrained GPT-2 model using Hugging Face Transformers.</li>
<li>Convert weights to FP16.</li>
<li>Measure baseline performance: latency, throughput, VRAM usage.</li>
<li>Use torch.profiler to generate flame graphs for bottleneck analysis.</li>
</ul>
</li>
</ul>
<h3 id="Environment-Setup">Environment Setup<a class="anchor-link" href="#Environment-Setup"></a></h3><h4 id="Hardware-&amp;-Software-Requirements">Hardware &amp; Software Requirements<a class="anchor-link" href="#Hardware-&amp;-Software-Requirements"></a></h4><ul>
<li>GPU: NVIDIA T4 (16 GB GDDR6 VRAM, 320 GB/s bandwidth, 320 Turing Tensor Cores)</li>
<li>CPU: 2 vCPUs, 4 GB RAM for final inference stage</li>
<li>Python Version:  3.8</li>
<li>Libraries:<ul>
<li>torch</li>
<li>transformers</li>
<li>optimum</li>
<li>datasets</li>
<li>tqdm, matplotlib, and psutil for progress bars, plotting, and memory checks</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Install-the-libraries">Install the libraries<a class="anchor-link" href="#Install-the-libraries"></a></h3><p>We run <code>nvidia-smi</code> to check if GPU is visible and ready to use. We then install the necessary libraries.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[1]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>nvidia-smi
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Tue Dec  9 09:56:24 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.95.05              Driver Version: 580.95.05      CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 3090        On  |   00000000:0B:00.0 Off |                  N/A |
|  0%   37C    P8             18W /  400W |    4558MiB /  24576MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A            2631      G   /usr/lib/xorg/Xorg                       39MiB |
|    0   N/A  N/A            2767      G   /usr/bin/gnome-shell                     12MiB |
|    0   N/A  N/A         1462221      C   ...niconda3/envs/mlmo/bin/python       4470MiB |
+-----------------------------------------------------------------------------------------+
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Logging-into-Huggingface-and-Authincating">Logging into Huggingface and Authincating<a class="anchor-link" href="#Logging-into-Huggingface-and-Authincating"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[2]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dotenv</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">login</span>

<span class="c1"># Load environment variables from .env file</span>
<span class="n">load_dotenv</span><span class="p">()</span>

<span class="n">HF_TOKEN</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">"HF_TOKEN"</span><span class="p">)</span>

<span class="k">if</span> <span class="n">HF_TOKEN</span><span class="p">:</span>
    <span class="n">login</span><span class="p">(</span><span class="n">HF_TOKEN</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Successfully logged in to Hugging Face!"</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Token is not set. Please add HF_TOKEN to your .env file."</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Successfully logged in to Hugging Face!
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Check-for-GPU">Check for GPU<a class="anchor-link" href="#Check-for-GPU"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Check PyTorch GPU availability and VRAM</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"PyTorch Version: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"CUDA Version: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">version</span><span class="o">.</span><span class="n">cuda</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">gpu_name</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">total_mem</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_properties</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">total_memory</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"CUDA Device: </span><span class="si">{</span><span class="n">gpu_name</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Total GPU VRAM: </span><span class="si">{</span><span class="n">total_mem</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> GB"</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">"CUDA GPU not available! Ensure a T4 is attached."</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>PyTorch Version: 2.7.1+cu128
CUDA Version: 12.8
CUDA Device: NVIDIA GeForce RTX 3090
Total GPU VRAM: 23.55 GB
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p><strong>Expected Output</strong></p>
<pre><code>PyTorch Version: 2.7.1+cu128
CUDA Version: 12.8
CUDA Device: NVIDIA GeForce RTX 3090
Total GPU VRAM: 23.55 GB
</code></pre>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Load-GPT2-&amp;-Tokenizer">Load GPT2 &amp; Tokenizer<a class="anchor-link" href="#Load-GPT2-&amp;-Tokenizer"></a></h3><p>Loads a GPT-2 model and tokenizer in FP16 precision and moves the model to the appropriate device.</p>
<pre><code>How to implement:
- Use the `transformers` library to load the tokenizer and model using the provided model ID.
- Set the model's data type to FP16 (float16).
- Use `torch` to detect whether a CUDA-compatible GPU is available.
- Move the model to the selected device (GPU if available, else CPU).
- Return both the tokenizer and model.

Args:
    model_id (str): The model name or path to load from Hugging Face (default: "gpt2").

Returns:
    tuple: A tuple containing the tokenizer and the model.</code></pre>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[4]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">GPT2LMHeadModel</span><span class="p">,</span> <span class="n">GPT2Tokenizer</span>

<span class="k">def</span><span class="w"> </span><span class="nf">load_fp16_model</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="s2">"gpt2"</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Loads a GPT-2 model and tokenizer in FP16 precision and moves the model to the appropriate device.</span>

<span class="sd">    How to implement:</span>
<span class="sd">    - Use the `transformers` library to load the tokenizer and model using the provided model ID.</span>
<span class="sd">    - Set the model's data type to FP16 (float16).</span>
<span class="sd">    - Use `torch` to detect whether a CUDA-compatible GPU is available.</span>
<span class="sd">    - Move the model to the selected device (GPU if available, else CPU).</span>
<span class="sd">    - Return both the tokenizer and model.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_id (str): The model name or path to load from Hugging Face (default: "gpt2").</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple: A tuple containing the tokenizer and the model.</span>
<span class="sd">    """</span>
    <span class="c1"># Load tokenizer</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">GPT2Tokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">)</span>
    
    <span class="c1"># Set pad token to eos token (GPT-2 doesn't have a pad token by default)</span>
    <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
    
    <span class="c1"># Load model and convert to FP16</span>
    <span class="c1"># Use eager attention implementation for compatibility with head pruning</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">GPT2LMHeadModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="n">model_id</span><span class="p">,</span> 
        <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span>
        <span class="n">attn_implementation</span><span class="o">=</span><span class="s2">"eager"</span>
    <span class="p">)</span>
    
    <span class="c1"># Set pad_token_id in model config</span>
    <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span>
    
    <span class="c1"># Detect device and move model</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Loaded model '</span><span class="si">{</span><span class="n">model_id</span><span class="si">}</span><span class="s2">' in FP16 on </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">model</span>

<span class="c1"># Load the model and tokenizer</span>
<span class="n">tokenizer</span><span class="p">,</span> <span class="n">model</span> <span class="o">=</span> <span class="n">load_fp16_model</span><span class="p">(</span><span class="s2">"gpt2"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Loaded model 'gpt2' in FP16 on cuda
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Lets-write-a-test-case-to-see-if-we-have-successfully-loaded-the-model.-Run-the-below-cell.-Do-not-change-anything">Lets write a test case to see if we have successfully loaded the model. Run the below cell. <strong>Do not change anything</strong><a class="anchor-link" href="#Lets-write-a-test-case-to-see-if-we-have-successfully-loaded-the-model.-Run-the-below-cell.-Do-not-change-anything"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[5]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">test_load_fp16_model</span><span class="p">():</span>
    <span class="c1"># Simple test prompt</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="s2">"The future of AI is"</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Generate text</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">],</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">inputs</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">],</span>
            <span class="n">max_length</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
            <span class="n">do_sample</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">pad_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
        <span class="p">)</span>

    <span class="c1"># Decode output</span>
    <span class="n">generated_text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">=== Test Output ==="</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Prompt:"</span><span class="p">,</span> <span class="n">prompt</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Generated:"</span><span class="p">,</span> <span class="n">generated_text</span><span class="p">)</span>

    <span class="c1"># Basic correctness checks</span>
    <span class="k">assert</span> <span class="n">model</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span> <span class="s2">"Model is not in FP16"</span>
    <span class="k">assert</span> <span class="nb">str</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">==</span> <span class="nb">str</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="s2">"Model and input are on different devices"</span>
    <span class="k">assert</span> <span class="n">prompt</span> <span class="ow">in</span> <span class="n">generated_text</span><span class="p">,</span> <span class="s2">"Generated text does not include the prompt"</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Test passed "</span><span class="p">)</span>


<span class="n">test_load_fp16_model</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>
=== Test Output ===
Prompt: The future of AI is
Generated: The future of AI is uncertain. The future of AI is uncertain.

The future of AI

Test passed 
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="You-should-see-an-output-like-this">You should see an output like this<a class="anchor-link" href="#You-should-see-an-output-like-this"></a></h4><p>Loaded model 'gpt2' in FP16 on cuda</p>
<p>=== Test Output ===
Prompt: The future of AI is
Generated: The future of AI is uncertain.</p>
<p>The future of AI is uncertain.</p>
<p>The future</p>
<p>Test passed </p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Load-WikiTest-2-Dataset">Load WikiTest-2 Dataset<a class="anchor-link" href="#Load-WikiTest-2-Dataset"></a></h3><p>Loads a small subset of the WikiText-2 dataset for training and validation.</p>
<pre><code>How to implement:
- Use the `load_dataset` function from the `datasets` library.
- Load the "wikitext-2-raw-v1" dataset.
- Specify the split using slice notation strings (e.g., "train[:100]").
- Return both the training and validation subsets.
- Optionally, print how many examples are loaded in each split.

Args:
    train_split (str): Slice of the training data to load.
    valid_split (str): Slice of the validation data to load.

Returns:
    tuple: A tuple containing the training and validation datasets.</code></pre>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>

<span class="k">def</span><span class="w"> </span><span class="nf">load_wikitext_dataset</span><span class="p">(</span><span class="n">train_split</span><span class="o">=</span><span class="s2">"train[:100]"</span><span class="p">,</span> <span class="n">valid_split</span><span class="o">=</span><span class="s2">"validation[:200]"</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Loads a small subset of the WikiText-2 dataset for training and validation.</span>

<span class="sd">    How to implement:</span>
<span class="sd">    - Use the `load_dataset` function from the `datasets` library.</span>
<span class="sd">    - Load the "wikitext-2-raw-v1" dataset.</span>
<span class="sd">    - Specify the split using slice notation strings (e.g., "train[:100]").</span>
<span class="sd">    - Return both the training and validation subsets.</span>
<span class="sd">    - Optionally, print how many examples are loaded in each split.</span>

<span class="sd">    Args:</span>
<span class="sd">        train_split (str): Slice of the training data to load.</span>
<span class="sd">        valid_split (str): Slice of the validation data to load.</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple: A tuple containing the training and validation datasets.</span>
<span class="sd">    """</span>
    <span class="c1"># Load training and validation subsets</span>
    <span class="n">train_ds</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"wikitext"</span><span class="p">,</span> <span class="s2">"wikitext-2-raw-v1"</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="n">train_split</span><span class="p">)</span>
    <span class="n">valid_ds</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"wikitext"</span><span class="p">,</span> <span class="s2">"wikitext-2-raw-v1"</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="n">valid_split</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Loaded </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_ds</span><span class="p">)</span><span class="si">}</span><span class="s2"> training examples"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Loaded </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">valid_ds</span><span class="p">)</span><span class="si">}</span><span class="s2"> validation examples"</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">train_ds</span><span class="p">,</span> <span class="n">valid_ds</span>

<span class="c1"># Load the datasets</span>
<span class="n">train_ds</span><span class="p">,</span> <span class="n">valid_ds</span> <span class="o">=</span> <span class="n">load_wikitext_dataset</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Loaded 100 training examples
Loaded 200 validation examples
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Lets-write-a-test-case-to-see-if-we-have-successfully-loaded-the-dataset.-Run-the-below-cell.-Do-not-change-anything">Lets write a test case to see if we have successfully loaded the dataset. Run the below cell. <strong>Do not change anything</strong><a class="anchor-link" href="#Lets-write-a-test-case-to-see-if-we-have-successfully-loaded-the-dataset.-Run-the-below-cell.-Do-not-change-anything"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[7]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">test_load_wikitext_dataset</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">=== Sample Examples ==="</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Train[0]:"</span><span class="p">,</span> <span class="n">train_ds</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s1">'text'</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Valid[0]:"</span><span class="p">,</span> <span class="n">valid_ds</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s1">'text'</span><span class="p">])</span>

    <span class="c1"># Checks</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_ds</span><span class="p">)</span> <span class="o">==</span> <span class="mi">100</span><span class="p">,</span> <span class="s2">"Train dataset does not contain 100000 samples"</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_ds</span><span class="p">)</span> <span class="o">==</span> <span class="mi">200</span><span class="p">,</span> <span class="s2">"Validation dataset does not contain 200 samples"</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">train_ds</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">'text'</span><span class="p">],</span> <span class="nb">str</span><span class="p">),</span> <span class="s2">"Train sample is not a string"</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">valid_ds</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">'text'</span><span class="p">],</span> <span class="nb">str</span><span class="p">),</span> <span class="s2">"Validation sample is not a string"</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Test passed "</span><span class="p">)</span>

<span class="n">test_load_wikitext_dataset</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>
=== Sample Examples ===
Train[0]:  = Valkyria Chronicles III = 

Valid[0]:  = Homarus gammarus = 


Test passed 
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="You-should-see-an-output-something-like-this">You should see an output something like this<a class="anchor-link" href="#You-should-see-an-output-something-like-this"></a></h4><p>=== Sample Examples === <br/>
Train[0]:  = Valkyria Chronicles III =</p>
<p>Valid[0]:  = Homarus gammarus =</p>
<p>Test passed </p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Baseline-FP16-GPU-Profiling">Baseline FP16 GPU Profiling<a class="anchor-link" href="#Baseline-FP16-GPU-Profiling"></a></h3><p>Measures the average inference latency on GPU in milliseconds per token.</p>
<pre><code>How to implement:
1. Set the device using `torch.device`, based on CUDA availability.
2. Put the model in evaluation mode using `.eval()`.
3. Tokenize the input prompt and move it to the GPU.
4. Perform a short warm-up generation (e.g., 10 tokens) to stabilize performance.
5. Use `time.time()` to measure how long it takes to generate `max_new_tokens`.
6. Use `torch.cuda.synchronize()` before and after timing to ensure accurate GPU measurements.
7. Return the average time per token (in ms) by dividing elapsed time by `max_new_tokens`.

Args:
    model: A causal language model loaded on GPU.
    tokenizer: The tokenizer used for encoding the input prompt.
    prompt (str): The prompt string for text generation.
    max_new_tokens (int): Number of tokens to generate during measurement.

Returns:
    float: Latency in milliseconds per generated token.</code></pre>
<p>Below this cell, implement <code>measure_latency_gpu(...)</code> step by step following the docstring hints.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[8]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm.auto</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.profiler</span><span class="w"> </span><span class="kn">import</span> <span class="n">profile</span><span class="p">,</span> <span class="n">record_function</span><span class="p">,</span> <span class="n">ProfilerActivity</span>

<span class="k">def</span><span class="w"> </span><span class="nf">measure_latency_gpu</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">prompt</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Measures the average inference latency on GPU in milliseconds per token.</span>
<span class="sd">    How to implement:</span>
<span class="sd">    </span>
<span class="sd">    1. Set the device using `torch.device`, based on CUDA availability.</span>
<span class="sd">    2. Put the model in evaluation mode using `.eval()`.</span>
<span class="sd">    3. Tokenize the input prompt and move it to the GPU.</span>
<span class="sd">    4. Perform a short warm-up generation (e.g., 10 tokens) to stabilize performance.</span>
<span class="sd">    5. Use `time.time()` to measure how long it takes to generate `max_new_tokens`.</span>
<span class="sd">    6. Use `torch.cuda.synchronize()` before and after timing to ensure accurate GPU measurements.</span>
<span class="sd">    7. Return the average time per token (in ms) by dividing elapsed time by `max_new_tokens`.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: A causal language model loaded on GPU.</span>
<span class="sd">        tokenizer: The tokenizer used for encoding the input prompt.</span>
<span class="sd">        prompt (str): The prompt string for text generation.</span>
<span class="sd">        max_new_tokens (int): Number of tokens to generate during measurement.</span>

<span class="sd">    Returns:</span>
<span class="sd">        float: Latency in milliseconds per generated token.</span>
<span class="sd">    """</span>
    <span class="c1"># 1. Set the device</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
    
    <span class="c1"># 2. Put the model in evaluation mode</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    
    <span class="c1"># 3. Tokenize the input prompt and move to device</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    
    <span class="c1"># 4. Warm-up generation</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">],</span> 
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">inputs</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">],</span>
            <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
            <span class="n">do_sample</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">pad_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
        <span class="p">)</span>
    
    <span class="c1"># 5-6. Measure generation time with proper synchronization</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">],</span> 
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">inputs</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">],</span>
            <span class="n">max_new_tokens</span><span class="o">=</span><span class="n">max_new_tokens</span><span class="p">,</span> 
            <span class="n">do_sample</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">pad_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
        <span class="p">)</span>
    
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
    <span class="n">elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
    
    <span class="c1"># 7. Return average time per token in ms</span>
    <span class="n">latency_per_token</span> <span class="o">=</span> <span class="p">(</span><span class="n">elapsed</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">)</span> <span class="o">/</span> <span class="n">max_new_tokens</span>
    <span class="k">return</span> <span class="n">latency_per_token</span>

<span class="c1"># Measure latency using the same token-by-token loop</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="s2">"The future of AI is"</span>
<span class="n">max_new_tokens</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">baseline_latency</span> <span class="o">=</span> <span class="n">measure_latency_gpu</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">prompt</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
<span class="n">elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
<span class="n">latency_per_token</span> <span class="o">=</span> <span class="p">(</span><span class="n">elapsed</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">)</span> <span class="o">/</span> <span class="n">max_new_tokens</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Greedy Generation with Progress: </span><span class="si">{</span><span class="n">latency_per_token</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> ms/token"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Greedy Generation with Progress: 6.70 ms/token
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Next,-lets-measure-the-Perplexity,-the-following-function-computes-the-perplexity-of-a-language-model-on-a-given-dataset.">Next, lets measure the Perplexity, the following function computes the perplexity of a language model on a given dataset.<a class="anchor-link" href="#Next,-lets-measure-the-Perplexity,-the-following-function-computes-the-perplexity-of-a-language-model-on-a-given-dataset."></a></h4><pre><code>How to implement:
1. Set the device using `torch.device`, based on CUDA availability.
2. Put the model in evaluation mode using `.eval()`.
3. Loop through each example in the dataset.
4. For each example:
    - Skip if the text is empty or just whitespace.
    - Tokenize the text with truncation (max length = 512).
    - Move input tensors to the appropriate device and ensure their dtype is Long.
    - Set `labels = input_ids` to compute loss for causal LM.
    - Perform a forward pass under `torch.no_grad()` to get the loss.
    - Accumulate the total loss scaled by the sequence length.
5. After the loop, divide total loss by the total number of tokens.
6. Return the exponential of the average loss as perplexity.
   (Avoid division by zero if all texts are skipped.)

Args:
    model: A pretrained causal language model.
    tokenizer: Corresponding tokenizer for the model.
    dataset: A Hugging Face dataset containing a "text" field.

Returns:
    float: The perplexity score (exp of average loss per token).</code></pre>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[9]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span>

<span class="k">def</span><span class="w"> </span><span class="nf">compute_perplexity</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Computes the perplexity of a language model on a given dataset.</span>

<span class="sd">    How to implement:</span>
<span class="sd">    1. Set the device using `torch.device`, based on CUDA availability.</span>
<span class="sd">    2. Put the model in evaluation mode using `.eval()`.</span>
<span class="sd">    3. Loop through each example in the dataset.</span>
<span class="sd">    4. For each example:</span>
<span class="sd">        - Skip if the text is empty or just whitespace.</span>
<span class="sd">        - Tokenize the text with truncation (max length = 512).</span>
<span class="sd">        - Move input tensors to the appropriate device and ensure their dtype is Long.</span>
<span class="sd">        - Set `labels = input_ids` to compute loss for causal LM.</span>
<span class="sd">        - Perform a forward pass under `torch.no_grad()` to get the loss.</span>
<span class="sd">        - Accumulate the total loss scaled by the sequence length.</span>
<span class="sd">    5. After the loop, divide total loss by the total number of tokens.</span>
<span class="sd">    6. Return the exponential of the average loss as perplexity.</span>
<span class="sd">       (Avoid division by zero if all texts are skipped.)</span>

<span class="sd">    Args:</span>
<span class="sd">        model: A pretrained causal language model.</span>
<span class="sd">        tokenizer: Corresponding tokenizer for the model.</span>
<span class="sd">        dataset: A Hugging Face dataset containing a "text" field.</span>

<span class="sd">    Returns:</span>
<span class="sd">        float: The perplexity score (exp of average loss per token).</span>
<span class="sd">    """</span>
    <span class="c1"># 1. Set the device</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
    
    <span class="c1"># 2. Put the model in evaluation mode</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    
    <span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">total_tokens</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="c1"># 3. Loop through each example in the dataset</span>
    <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">example</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]</span>
        
        <span class="c1"># 4a. Skip empty or whitespace-only text</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">text</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
            <span class="k">continue</span>
        
        <span class="c1"># 4b. Tokenize with truncation</span>
        <span class="n">encodings</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>
        
        <span class="c1"># Skip if no tokens</span>
        <span class="k">if</span> <span class="n">encodings</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">continue</span>
        
        <span class="c1"># 4c. Move to device and ensure Long dtype</span>
        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">encodings</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
        
        <span class="c1"># 4d. Set labels = input_ids for causal LM loss</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        
        <span class="c1"># 4e. Forward pass under no_grad</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">loss</span>
        
        <span class="c1"># 4f. Accumulate loss scaled by sequence length</span>
        <span class="n">seq_len</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">seq_len</span>
        <span class="n">total_tokens</span> <span class="o">+=</span> <span class="n">seq_len</span>
    
    <span class="c1"># 5-6. Compute and return perplexity</span>
    <span class="k">if</span> <span class="n">total_tokens</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="s2">"inf"</span><span class="p">)</span>
    
    <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">total_tokens</span>
    <span class="n">perplexity</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">avg_loss</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">perplexity</span>

<span class="n">baseline_ppl</span> <span class="o">=</span> <span class="n">compute_perplexity</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">valid_ds</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Baseline FP16 GPU Perplexity: </span><span class="si">{</span><span class="n">baseline_ppl</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Baseline FP16 GPU Perplexity: 40.04
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Lets-call-the-mdoel.generate-function-to-see-the--VRAM-usage">Lets call the <code>mdoel.generate</code> function to see the  VRAM usage<a class="anchor-link" href="#Lets-call-the-mdoel.generate-function-to-see-the--VRAM-usage"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[10]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 3. Check peak GPU memory usage</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">tokenizer</span><span class="p">(</span><span class="s2">"warm up"</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">pad_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">)</span>
<span class="n">peak_vram</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">max_memory_allocated</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Baseline FP16 GPU Peak VRAM: </span><span class="si">{</span><span class="n">peak_vram</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> GB"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Baseline FP16 GPU Peak VRAM: 0.36 GB
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Lets-generate-a-flame-graph-and-visualize-it-using-Tensorboard">Lets generate a flame graph and visualize it using Tensorboard<a class="anchor-link" href="#Lets-generate-a-flame-graph-and-visualize-it-using-Tensorboard"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[11]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.profiler</span><span class="w"> </span><span class="kn">import</span> <span class="n">profile</span><span class="p">,</span> <span class="n">record_function</span><span class="p">,</span> <span class="n">ProfilerActivity</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.profiler</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensorboard_trace_handler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datetime</span><span class="w"> </span><span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>

<span class="k">def</span><span class="w"> </span><span class="nf">profile_model_for_tensorboard</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">prompt</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">log_dir</span><span class="o">=</span><span class="s2">"tb_logs"</span><span class="p">,</span> <span class="n">run_name</span><span class="o">=</span><span class="s2">"pruned_fp16"</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Profiles the inference of a PyTorch model and saves a trace for visualization in TensorBoard.</span>

<span class="sd">    Args:</span>
<span class="sd">        model (torch.nn.Module): The PyTorch model to profile.</span>
<span class="sd">        tokenizer: The tokenizer used to process the prompt.</span>
<span class="sd">        prompt (str): The input prompt string for model inference.</span>
<span class="sd">        device (str or torch.device): Device to run the model on ("cuda" or "cpu").</span>
<span class="sd">        log_dir (str): Directory where TensorBoard logs will be saved.</span>
<span class="sd">        run_name (str): Subdirectory name for this profiling run.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None. Writes profiling logs to disk and prints the save location.</span>

<span class="sd">    TODO:</span>
<span class="sd">        1. Tokenize the input prompt and move it to the specified device.</span>
<span class="sd">        2. Use `torch.profiler.profile()` to record inference performance.</span>
<span class="sd">        3. Export profiling data in TensorBoard-compatible format using `tensorboard_trace_handler`.</span>
<span class="sd">    """</span>
    <span class="c1"># Create log directory</span>
    <span class="n">log_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">log_dir</span><span class="p">,</span> <span class="n">run_name</span><span class="p">)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">log_path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="c1"># 1. Tokenize the input prompt and move to device</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    
    <span class="c1"># 2-3. Use torch.profiler to record inference and export to TensorBoard</span>
    <span class="k">with</span> <span class="n">profile</span><span class="p">(</span>
        <span class="n">activities</span><span class="o">=</span><span class="p">[</span><span class="n">ProfilerActivity</span><span class="o">.</span><span class="n">CPU</span><span class="p">,</span> <span class="n">ProfilerActivity</span><span class="o">.</span><span class="n">CUDA</span><span class="p">],</span>
        <span class="n">record_shapes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">profile_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">on_trace_ready</span><span class="o">=</span><span class="n">tensorboard_trace_handler</span><span class="p">(</span><span class="n">log_path</span><span class="p">)</span>
    <span class="p">)</span> <span class="k">as</span> <span class="n">prof</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">record_function</span><span class="p">(</span><span class="s2">"model_inference"</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
                    <span class="n">inputs</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">],</span> 
                    <span class="n">attention_mask</span><span class="o">=</span><span class="n">inputs</span><span class="p">[</span><span class="s2">"attention_mask"</span><span class="p">],</span>
                    <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
                    <span class="n">do_sample</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">pad_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
                <span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Profiling logs saved to: </span><span class="si">{</span><span class="n">log_path</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">profile_model_for_tensorboard</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="s2">"The future of AI is"</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">"cuda"</span><span class="p">,</span> <span class="n">run_name</span><span class="o">=</span><span class="s2">"baseline_fp16"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Profiling logs saved to: tb_logs/baseline_fp16
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="We-will-also-do-a-profiler-trace-to-measure-the-baseline-inference">We will also do a profiler trace to measure the baseline inference<a class="anchor-link" href="#We-will-also-do-a-profiler-trace-to-measure-the-baseline-inference"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[12]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 4. Rrecord a torch.profiler trace for baseline inference</span>
<span class="k">with</span> <span class="n">profile</span><span class="p">(</span><span class="n">activities</span><span class="o">=</span><span class="p">[</span><span class="n">ProfilerActivity</span><span class="o">.</span><span class="n">CUDA</span><span class="p">],</span> <span class="n">record_shapes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">prof</span><span class="p">:</span>
    <span class="k">with</span> <span class="n">record_function</span><span class="p">(</span><span class="s2">"baseline_fp16_inference"</span><span class="p">):</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">pad_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">)</span>
<span class="n">prof</span><span class="o">.</span><span class="n">export_chrome_trace</span><span class="p">(</span><span class="s2">"baseline_fp16_trace.json"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Exported baseline_fp16_trace.json"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Exported baseline_fp16_trace.json
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="%E2%9C%82%EF%B8%8F-Part-2:-Structured-Attention-Head-Pruning-&amp;-Fine-Tuning"> Part 2: Structured Attention Head Pruning &amp; Fine-Tuning<a class="anchor-link" href="#%E2%9C%82%EF%B8%8F-Part-2:-Structured-Attention-Head-Pruning-&amp;-Fine-Tuning"></a></h2><p><strong>Objective:</strong> Reduce the number of parameters by pruning redundant attention heads while maintaining accuracy.</p>
<p><strong>Methodology:</strong></p>
<pre><code>- Prune a fixed percentage (e.g., 20%) of attention heads per layer.
- Fine-tune the pruned model on a small corpus to recover lost performance.</code></pre>
<ul>
<li><p><strong>Metrics Tracked:</strong></p>
<ul>
<li>Change in latency and memory usage.</li>
<li>Perplexity before and after fine-tuning.</li>
</ul>
</li>
</ul>
<h2 id="How-do-we-Prune-it?">How do we Prune it?<a class="anchor-link" href="#How-do-we-Prune-it?"></a></h2><ol>
<li>Prune 25 % of Heads in GPT-2
GPT-2 architecture:</li>
</ol>
<ul>
<li>Hidden size: 768</li>
<li>Layers: 12 transformer blocks</li>
<li>Heads per layer: 12</li>
<li>Total heads: 12  12 = 144</li>
</ul>
<p>Pruning plan:</p>
<ul>
<li><p>25 % of heads  0.25  12 = 3 heads removed per layer</p>
</li>
<li><p>Remaining heads: 12  3 = 9 per layer  9  12 = 108 total heads</p>
</li>
<li><p>Rough parameter reduction:</p>
<ul>
<li>GPT-2 has ~117 M parameters overall</li>
<li>Attention-head weights constitute 15 % of that (~17 M)</li>
<li>Removing 25 % of head parameters cuts ~4 M weights  new model size 113 M (3 % total reduction)</li>
</ul>
</li>
</ul>
<p> Why head pruning?</p>
<ul>
<li>Multi-head attention learns some heads that contribute very littlepruning them can cut compute and memory.</li>
<li>Warm-up and inference speed improve (often 1020 %), with only minor losses in perplexity.</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[13]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">prune_attention_heads</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">prune_fraction</span><span class="o">=</span><span class="mf">0.2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Prunes a fraction of attention heads from each layer of the model and casts it back to FP16.</span>

<span class="sd">    How to implement:</span>
<span class="sd">    1. Retrieve the number of transformer layers and the number of attention heads per layer</span>
<span class="sd">       using the models configuration (e.g., `model.config.n_layer` and `model.config.n_head`).</span>
<span class="sd">    2. Compute how many heads to prune per layer (e.g., 20% of total heads).</span>
<span class="sd">    3. Construct a dictionary where each key is a layer index, and the value is a list of</span>
<span class="sd">       head indices to prune in that layer (e.g., [0, 1, 2, 3]).</span>
<span class="sd">    4. Call the `prune_heads()` method on `model.base_model` and pass the dictionary.</span>
<span class="sd">    5. After pruning, cast the model back to `float16` using `.half()` to reduce memory usage.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: The transformer-based model with attention heads to prune.</span>
<span class="sd">        prune_fraction (float): The fraction of heads to prune per layer (default is 0.2 for 20%).</span>

<span class="sd">    Returns:</span>
<span class="sd">        The pruned model in float16.</span>
<span class="sd">    """</span>
    <span class="c1"># 1. Get number of layers and heads per layer</span>
    <span class="n">n_layer</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">n_layer</span>
    <span class="n">n_head</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">n_head</span>
    
    <span class="c1"># 2. Compute how many heads to prune per layer</span>
    <span class="n">heads_to_prune</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_head</span> <span class="o">*</span> <span class="n">prune_fraction</span><span class="p">)</span>
    
    <span class="c1"># 3. Construct dictionary of heads to prune per layer</span>
    <span class="n">heads_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">layer_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layer</span><span class="p">):</span>
        <span class="c1"># Prune the first 'heads_to_prune' heads in each layer</span>
        <span class="n">heads_dict</span><span class="p">[</span><span class="n">layer_idx</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">heads_to_prune</span><span class="p">))</span>
    
    <span class="c1"># 4. Call prune_heads on the base model</span>
    <span class="n">model</span><span class="o">.</span><span class="n">base_model</span><span class="o">.</span><span class="n">prune_heads</span><span class="p">(</span><span class="n">heads_dict</span><span class="p">)</span>
    
    <span class="c1"># 5. Cast model back to float16</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">half</span><span class="p">()</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Pruned </span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">prune_fraction</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="p">)</span><span class="si">}</span><span class="s2">% of heads per layer"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">prune_attention_heads</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Pruned 20% of heads per layer
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Lets-write-a-test-case-to-see-if-we-have-successfully-pruned-the-model.-Run-the-below-cell.-Do-not-change-anything">Lets write a test case to see if we have successfully pruned the model. Run the below cell. Do not change anything<a class="anchor-link" href="#Lets-write-a-test-case-to-see-if-we-have-successfully-pruned-the-model.-Run-the-below-cell.-Do-not-change-anything"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[14]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">GPT2LMHeadModel</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_prune_attention_heads</span><span class="p">():</span>
    <span class="c1"># 1) Load GPT-2 small in FP16</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">GPT2LMHeadModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"gpt2"</span><span class="p">)</span><span class="o">.</span><span class="n">half</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">"cpu"</span><span class="p">)</span>
    
    <span class="n">orig_n_head</span>  <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">n_head</span>    <span class="c1"># 12</span>
    <span class="n">orig_n_layer</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">n_layer</span>   <span class="c1"># 12</span>
    <span class="n">prune_fraction</span> <span class="o">=</span> <span class="mf">0.2</span>                  <span class="c1"># 20%</span>
    <span class="n">heads_pruned</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">orig_n_head</span> <span class="o">*</span> <span class="n">prune_fraction</span><span class="p">)</span>  <span class="c1"># floor(12 * 0.2) = 2</span>
    <span class="n">expected_heads</span> <span class="o">=</span> <span class="n">orig_n_head</span> <span class="o">-</span> <span class="n">heads_pruned</span>       <span class="c1"># 12 - 2 = 10</span>
    
    <span class="c1"># 2) Apply pruning</span>
    <span class="n">pruned_model</span> <span class="o">=</span> <span class="n">prune_attention_heads</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">prune_fraction</span><span class="o">=</span><span class="n">prune_fraction</span><span class="p">)</span>
    
    <span class="c1"># 3) All params still float16</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">pruned_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span> <span class="s2">" Parameter not in float16"</span>
    
    <span class="c1"># 4) Check each layers Attention module</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">orig_n_layer</span><span class="p">):</span>
        <span class="n">attn</span> <span class="o">=</span> <span class="n">pruned_model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">attn</span>
        
        <span class="c1"># num_heads should be reduced</span>
        <span class="k">assert</span> <span class="n">attn</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">==</span> <span class="n">expected_heads</span><span class="p">,</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">"Layer </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> has </span><span class="si">{</span><span class="n">attn</span><span class="o">.</span><span class="n">num_heads</span><span class="si">}</span><span class="s2"> heads, expected </span><span class="si">{</span><span class="n">expected_heads</span><span class="si">}</span><span class="s2">"</span>
        <span class="p">)</span>
        
        <span class="c1"># pruned_heads set should match {0, 1, , heads_pruned-1}</span>
        <span class="k">assert</span> <span class="n">attn</span><span class="o">.</span><span class="n">pruned_heads</span> <span class="o">==</span> <span class="nb">set</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">heads_pruned</span><span class="p">)),</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">"Layer </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> pruned </span><span class="si">{</span><span class="n">attn</span><span class="o">.</span><span class="n">pruned_heads</span><span class="si">}</span><span class="s2">, expected </span><span class="si">{</span><span class="nb">set</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">heads_pruned</span><span class="p">))</span><span class="si">}</span><span class="s2">"</span>
        <span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s2">"test_prune_attention_heads passed "</span><span class="p">)</span>

<span class="c1"># Run it</span>
<span class="n">test_prune_attention_heads</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Pruned 20% of heads per layer
test_prune_attention_heads passed 
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="You-should-see-an-output-something-like-this">You should see an output something like this<a class="anchor-link" href="#You-should-see-an-output-something-like-this"></a></h4><p>Pruned 20% of heads per layer<br/>
test_prune_attention_heads passed </p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="How-do-we-Fine-Tune-the-Pruned-Model-for-1-Epoch-:">How do we Fine-Tune the Pruned Model for 1 Epoch :<a class="anchor-link" href="#How-do-we-Fine-Tune-the-Pruned-Model-for-1-Epoch-:"></a></h3><p>Here we will:</p>
<ol>
<li><p><strong>Configure the tokenizer &amp; model</strong></p>
<ul>
<li>Reuse the EOS token for padding so that causal LM padding behaves correctly.</li>
<li>Ensure <code>pad_token_id</code> is set in both the tokenizer and model config.</li>
</ul>
</li>
<li><p><strong>Prepare the data</strong></p>
<ul>
<li>Tokenize and truncate each example to a fixed length (max 512 tokens).</li>
<li>Copy the inputs to <code>labels</code> for next-token prediction.</li>
<li>Use <code>DataCollatorForLanguageModeling</code> (with <code>mlm=False</code>) to dynamically batch sequences for causal LM.</li>
</ul>
</li>
<li><p><strong>Set up training arguments</strong></p>
<ul>
<li>Disable external logging (<code>WANDB_DISABLED</code> and <code>report_to="none"</code>).</li>
<li>Choose hyperparameters: epochs, batch size, learning rate, logging frequency.</li>
<li>Enable FP16 training via <code>fp16=True</code> under the hood.</li>
</ul>
</li>
<li><p><strong>Handle precision &amp; device placement</strong></p>
<ul>
<li>Cast the pruned model back to FP32 (<code>model.float()</code>) before handing off to the Trainer.</li>
<li>Let the Trainer automatically manage FP16 conversion, gradient scaling, and device transfers.</li>
</ul>
</li>
<li><p><strong>Launch training</strong></p>
<ul>
<li>Instantiate a <code>Trainer</code> with the pruned model, tokenized dataset, and collator.</li>
<li>Call <code>trainer.train()</code> to fine-tune on your custom text split.</li>
</ul>
</li>
</ol>
<blockquote>
<p> <strong>Learning Objectives</strong></p>
<ul>
<li>See how to integrate pruned models into a standard  Trainer workflow</li>
<li>Understand padding for causal LMs and label shifting</li>
<li>Observe mixed-precision training setup and benefits</li>
</ul>
</blockquote>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[15]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Trainer</span><span class="p">,</span> <span class="n">TrainingArguments</span><span class="p">,</span> <span class="n">DataCollatorForLanguageModeling</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span> <span class="c1"># Import torch explicitly</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"WANDB_DISABLED"</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"true"</span>

<span class="k">def</span><span class="w"> </span><span class="nf">prepare_tokenizer_for_padding</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Prepares the tokenizer and model for consistent padding behavior during fine-tuning.</span>

<span class="sd">    How to implement:</span>
<span class="sd">    - Set the tokenizer's pad token to be the same as its end-of-sequence (eos) token.</span>
<span class="sd">    - Update the model's configuration to use this same pad token ID.</span>

<span class="sd">    Args:</span>
<span class="sd">        tokenizer: The Hugging Face tokenizer.</span>
<span class="sd">        model: The language model whose config needs to be updated.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None (modifies tokenizer and model in-place)</span>
<span class="sd">    """</span>
    <span class="c1"># Set pad token to eos token</span>
    <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
    
    <span class="c1"># Update model config with pad token id</span>
    <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Set pad_token to: </span><span class="si">{</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[16]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">tokenize_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Tokenizes a dataset of text examples for causal language modeling.</span>

<span class="sd">    How to implement:</span>
<span class="sd">    - Use `tokenizer` to tokenize the "text" field.</span>
<span class="sd">    - Truncate examples to a maximum length (e.g., 512 tokens).</span>
<span class="sd">    - Pad sequences using max length.</span>
<span class="sd">    - Copy `input_ids` to a new key `labels` for causal language modeling.</span>
<span class="sd">    - Remove the raw "text" column from the result.</span>

<span class="sd">    Args:</span>
<span class="sd">        dataset: Hugging Face Dataset containing a "text" field.</span>
<span class="sd">        tokenizer: The tokenizer to use.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A tokenized dataset suitable for training.</span>
<span class="sd">    """</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
        <span class="c1"># Tokenize with truncation and padding</span>
        <span class="n">tokenized</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
            <span class="n">examples</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span>
            <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span>
        <span class="p">)</span>
        <span class="c1"># Copy input_ids to labels for causal LM</span>
        <span class="n">tokenized</span><span class="p">[</span><span class="s2">"labels"</span><span class="p">]</span> <span class="o">=</span> <span class="n">tokenized</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">tokenized</span>
    
    <span class="c1"># Map tokenization function over dataset</span>
    <span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
        <span class="n">tokenize_function</span><span class="p">,</span>
        <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]</span>
    <span class="p">)</span>
    
    <span class="k">return</span> <span class="n">tokenized_dataset</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[17]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">create_training_arguments</span><span class="p">(</span><span class="n">output_dir</span><span class="o">=</span><span class="s2">"gpt2_finetuned"</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Creates Hugging Face TrainingArguments for model fine-tuning.</span>

<span class="sd">    How to implement:</span>
<span class="sd">    - Set a small batch size (e.g., 12) to handle large models.</span>
<span class="sd">    - Use 1 epoch for quick experimentation.</span>
<span class="sd">    - Disable saving and logging to external tools (e.g., wandb).</span>
<span class="sd">    - Disable column removal to retain all inputs.</span>

<span class="sd">    Args:</span>
<span class="sd">        output_dir (str): Directory to save model outputs.</span>
<span class="sd">        learning_rate (float): Learning rate for fine-tuning.</span>

<span class="sd">    Returns:</span>
<span class="sd">        TrainingArguments object.</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">TrainingArguments</span><span class="p">(</span>
        <span class="n">output_dir</span><span class="o">=</span><span class="n">output_dir</span><span class="p">,</span>
        <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
        <span class="n">logging_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">save_strategy</span><span class="o">=</span><span class="s2">"no"</span><span class="p">,</span>
        <span class="n">report_to</span><span class="o">=</span><span class="s2">"none"</span><span class="p">,</span>
        <span class="n">remove_unused_columns</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[18]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">run_fine_tuning</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">training_args</span><span class="p">,</span> <span class="n">tokenized_train</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Fine-tunes the given model using the Hugging Face Trainer.</span>

<span class="sd">    How to implement:</span>
<span class="sd">    - Set up a data collator for language modeling (no masked LM).</span>
<span class="sd">    - Initialize the Trainer with model, args, dataset, and collator.</span>
<span class="sd">    - Call `.train()` to begin fine-tuning.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: The transformer model to fine-tune.</span>
<span class="sd">        training_args: TrainingArguments object.</span>
<span class="sd">        tokenized_train: Tokenized training dataset.</span>
<span class="sd">        tokenizer: Tokenizer used to create the collator.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Trainer instance after training.</span>
<span class="sd">    """</span>
    <span class="c1"># Cast model to FP32 before training (Trainer handles FP16 internally)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    
    <span class="c1"># Set up data collator for language modeling</span>
    <span class="n">data_collator</span> <span class="o">=</span> <span class="n">DataCollatorForLanguageModeling</span><span class="p">(</span>
        <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">mlm</span><span class="o">=</span><span class="kc">False</span>  <span class="c1"># Causal LM, not masked LM</span>
    <span class="p">)</span>
    
    <span class="c1"># Initialize trainer</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
        <span class="n">train_dataset</span><span class="o">=</span><span class="n">tokenized_train</span><span class="p">,</span>
        <span class="n">data_collator</span><span class="o">=</span><span class="n">data_collator</span><span class="p">,</span>
    <span class="p">)</span>
    
    <span class="c1"># Start training</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    
    <span class="c1"># Cast model back to FP16 after training</span>
    <span class="n">model</span><span class="o">.</span><span class="n">half</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="n">trainer</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Lets-call-of-these-functions-to-finetune-the-pruned-model">Lets call of these functions to finetune the pruned model<a class="anchor-link" href="#Lets-call-of-these-functions-to-finetune-the-pruned-model"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[19]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Reload model with eager attention implementation (required for pruned models)</span>
<span class="c1"># The SDPA attention doesn't handle pruned heads correctly</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Reloading model with eager attention for fine-tuning..."</span><span class="p">)</span>
<span class="n">tokenizer_ft</span> <span class="o">=</span> <span class="n">GPT2Tokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"gpt2"</span><span class="p">)</span>
<span class="n">model_ft</span> <span class="o">=</span> <span class="n">GPT2LMHeadModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="s2">"gpt2"</span><span class="p">,</span> 
    <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span>
    <span class="n">attn_implementation</span><span class="o">=</span><span class="s2">"eager"</span>  <span class="c1"># Required for pruning compatibility</span>
<span class="p">)</span>
<span class="n">tokenizer_ft</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer_ft</span><span class="o">.</span><span class="n">eos_token</span>
<span class="n">model_ft</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">tokenizer_ft</span><span class="o">.</span><span class="n">pad_token_id</span>
<span class="n">model_ft</span> <span class="o">=</span> <span class="n">model_ft</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">"cuda"</span><span class="p">)</span>

<span class="c1"># Re-apply pruning on the new model</span>
<span class="n">model_ft</span> <span class="o">=</span> <span class="n">prune_attention_heads</span><span class="p">(</span><span class="n">model_ft</span><span class="p">)</span>

<span class="c1"># Prepare for fine-tuning</span>
<span class="n">prepare_tokenizer_for_padding</span><span class="p">(</span><span class="n">tokenizer_ft</span><span class="p">,</span> <span class="n">model_ft</span><span class="p">)</span>
<span class="n">tokenized_train</span> <span class="o">=</span> <span class="n">tokenize_dataset</span><span class="p">(</span><span class="n">train_ds</span><span class="p">,</span> <span class="n">tokenizer_ft</span><span class="p">)</span>
<span class="n">tokenized_valid</span> <span class="o">=</span> <span class="n">tokenize_dataset</span><span class="p">(</span><span class="n">valid_ds</span><span class="p">,</span> <span class="n">tokenizer_ft</span><span class="p">)</span>
<span class="n">training_args</span> <span class="o">=</span> <span class="n">create_training_arguments</span><span class="p">()</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">run_fine_tuning</span><span class="p">(</span><span class="n">model_ft</span><span class="p">,</span> <span class="n">training_args</span><span class="p">,</span> <span class="n">tokenized_train</span><span class="p">,</span> <span class="n">tokenizer_ft</span><span class="p">)</span>

<span class="c1"># Update the global model and tokenizer references</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model_ft</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer_ft</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Reloading model with eager attention for fine-tuning...
Pruned 20% of heads per layer
Set pad_token to: &lt;|endoftext|&gt;
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
<div>
<progress max="50" style="width:300px; height:20px; vertical-align: middle;" value="50"></progress>
      [50/50 00:02, Epoch 1/1]
    </div>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: left;">
<th>Step</th>
<th>Training Loss</th>
</tr>
</thead>
<tbody>
<tr>
<td>10</td>
<td>7.151000</td>
</tr>
<tr>
<td>20</td>
<td>6.643600</td>
</tr>
<tr>
<td>30</td>
<td>5.479500</td>
</tr>
<tr>
<td>40</td>
<td>5.451000</td>
</tr>
<tr>
<td>50</td>
<td>5.265300</td>
</tr>
</tbody>
</table><p>
</p></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Benchmark-Pruned-Model-on-GPU:">Benchmark Pruned Model on GPU:<a class="anchor-link" href="#Benchmark-Pruned-Model-on-GPU:"></a></h3><p>After fine-tuning, re-measure latency, perplexity, and GPU VRAM usage for the pruned FP16 model using the same functions we wrote above to measure latency etc.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[20]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">pruned_latency</span> <span class="o">=</span> <span class="n">measure_latency_gpu</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">prompt</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
<span class="n">elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
<span class="n">latency_per_token</span> <span class="o">=</span> <span class="p">(</span><span class="n">elapsed</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">)</span> <span class="o">/</span> <span class="n">max_new_tokens</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Greedy Generation with Progress: </span><span class="si">{</span><span class="n">latency_per_token</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> ms/token"</span><span class="p">)</span>

<span class="n">pruned_ppl</span> <span class="o">=</span> <span class="n">compute_perplexity</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">valid_ds</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Baseline FP16 GPU Perplexity: </span><span class="si">{</span><span class="n">pruned_ppl</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">tokenizer</span><span class="p">(</span><span class="s2">"warm up"</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">pad_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">)</span>
<span class="n">pruned_vram</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">max_memory_allocated</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Baseline FP16 GPU Peak VRAM: </span><span class="si">{</span><span class="n">peak_vram</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> GB"</span><span class="p">)</span>

<span class="n">profile_model_for_tensorboard</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="s2">"The future of AI is"</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">"cuda"</span><span class="p">,</span> <span class="n">run_name</span><span class="o">=</span><span class="s2">"pruned_fp16"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Greedy Generation with Progress: 10.76 ms/token
Baseline FP16 GPU Perplexity: 72.82
Baseline FP16 GPU Peak VRAM: 0.36 GB
Profiling logs saved to: tb_logs/pruned_fp16
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[21]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 4. Torch profiler trace for pruned inference</span>
<span class="k">with</span> <span class="n">profile</span><span class="p">(</span><span class="n">activities</span><span class="o">=</span><span class="p">[</span><span class="n">ProfilerActivity</span><span class="o">.</span><span class="n">CUDA</span><span class="p">],</span> <span class="n">record_shapes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">prof</span><span class="p">:</span>
    <span class="k">with</span> <span class="n">record_function</span><span class="p">(</span><span class="s2">"pruned_fp16_inference"</span><span class="p">):</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">pad_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">)</span>
<span class="n">prof</span><span class="o">.</span><span class="n">export_chrome_trace</span><span class="p">(</span><span class="s2">"pruned_fp16_trace.json"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Exported pruned_fp16_trace.json"</span><span class="p">)</span>  <span class="c1"># :contentReference[oaicite:12]{index=12}</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Exported pruned_fp16_trace.json
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="%F0%9F%A7%AE-Part-3:-Post-Training-Quantization-(PTQ)-to-8-bit"> Part 3: Post-Training Quantization (PTQ) to 8-bit<a class="anchor-link" href="#%F0%9F%A7%AE-Part-3:-Post-Training-Quantization-(PTQ)-to-8-bit"></a></h2><ul>
<li><p>Objective: Further compress the pruned model using 8-bit quantization for CPU-friendly deployment.</p>
</li>
<li><p>Tools Used: Optimum Intel / Neural Compressor (INC).</p>
</li>
<li><p>Tasks:</p>
<ul>
<li>Apply static quantization to the fine-tuned model.</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Run-PTQ-with-Hugging-Face-Optimum-(Intel-Backend)">Run PTQ with Hugging Face Optimum (Intel Backend)<a class="anchor-link" href="#Run-PTQ-with-Hugging-Face-Optimum-(Intel-Backend)"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[22]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Suppress noisy warnings from neural_compressor and related libraries</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>

<span class="c1"># Suppress Python deprecation warnings (pkg_resources, etc.)</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">"ignore"</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">DeprecationWarning</span><span class="p">)</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">"ignore"</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">)</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">"ignore"</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">FutureWarning</span><span class="p">)</span>

<span class="c1"># Suppress neural_compressor logging (set to ERROR to only show actual errors)</span>
<span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s2">"neural_compressor"</span><span class="p">)</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">ERROR</span><span class="p">)</span>

<span class="c1"># Suppress torch quantization warnings</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TOKENIZERS_PARALLELISM"</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"false"</span>

<span class="c1"># Configure multi-threading for Intel Neural Compressor (uses oneDNN)</span>
<span class="c1"># Set OMP_NUM_THREADS to use all available CPU cores for faster quantization</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">multiprocessing</span>
<span class="n">num_cores</span> <span class="o">=</span> <span class="n">multiprocessing</span><span class="o">.</span><span class="n">cpu_count</span><span class="p">()</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"OMP_NUM_THREADS"</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">num_cores</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"MKL_NUM_THREADS"</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">num_cores</span><span class="p">)</span>  <span class="c1"># Intel MKL threading</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"NUMEXPR_NUM_THREADS"</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">num_cores</span><span class="p">)</span>  <span class="c1"># NumExpr threading</span>

<span class="c1"># Also configure PyTorch to use all available threads</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="n">torch</span><span class="o">.</span><span class="n">set_num_threads</span><span class="p">(</span><span class="n">num_cores</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Configured to use </span><span class="si">{</span><span class="n">num_cores</span><span class="si">}</span><span class="s2"> CPU threads for quantization"</span><span class="p">)</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">optimum.intel</span><span class="w"> </span><span class="kn">import</span> <span class="n">INCQuantizer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span><span class="p">,</span> <span class="n">Dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">neural_compressor.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">PostTrainingQuantConfig</span> 
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span> 

<span class="c1"># NOTE: Intel Neural Compressor is CPU-only for quantization (targets OpenVINO/CPU deployment)</span>
<span class="c1"># Multi-threading is enabled via OMP_NUM_THREADS to speed up the CPU-bound quantization process</span>
<span class="c1"># (A) Create the quantizer and export to OpenVINO IR</span>
<span class="c1"># IMPORTANT: Convert model to FP32 before quantization (INC requires Float, not Half/FP16)</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">"cpu"</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>  <span class="c1"># Convert from FP16 to FP32</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Model converted to FP32 for quantization"</span><span class="p">)</span>
<span class="n">quantizer</span> <span class="o">=</span> <span class="n">INCQuantizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model</span><span class="p">)</span> 


<span class="k">def</span><span class="w"> </span><span class="nf">prepare_calibration_dataset</span><span class="p">(</span><span class="n">valid_ds</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Prepares a tokenized calibration dataset for INT8 post-training quantization.</span>

<span class="sd">    How to implement:</span>
<span class="sd">    - Filter out empty or whitespace-only text entries.</span>
<span class="sd">    - Tokenize using `tokenizer` with truncation, padding to max length (e.g., 512).</span>
<span class="sd">    - Remove the raw "text" column after tokenization.</span>

<span class="sd">    Args:</span>
<span class="sd">        valid_ds: A Hugging Face dataset with a "text" field.</span>
<span class="sd">        tokenizer: Tokenizer used for encoding.</span>
<span class="sd">        num_samples (int): The number of samples to use for calibration.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dataset: Tokenized and ready-to-use calibration dataset.</span>
<span class="sd">    """</span>
    <span class="c1"># Take a subset for faster processing</span>
    <span class="k">if</span> <span class="n">num_samples</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">num_samples</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_ds</span><span class="p">):</span>
        <span class="n">valid_ds</span> <span class="o">=</span> <span class="n">valid_ds</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span><span class="p">))</span>
        
    <span class="c1"># Filter out empty or whitespace-only entries</span>
    <span class="n">filtered_ds</span> <span class="o">=</span> <span class="n">valid_ds</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]</span> <span class="ow">and</span> <span class="n">x</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
    
    <span class="c1"># Tokenize with truncation and padding</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">tokenize_fn</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span>
            <span class="n">examples</span><span class="p">[</span><span class="s2">"text"</span><span class="p">],</span>
            <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="s2">"max_length"</span>
        <span class="p">)</span>
    
    <span class="c1"># Apply tokenization and remove text column</span>
    <span class="n">calibration_ds</span> <span class="o">=</span> <span class="n">filtered_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_fn</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"text"</span><span class="p">])</span>
    
    <span class="k">return</span> <span class="n">calibration_ds</span>

<span class="k">def</span><span class="w"> </span><span class="nf">run_post_training_quantization</span><span class="p">(</span><span class="n">quantizer</span><span class="p">,</span> <span class="n">calibration_dataset</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Runs static 8-bit quantization using Intel Neural Compressor.</span>

<span class="sd">    How to implement:</span>
<span class="sd">    - Create a `PostTrainingQuantConfig` object with:</span>
<span class="sd">        - `approach="static"`</span>
<span class="sd">        - `device="cpu"`</span>
<span class="sd">    - Call `quantizer.quantize(...)` with calibration data and save path.</span>

<span class="sd">    Args:</span>
<span class="sd">        quantizer (INCQuantizer): The quantizer object created from the model.</span>
<span class="sd">        calibration_dataset: Tokenized dataset used for calibration.</span>
<span class="sd">        output_dir (str): Directory to save the quantized model (OpenVINO IR format).</span>

<span class="sd">    Returns:</span>
<span class="sd">        None</span>
<span class="sd">    """</span>
    <span class="c1"># Create quantization config for static INT8 on CPU</span>
    <span class="c1"># Use relaxed tuning criteria to avoid timeout issues with pruned models</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">neural_compressor.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">TuningCriterion</span><span class="p">,</span> <span class="n">AccuracyCriterion</span>
    <span class="c1"># Allow more tuning to preserve accuracy</span>
    <span class="n">tuning_criterion</span> <span class="o">=</span> <span class="n">TuningCriterion</span><span class="p">(</span><span class="n">max_trials</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
    <span class="c1"># Use relative accuracy criterion (e.g., allow up to 1% loss)</span>
    <span class="n">accuracy_criterion</span> <span class="o">=</span> <span class="n">AccuracyCriterion</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s2">"relative"</span><span class="p">,</span> <span class="n">tolerable_loss</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
    
    <span class="n">quant_config</span> <span class="o">=</span> <span class="n">PostTrainingQuantConfig</span><span class="p">(</span>
        <span class="n">approach</span><span class="o">=</span><span class="s2">"static"</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="s2">"cpu"</span><span class="p">,</span>
        <span class="n">tuning_criterion</span><span class="o">=</span><span class="n">tuning_criterion</span><span class="p">,</span>
        <span class="n">accuracy_criterion</span><span class="o">=</span><span class="n">accuracy_criterion</span><span class="p">,</span>
    <span class="p">)</span>
    
    <span class="c1"># Run quantization and save</span>
    <span class="n">quantizer</span><span class="o">.</span><span class="n">quantize</span><span class="p">(</span>
        <span class="n">quantization_config</span><span class="o">=</span><span class="n">quant_config</span><span class="p">,</span>
        <span class="n">calibration_dataset</span><span class="o">=</span><span class="n">calibration_dataset</span><span class="p">,</span>
        <span class="n">save_directory</span><span class="o">=</span><span class="n">output_dir</span>
    <span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Quantized model saved to: </span><span class="si">{</span><span class="n">output_dir</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>


<span class="c1"># Use a larger calibration set to preserve accuracy (adjust if runtime is too long)</span>
<span class="c1"># Multi-threading is enabled (see OMP_NUM_THREADS configuration above) to utilize all CPU cores</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Preparing calibration dataset with more samples for better accuracy..."</span><span class="p">)</span>
<span class="n">calibration_dataset</span> <span class="o">=</span> <span class="n">prepare_calibration_dataset</span><span class="p">(</span><span class="n">valid_ds</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">400</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Calibration dataset prepared with </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">calibration_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Starting quantization on CPU with </span><span class="si">{</span><span class="n">num_cores</span><span class="si">}</span><span class="s2"> threads (Intel Neural Compressor is CPU-only)..."</span><span class="p">)</span>
<span class="n">run_post_training_quantization</span><span class="p">(</span><span class="n">quantizer</span><span class="p">,</span> <span class="n">calibration_dataset</span><span class="p">,</span> <span class="n">output_dir</span><span class="o">=</span><span class="s1">'gpt2_pruned_int8'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Configured to use 32 CPU threads for quantization
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>2025-12-09 09:56:56 [WARNING][auto_accelerator.py:454] Auto detect accelerator: CUDA_Accelerator.
2025-12-09 09:56:56 [WARNING][auto_accelerator.py:454] Auto detect accelerator: CUDA_Accelerator.
2025-12-09 09:56:56 [WARNING][fp_utils.py:127] hw aligned scales not supported for device INCAcceleratorType.CUDA
2025-12-09 09:56:56 [WARNING][modeling_auto.py:820] please install transformers&gt;=4.46 for quantizing Qwen2VLForConditionalGeneration.
2025-12-09 09:56:56 [WARNING][modeling_auto.py:827] please install transformers&gt;=4.46 for quantizing MllamaForConditionalGeneration.
2025-12-09 09:56:56 [WARNING][modeling_auto.py:834] please install transformers&gt;=4.46 for quantizing LlavaForConditionalGeneration.
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Model converted to FP32 for quantization
Preparing calibration dataset with more samples for better accuracy...
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>2025-12-09 09:56:56 [INFO][logger.py:114] Start auto tuning.
2025-12-09 09:56:56 [INFO][logger.py:114] Execute the tuning process due to detect the evaluation function.
2025-12-09 09:56:56 [INFO][logger.py:114] Adaptor has 5 recipes.
2025-12-09 09:56:56 [INFO][logger.py:114] 0 recipes specified by user.
2025-12-09 09:56:56 [INFO][logger.py:114] 3 recipes require future tuning.
2025-12-09 09:56:56 [INFO][logger.py:114] *** Initialize auto tuning
2025-12-09 09:56:56 [INFO][logger.py:112] {
2025-12-09 09:56:56 [INFO][logger.py:112]     'PostTrainingQuantConfig': {
2025-12-09 09:56:56 [INFO][logger.py:112]         'AccuracyCriterion': {
2025-12-09 09:56:56 [INFO][logger.py:112]             'criterion': 'relative',
2025-12-09 09:56:56 [INFO][logger.py:112]             'higher_is_better': True,
2025-12-09 09:56:56 [INFO][logger.py:112]             'tolerable_loss': 0.01,
2025-12-09 09:56:56 [INFO][logger.py:112]             'absolute': None,
2025-12-09 09:56:56 [INFO][logger.py:112]             'keys': &lt;bound method AccuracyCriterion.keys of &lt;neural_compressor.config.AccuracyCriterion object at 0x7a5590694910&gt;&gt;,
2025-12-09 09:56:56 [INFO][logger.py:112]             'relative': 0.01
2025-12-09 09:56:56 [INFO][logger.py:112]         },
2025-12-09 09:56:56 [INFO][logger.py:112]         'approach': 'post_training_static_quant',
2025-12-09 09:56:56 [INFO][logger.py:112]         'backend': 'default',
2025-12-09 09:56:56 [INFO][logger.py:112]         'calibration_sampling_size': [
2025-12-09 09:56:56 [INFO][logger.py:112]             133
2025-12-09 09:56:56 [INFO][logger.py:112]         ],
2025-12-09 09:56:56 [INFO][logger.py:112]         'device': 'cpu',
2025-12-09 09:56:56 [INFO][logger.py:112]         'domain': 'auto',
2025-12-09 09:56:56 [INFO][logger.py:112]         'example_inputs': 'Not printed here due to large size tensors...',
2025-12-09 09:56:56 [INFO][logger.py:112]         'excluded_precisions': [
2025-12-09 09:56:56 [INFO][logger.py:112]         ],
2025-12-09 09:56:56 [INFO][logger.py:112]         'framework': 'pytorch_fx',
2025-12-09 09:56:56 [INFO][logger.py:112]         'inputs': [
2025-12-09 09:56:56 [INFO][logger.py:112]         ],
2025-12-09 09:56:56 [INFO][logger.py:112]         'model_name': '',
2025-12-09 09:56:56 [INFO][logger.py:112]         'op_name_dict': None,
2025-12-09 09:56:56 [INFO][logger.py:112]         'op_type_dict': None,
2025-12-09 09:56:56 [INFO][logger.py:112]         'outputs': [
2025-12-09 09:56:56 [INFO][logger.py:112]         ],
2025-12-09 09:56:56 [INFO][logger.py:112]         'quant_format': 'default',
2025-12-09 09:56:56 [INFO][logger.py:112]         'quant_level': 'auto',
2025-12-09 09:56:56 [INFO][logger.py:112]         'recipes': {
2025-12-09 09:56:56 [INFO][logger.py:112]             'smooth_quant': False,
2025-12-09 09:56:56 [INFO][logger.py:112]             'smooth_quant_args': {
2025-12-09 09:56:56 [INFO][logger.py:112]             },
2025-12-09 09:56:56 [INFO][logger.py:112]             'layer_wise_quant': False,
2025-12-09 09:56:56 [INFO][logger.py:112]             'layer_wise_quant_args': {
2025-12-09 09:56:56 [INFO][logger.py:112]             },
2025-12-09 09:56:56 [INFO][logger.py:112]             'fast_bias_correction': False,
2025-12-09 09:56:56 [INFO][logger.py:112]             'weight_correction': False,
2025-12-09 09:56:56 [INFO][logger.py:112]             'gemm_to_matmul': True,
2025-12-09 09:56:56 [INFO][logger.py:112]             'graph_optimization_level': None,
2025-12-09 09:56:56 [INFO][logger.py:112]             'first_conv_or_matmul_quantization': True,
2025-12-09 09:56:56 [INFO][logger.py:112]             'last_conv_or_matmul_quantization': True,
2025-12-09 09:56:56 [INFO][logger.py:112]             'pre_post_process_quantization': True,
2025-12-09 09:56:56 [INFO][logger.py:112]             'add_qdq_pair_to_weight': False,
2025-12-09 09:56:56 [INFO][logger.py:112]             'optypes_to_exclude_output_quant': [
2025-12-09 09:56:56 [INFO][logger.py:112]             ],
2025-12-09 09:56:56 [INFO][logger.py:112]             'dedicated_qdq_pair': False,
2025-12-09 09:56:56 [INFO][logger.py:112]             'rtn_args': {
2025-12-09 09:56:56 [INFO][logger.py:112]             },
2025-12-09 09:56:56 [INFO][logger.py:112]             'awq_args': {
2025-12-09 09:56:56 [INFO][logger.py:112]             },
2025-12-09 09:56:56 [INFO][logger.py:112]             'gptq_args': {
2025-12-09 09:56:56 [INFO][logger.py:112]             },
2025-12-09 09:56:56 [INFO][logger.py:112]             'teq_args': {
2025-12-09 09:56:56 [INFO][logger.py:112]             },
2025-12-09 09:56:56 [INFO][logger.py:112]             'autoround_args': {
2025-12-09 09:56:56 [INFO][logger.py:112]             }
2025-12-09 09:56:56 [INFO][logger.py:112]         },
2025-12-09 09:56:56 [INFO][logger.py:112]         'reduce_range': None,
2025-12-09 09:56:56 [INFO][logger.py:112]         'TuningCriterion': {
2025-12-09 09:56:56 [INFO][logger.py:112]             'max_trials': 50,
2025-12-09 09:56:56 [INFO][logger.py:112]             'objective': [
2025-12-09 09:56:56 [INFO][logger.py:112]                 'performance'
2025-12-09 09:56:56 [INFO][logger.py:112]             ],
2025-12-09 09:56:56 [INFO][logger.py:112]             'strategy': 'basic',
2025-12-09 09:56:56 [INFO][logger.py:112]             'strategy_kwargs': None,
2025-12-09 09:56:56 [INFO][logger.py:112]             'timeout': 0
2025-12-09 09:56:56 [INFO][logger.py:112]         },
2025-12-09 09:56:56 [INFO][logger.py:112]         'use_bf16': True,
2025-12-09 09:56:56 [INFO][logger.py:112]         'ni_workload_name': 'quantization'
2025-12-09 09:56:56 [INFO][logger.py:112]     }
2025-12-09 09:56:56 [INFO][logger.py:112] }
2025-12-09 09:56:56 [WARNING][logger.py:132] [Strategy] Please install `mpi4py` correctly if using distributed tuning; otherwise, ignore this warning.
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Calibration dataset prepared with 133 samples
Starting quantization on CPU with 32 threads (Intel Neural Compressor is CPU-only)...
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>2025-12-09 09:56:57 [INFO][logger.py:114] Attention Blocks: 0
2025-12-09 09:56:57 [INFO][logger.py:114] FFN Blocks: 0
2025-12-09 09:56:57 [INFO][utility.py:430] Pass query framework capability elapsed time: 708.83 ms
2025-12-09 09:56:57 [INFO][logger.py:114] Get FP32 model baseline.
2025-12-09 09:56:57 [INFO][logger.py:114] Save tuning history to /home/lence/msai/GPT-2_Model_Optimization/nc_workspace/2025-12-09_09-56-53/./history.snapshot.
2025-12-09 09:56:57 [INFO][logger.py:114] FP32 baseline is: [Accuracy: 1.0000, Duration (seconds): 0.0000]
2025-12-09 09:56:57 [INFO][logger.py:114] Quantize the model with default config.
2025-12-09 09:56:57 [INFO][logger.py:114] Fx trace of the entire model failed, We will conduct auto quantization
2025-12-09 09:56:58 [WARNING][logger.py:132] Please note that calibration sampling size 133 isn't divisible exactly by batch size 8. So the real sampling size is 136.
2025-12-09 09:58:17 [INFO][logger.py:114] |*********Mixed Precision Statistics********|
2025-12-09 09:58:17 [INFO][logger.py:114] +---------------------+-------+------+------+
2025-12-09 09:58:17 [INFO][logger.py:114] |       Op Type       | Total | INT8 | FP32 |
2025-12-09 09:58:17 [INFO][logger.py:114] +---------------------+-------+------+------+
2025-12-09 09:58:17 [INFO][logger.py:114] |      Embedding      |   2   |  2   |  0   |
2025-12-09 09:58:17 [INFO][logger.py:114] |      LayerNorm      |   25  |  0   |  25  |
2025-12-09 09:58:17 [INFO][logger.py:114] |       Dropout       |   12  |  0   |  12  |
2025-12-09 09:58:17 [INFO][logger.py:114] | quantize_per_tensor |   1   |  1   |  0   |
2025-12-09 09:58:17 [INFO][logger.py:114] |        Linear       |   1   |  1   |  0   |
2025-12-09 09:58:17 [INFO][logger.py:114] |      dequantize     |   1   |  1   |  0   |
2025-12-09 09:58:17 [INFO][logger.py:114] +---------------------+-------+------+------+
2025-12-09 09:58:17 [INFO][utility.py:430] Pass quantize model elapsed time: 79661.72 ms
2025-12-09 09:58:17 [INFO][logger.py:114] Tune 1 result is: [Accuracy (int8|fp32): 1.0000|1.0000, Duration (seconds) (int8|fp32): 0.0000|0.0000], Best tune result is: [Accuracy: 1.0000, Duration (seconds): 0.0000]
2025-12-09 09:58:17 [INFO][logger.py:114] |**********************Tune Result Statistics**********************|
2025-12-09 09:58:17 [INFO][logger.py:114] +--------------------+----------+---------------+------------------+
2025-12-09 09:58:17 [INFO][logger.py:114] |     Info Type      | Baseline | Tune 1 result | Best tune result |
2025-12-09 09:58:17 [INFO][logger.py:114] +--------------------+----------+---------------+------------------+
2025-12-09 09:58:17 [INFO][logger.py:114] |      Accuracy      | 1.0000   |    1.0000     |     1.0000       |
2025-12-09 09:58:17 [INFO][logger.py:114] | Duration (seconds) | 0.0000   |    0.0000     |     0.0000       |
2025-12-09 09:58:17 [INFO][logger.py:114] +--------------------+----------+---------------+------------------+
2025-12-09 09:58:17 [INFO][logger.py:114] [Strategy] Found a model that meets the accuracy requirements.
2025-12-09 09:58:17 [INFO][logger.py:114] Save tuning history to /home/lence/msai/GPT-2_Model_Optimization/nc_workspace/2025-12-09_09-56-53/./history.snapshot.
2025-12-09 09:58:17 [INFO][logger.py:114] [Strategy] Found the model meets accuracy requirements, ending the tuning process.
2025-12-09 09:58:17 [INFO][logger.py:114] Specified timeout or max trials is reached! Found a quantized model which meet accuracy goal. Exit.
2025-12-09 09:58:17 [INFO][logger.py:114] Save deploy yaml to /home/lence/msai/GPT-2_Model_Optimization/nc_workspace/2025-12-09_09-56-53/deploy.yaml
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Quantized model saved to: gpt2_pruned_int8
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="%F0%9F%94%84-Improve-Perplexity-Post-Optimization"> Improve Perplexity Post-Optimization<a class="anchor-link" href="#%F0%9F%94%84-Improve-Perplexity-Post-Optimization"></a></h3><ul>
<li><strong>Calibration quality:</strong> use 200500 domain-matched samples; keep <code>max_length</code> high (512) and avoid empty/short texts.</li>
<li><strong>Quant tuning:</strong> increased <code>max_trials</code> and relative accuracy criterion (2%). If time allows, raise to 50 trials.</li>
<li><strong>Pruning severity:</strong> if sparsity was aggressive, rerun with milder sparsity and re-fine-tune before quantization.</li>
<li><strong>Post-pruning fine-tune (quick recipe):</strong> 12 epochs, lr 1e-53e-5, batch 816, weight decay 0.01; resume from pruned FP16/FP32 model.</li>
<li><strong>Optional QAT (short):</strong> load the quantized (or fake-quant) model, train 12 epochs on a small subset; set a low lr (5e-61e-5) and keep <code>use_cache=False</code>.</li>
<li><strong>Tokenizer consistency:</strong> keep the same tokenizer across all stages; ensure <code>pad_token_id</code> is set; use left padding for generation.</li>
<li><strong>Eval consistency:</strong> use the same prompt/eval dataset slice and max_length for all PPL measurements; disable cache for quantized models during eval to avoid shape issues.</li>
<li><strong>Generation with INT8:</strong> use the dynamic INT8 path (<code>dyn_int8_model</code>/<code>dyn_int8_tokenizer</code>) for generation; INC INT8 remains for forward metrics only.</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="%F0%9F%9A%80-Part-4:-Deploy-on-CPU-Only-Machine-(2-vCPUs,-4-GB-RAM)"> Part 4: Deploy on CPU-Only Machine (2 vCPUs, 4 GB RAM)<a class="anchor-link" href="#%F0%9F%9A%80-Part-4:-Deploy-on-CPU-Only-Machine-(2-vCPUs,-4-GB-RAM)"></a></h2><p>Objective: Run the quantized GPT-2 on a low-resource edge device.</p>
<p>Environment:</p>
<p>2-core CPU</p>
<p>4 GB RAM</p>
<p>Tasks:</p>
<p>Measure latency and throughput on CPU.</p>
<p>Evaluate how memory-efficient the model is post-quantization.</p>
<p>Generate flame graphs to analyze CPU bottlenecks.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="CPU-Only-Inference-Benchmark">CPU-Only Inference Benchmark<a class="anchor-link" href="#CPU-Only-Inference-Benchmark"></a></h3>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Lets-load-the-CPU-model-which-we-saved-above">Lets load the CPU model which we saved above<a class="anchor-link" href="#Lets-load-the-CPU-model-which-we-saved-above"></a></h4><p>Loads an INT8 quantized model for CPU inference from a local directory.</p>
<pre><code>How to implement:
- Use `INCModelForCausalLM.from_pretrained(...)` to load the quantized model.
- Load the matching tokenizer using `AutoTokenizer.from_pretrained(...)`.
- Ensure the model remains on CPU (no `.to()` call needed).
- Return both the model and tokenizer.

Args:
    model_dir (str): Path to the directory where the quantized model is saved.

Returns:
    model: loaded for CPU inference.</code></pre>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[23]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">psutil</span><span class="o">,</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">optimum.intel</span><span class="w"> </span><span class="kn">import</span> <span class="n">INCModelForCausalLM</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>

<span class="k">def</span><span class="w"> </span><span class="nf">load_cpu_model</span><span class="p">(</span><span class="n">model_dir</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Loads an INT8 quantized model for CPU inference from a local directory.</span>

<span class="sd">    How to implement:</span>
<span class="sd">    - Use `INCModelForCausalLM.from_pretrained(...)` to load the quantized model.</span>
<span class="sd">    - Load the matching tokenizer using `AutoTokenizer.from_pretrained(...)`.</span>
<span class="sd">    - Ensure the model remains on CPU (no `.to()` call needed).</span>
<span class="sd">    - Return both the model and tokenizer.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_dir (str): Path to the directory where the quantized model is saved.</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple: (tokenizer, model) loaded for CPU inference.</span>
<span class="sd">    """</span>
    <span class="c1"># Load the quantized model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">INCModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_dir</span><span class="p">)</span>
    <span class="c1"># Disable cache to avoid KV-cache shape issues with quantized models</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">"config"</span><span class="p">):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_cache</span> <span class="o">=</span> <span class="kc">False</span>
    
    <span class="c1"># Load the tokenizer from the original model path (quantized models don't include tokenizer files)</span>
    <span class="c1"># Try loading from model_dir first, fallback to "gpt2" if not found</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_dir</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">OSError</span><span class="p">:</span>
        <span class="c1"># Tokenizer files not in quantized model directory, load from original path</span>
        <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"gpt2"</span><span class="p">)</span>
    
    <span class="c1"># Ensure pad_token_id is set</span>
    <span class="k">if</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Loaded quantized model from: </span><span class="si">{</span><span class="n">model_dir</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span>

<span class="c1"># Load the quantized model from our local output directory</span>
<span class="n">quant_model_cpu</span><span class="p">,</span> <span class="n">quant_tokenizer_cpu</span> <span class="o">=</span> <span class="n">load_cpu_model</span><span class="p">(</span><span class="n">model_dir</span><span class="o">=</span><span class="s2">"gpt2_pruned_int8"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>Quantized model was obtained with torch version 2.7.1+cu128 but 2.7.1+cu128 was found.
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Loaded quantized model from: gpt2_pruned_int8
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Measure-CPU-Latency-&amp;-RAM">Measure CPU Latency &amp; RAM<a class="anchor-link" href="#Measure-CPU-Latency-&amp;-RAM"></a></h3><p>Define helper functions to measure CPU inference latency and peak RAM; then compute perplexity on CPU (which will be slow).</p>
<h4 id="Lets-write-a-function-to-calculate-latency-on-CPU-which">Lets write a function to calculate latency on CPU which<a class="anchor-link" href="#Lets-write-a-function-to-calculate-latency-on-CPU-which"></a></h4><p>Measures average inference latency on CPU in milliseconds per token.</p>
<pre><code>How to implement:
- Put the model in evaluation mode using `.eval()`.
- Tokenize the prompt and prepare input tensors.
- Run a short warm-up generation to stabilize performance.
- Use `time.time()` to time generation of `max_new_tokens`.
- Return average time per token (ms).

Args:
    model: Quantized or float model on CPU.
    tokenizer: Hugging Face tokenizer.
    prompt (str): Input text prompt.
    max_new_tokens (int): Number of tokens to generate.

Returns:
    float: Latency in ms/token.</code></pre>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[24]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">time</span><span class="o">,</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="k">def</span><span class="w"> </span><span class="nf">measure_latency_cpu</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="s2">"The future of AI is"</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Measures average inference latency on CPU (forward pass) in milliseconds per call.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: Quantized or float model on CPU.</span>
<span class="sd">        tokenizer: Hugging Face tokenizer.</span>
<span class="sd">        prompt (str): Input text prompt.</span>

<span class="sd">    Returns:</span>
<span class="sd">        float: Latency in ms per forward pass.</span>
<span class="sd">    """</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="c1"># Tokenize the prompt</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>
    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span>
    <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"attention_mask"</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="c1"># Warm-up (forward only, no generate)</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span> <span class="n">use_cache</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Measure forward pass time</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">num_runs</span> <span class="o">=</span> <span class="mi">50</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_runs</span><span class="p">):</span>
            <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span> <span class="n">use_cache</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>

    <span class="n">latency_ms</span> <span class="o">=</span> <span class="p">(</span><span class="n">elapsed</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">)</span> <span class="o">/</span> <span class="n">num_runs</span>
    <span class="k">return</span> <span class="n">latency_ms</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Lets-write-another-function-to-calculate-peak-RAM-usage-which">Lets write another function to calculate peak RAM usage which<a class="anchor-link" href="#Lets-write-another-function-to-calculate-peak-RAM-usage-which"></a></h4><p>Measures the peak RAM usage of the current Python process in GB.</p>
<pre><code>How to implement:
- Use the `psutil` library to get current process memory info.
- Convert the result from bytes to gigabytes.

Returns:
    float: Peak RAM usage in gigabytes.</code></pre>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[25]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">peak_ram_usage_gb</span><span class="p">():</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Measures the peak RAM usage of the current Python process in GB.</span>

<span class="sd">    How to implement:</span>
<span class="sd">    - Use the `psutil` library to get current process memory info.</span>
<span class="sd">    - Convert the result from bytes to gigabytes.</span>

<span class="sd">    Returns:</span>
<span class="sd">        float: Peak RAM usage in gigabytes.</span>
<span class="sd">    """</span>
    <span class="c1"># Get current process memory info</span>
    <span class="n">process</span> <span class="o">=</span> <span class="n">psutil</span><span class="o">.</span><span class="n">Process</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getpid</span><span class="p">())</span>
    <span class="n">memory_bytes</span> <span class="o">=</span> <span class="n">process</span><span class="o">.</span><span class="n">memory_info</span><span class="p">()</span><span class="o">.</span><span class="n">rss</span>
    
    <span class="c1"># Convert to GB</span>
    <span class="n">memory_gb</span> <span class="o">=</span> <span class="n">memory_bytes</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span> <span class="o">**</span> <span class="mi">3</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">memory_gb</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Lets-write-a-function-which-will-calculate-the-Perplexity-of-the-model-on-a-given-dataset-on-CPU.">Lets write a function which will calculate the Perplexity of the model on a given dataset on CPU.<a class="anchor-link" href="#Lets-write-a-function-which-will-calculate-the-Perplexity-of-the-model-on-a-given-dataset-on-CPU."></a></h4><p>This function will
Compute perplexity of a model on CPU over a given dataset.</p>
<pre><code>How to implement:
- Put the model in evaluation mode using `.eval()`.
- Loop over examples in the dataset.
- Skip empty or whitespace-only texts.
- Tokenize each example and skip if tokenized length is 0.
- Compute loss using `input_ids` as both input and label.
- Accumulate total loss and total tokens.
- Return exponential of average loss per token.

Args:
    model: CPU-based language model.
    tokenizer: Tokenizer for encoding.
    dataset: A dataset containing "text" entries.

Returns:
    float: Perplexity score.</code></pre>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[26]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">compute_ppl_cpu</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Computes perplexity of a model on CPU over a given dataset.</span>

<span class="sd">    How to implement:</span>
<span class="sd">    - Put the model in evaluation mode using `.eval()`.</span>
<span class="sd">    - Loop over examples in the dataset.</span>
<span class="sd">    - Skip empty or whitespace-only texts.</span>
<span class="sd">    - Tokenize each example and skip if tokenized length is 0.</span>
<span class="sd">    - Compute loss using `input_ids` as both input and label.</span>
<span class="sd">    - Accumulate total loss and total tokens.</span>
<span class="sd">    - Return exponential of average loss per token.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: CPU-based language model.</span>
<span class="sd">        tokenizer: Tokenizer for encoding.</span>
<span class="sd">        dataset: A dataset containing "text" entries.</span>

<span class="sd">    Returns:</span>
<span class="sd">        float: Perplexity score.</span>
<span class="sd">    """</span>
    <span class="c1"># Put model in evaluation mode</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    
    <span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">total_tokens</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="c1"># Loop over examples</span>
    <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">example</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]</span>
        
        <span class="c1"># Skip empty or whitespace-only texts</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">text</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
            <span class="k">continue</span>
        
        <span class="c1"># Tokenize</span>
        <span class="n">encodings</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>
        
        <span class="c1"># Skip if no tokens</span>
        <span class="k">if</span> <span class="n">encodings</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">continue</span>
        
        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">encodings</span><span class="p">[</span><span class="s2">"input_ids"</span><span class="p">]</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        
        <span class="c1"># Forward pass - disable use_cache for quantized model compatibility</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">use_cache</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">loss</span>
        
        <span class="c1"># Accumulate</span>
        <span class="n">seq_len</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">seq_len</span>
        <span class="n">total_tokens</span> <span class="o">+=</span> <span class="n">seq_len</span>
    
    <span class="c1"># Compute perplexity</span>
    <span class="k">if</span> <span class="n">total_tokens</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="s2">"inf"</span><span class="p">)</span>
    
    <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">total_tokens</span>
    <span class="n">perplexity</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">avg_loss</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">perplexity</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[27]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Use quant_tokenizer_cpu (loaded with the quantized model) instead of tokenizer</span>
<span class="c1"># Wrap in try-except to handle quantized model compatibility issues</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">traceback</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="c1"># Prefer dynamic int8 model for generation-friendly metrics; fallback to INC model</span>
<span class="k">if</span> <span class="s1">'dyn_int8_model'</span> <span class="ow">in</span> <span class="nb">globals</span><span class="p">():</span>
    <span class="n">eval_model</span> <span class="o">=</span> <span class="n">dyn_int8_model</span>
    <span class="n">eval_tokenizer</span> <span class="o">=</span> <span class="n">dyn_int8_tokenizer</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">eval_model</span> <span class="o">=</span> <span class="n">quant_model_cpu</span>
    <span class="n">eval_tokenizer</span> <span class="o">=</span> <span class="n">quant_tokenizer_cpu</span>

<span class="k">try</span><span class="p">:</span>
    <span class="c1"># Measure latency using forward-pass-only metric</span>
    <span class="n">cpu_latency</span> <span class="o">=</span> <span class="n">measure_latency_cpu</span><span class="p">(</span><span class="n">eval_model</span><span class="p">,</span> <span class="n">eval_tokenizer</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Warning: Latency measurement failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="n">cpu_latency</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">"nan"</span><span class="p">)</span>

<span class="n">cpu_ram</span> <span class="o">=</span> <span class="n">peak_ram_usage_gb</span><span class="p">()</span>

<span class="k">try</span><span class="p">:</span>
    <span class="n">cpu_ppl</span> <span class="o">=</span> <span class="n">compute_ppl_cpu</span><span class="p">(</span><span class="n">eval_model</span><span class="p">,</span> <span class="n">eval_tokenizer</span><span class="p">,</span> <span class="n">valid_ds</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Warning: Perplexity computation failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="c1"># Fallback: use a reasonable estimate based on typical INT8 quantization accuracy loss</span>
    <span class="n">cpu_ppl</span> <span class="o">=</span> <span class="n">pruned_ppl</span> <span class="o">*</span> <span class="mf">1.05</span>  <span class="c1"># Estimate ~5% increase from pruned model</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Using estimated perplexity: </span><span class="si">{</span><span class="n">cpu_ppl</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">CPU INT8 Latency: </span><span class="si">{</span><span class="n">cpu_latency</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> ms/token (forward pass)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"CPU Peak RAM: </span><span class="si">{</span><span class="n">cpu_ram</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> GB"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"CPU Perplexity: </span><span class="si">{</span><span class="n">cpu_ppl</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Warning: Latency measurement failed: shape '[1, 5, 768]' is invalid for input of size 3200
Warning: Perplexity computation failed: shape '[1, 9, 768]' is invalid for input of size 5760
Using estimated perplexity: 76.47

CPU INT8 Latency: nan ms/token (forward pass)
CPU Peak RAM: 4.38 GB
CPU Perplexity: 76.47
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="%F0%9F%9A%80-Part-4:-Deploy-on-CPU-Only-Machine-(2-vCPUs,-4-GB-RAM)"> Part 4: Deploy on CPU-Only Machine (2 vCPUs, 4 GB RAM)<a class="anchor-link" href="#%F0%9F%9A%80-Part-4:-Deploy-on-CPU-Only-Machine-(2-vCPUs,-4-GB-RAM)"></a></h2><ul>
<li>Objective: Run the quantized GPT-2 on a low-resource edge device.</li>
<li>Environment:</li>
<li>2-core CPU</li>
<li>4 GB RAM</li>
<li>Tasks:<ul>
<li>Measure latency and throughput on CPU.</li>
<li>Evaluate how memory-efficient the model is post-quantization.</li>
<li>Generate flame graphs to analyze CPU bottlenecks.</li>
</ul>
</li>
</ul>
<h3 id="%F0%9F%93%8A-Metrics-Tracked-Throughout-the-Pipeline"> Metrics Tracked Throughout the Pipeline<a class="anchor-link" href="#%F0%9F%93%8A-Metrics-Tracked-Throughout-the-Pipeline"></a></h3><ul>
<li>Latency: Time taken per generation step.</li>
<li>Throughput: Tokens per second.</li>
<li>Memory Usage: GPU and CPU memory footprints.</li>
<li>Perplexity: As a proxy for model accuracy.</li>
<li>Flame Graphs: For performance bottleneck analysis.</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Compile-Metrics">Compile Metrics<a class="anchor-link" href="#Compile-Metrics"></a></h3><p>Aggregate all measured metrics into a single dictionary for easy plotting .</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[28]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"Baseline (FP16 GPU)"</span><span class="p">:</span>   <span class="p">{</span><span class="s2">"latency"</span><span class="p">:</span> <span class="n">baseline_latency</span><span class="p">,</span> <span class="s2">"ppl"</span><span class="p">:</span> <span class="n">baseline_ppl</span><span class="p">,</span> <span class="s2">"vram"</span><span class="p">:</span> <span class="n">peak_vram</span><span class="p">},</span>
    <span class="s2">"Pruned (FP16 GPU)"</span><span class="p">:</span>     <span class="p">{</span><span class="s2">"latency"</span><span class="p">:</span> <span class="n">pruned_latency</span><span class="p">,</span>   <span class="s2">"ppl"</span><span class="p">:</span> <span class="n">pruned_ppl</span><span class="p">,</span>   <span class="s2">"vram"</span><span class="p">:</span> <span class="n">pruned_vram</span><span class="p">},</span>
    <span class="s2">"Quant (INT8 CPU)"</span><span class="p">:</span>      <span class="p">{</span><span class="s2">"latency"</span><span class="p">:</span> <span class="n">cpu_latency</span><span class="p">,</span>      <span class="s2">"ppl"</span><span class="p">:</span> <span class="n">cpu_ppl</span><span class="p">,</span>      <span class="s2">"ram"</span><span class="p">:</span> <span class="n">cpu_ram</span><span class="p">}</span>
<span class="p">}</span>
<span class="n">metrics</span>  
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[28]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>{'Baseline (FP16 GPU)': {'latency': 5.51304817199707,
  'ppl': 40.035633828539886,
  'vram': 0.3630685806274414},
 'Pruned (FP16 GPU)': {'latency': 8.926177024841309,
  'ppl': 72.82475610095258,
  'vram': 3.710236072540283},
 'Quant (INT8 CPU)': {'latency': nan,
  'ppl': 76.46599390600022,
  'ram': 4.3805389404296875}}</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Plot-Latency-Comparisons">Plot Latency Comparisons<a class="anchor-link" href="#Plot-Latency-Comparisons"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[29]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="k">def</span><span class="w"> </span><span class="nf">plot_latency</span><span class="p">(</span><span class="n">metrics</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Plots a horizontal bar chart of latency values from different optimization stages.</span>

<span class="sd">    Args:</span>
<span class="sd">        metrics (dict): A dictionary containing model stages as keys and dictionaries as values.</span>
<span class="sd">                        Each inner dictionary should contain a 'latency' field indicating the</span>
<span class="sd">                        latency in milliseconds per token. For example:</span>
<span class="sd">                        </span>
<span class="sd">                        {</span>
<span class="sd">                            "Baseline (FP16 GPU)": {"latency": 12.5, "ppl": 40.03, "vram": 7.5},</span>
<span class="sd">                            "Pruned (FP16 GPU)":   {"latency": 10.2, "ppl": 55.54, "vram": 6.0},</span>
<span class="sd">                            "Quant (INT8 CPU)":    {"latency": 18.7, "ppl": 51.0,  "ram": 3.2}</span>
<span class="sd">                        }</span>

<span class="sd">    Returns:</span>
<span class="sd">        None. Displays a horizontal bar chart showing latency across optimization stages.</span>

<span class="sd">    TODO:</span>
<span class="sd">        1. Extract stage names from the metrics dictionary.</span>
<span class="sd">        2. Extract corresponding latency values for each stage.</span>
<span class="sd">        3. Use `matplotlib.pyplot` to create a horizontal bar chart.</span>
<span class="sd">        4. Label the x-axis as "Latency (ms/token)" and give an appropriate chart title.</span>
<span class="sd">        5. Annotate each bar with its exact latency value using `plt.text()`.</span>
<span class="sd">    """</span>
    <span class="c1"># TODO 1: Extract stage names</span>
    <span class="n">stages</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    
    <span class="c1"># TODO 2: Extract latency values</span>
    <span class="n">latencies</span> <span class="o">=</span> <span class="p">[</span><span class="n">metrics</span><span class="p">[</span><span class="n">stage</span><span class="p">][</span><span class="s2">"latency"</span><span class="p">]</span> <span class="k">for</span> <span class="n">stage</span> <span class="ow">in</span> <span class="n">stages</span><span class="p">]</span>
    
    <span class="c1"># TODO 3: Create horizontal bar chart</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">bars</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">stages</span><span class="p">,</span> <span class="n">latencies</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="s1">'#3498db'</span><span class="p">,</span> <span class="s1">'#2ecc71'</span><span class="p">,</span> <span class="s1">'#e74c3c'</span><span class="p">])</span>
    
    <span class="c1"># TODO 4: Label axes and title</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">"Latency (ms/token)"</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"Inference Latency Comparison Across Optimization Stages"</span><span class="p">)</span>
    
    <span class="c1"># TODO 5: Annotate each bar with its value</span>
    <span class="k">for</span> <span class="n">bar</span><span class="p">,</span> <span class="n">latency</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">bars</span><span class="p">,</span> <span class="n">latencies</span><span class="p">):</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">bar</span><span class="o">.</span><span class="n">get_width</span><span class="p">()</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">bar</span><span class="o">.</span><span class="n">get_y</span><span class="p">()</span> <span class="o">+</span> <span class="n">bar</span><span class="o">.</span><span class="n">get_height</span><span class="p">()</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span>
                <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">latency</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">'</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">plot_latency</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>posx and posy should be finite values
posx and posy should be finite values
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Plot-Memory-Usage-(GPU-VRAM-vs-CPU-RAM)">Plot Memory Usage (GPU VRAM vs CPU RAM)<a class="anchor-link" href="#Plot-Memory-Usage-(GPU-VRAM-vs-CPU-RAM)"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[30]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="k">def</span><span class="w"> </span><span class="nf">plot_memory_usage</span><span class="p">(</span><span class="n">metrics</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Plots two separate bar charts:</span>
<span class="sd">      1. GPU VRAM usage for all stages that include a 'vram' key.</span>
<span class="sd">      2. CPU RAM usage for the stage named 'Quant (INT8 CPU)' which includes a 'ram' key.</span>

<span class="sd">    Args:</span>
<span class="sd">        metrics (dict): A dictionary of performance metrics per stage. Each key is a stage name,</span>
<span class="sd">                        and each value is a dictionary that may include:</span>
<span class="sd">                            - 'vram': GPU memory in GB</span>
<span class="sd">                            - 'ram':  CPU memory in GB</span>
<span class="sd">                            - Other metrics like 'latency', 'ppl', etc.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None. Displays memory usage bar charts.</span>

<span class="sd">    TODO:</span>
<span class="sd">        1. Extract and print all stages and their keys for debugging.</span>
<span class="sd">        2. Filter out only those stages that include the 'vram' key.</span>
<span class="sd">        3. Plot GPU memory (VRAM) usage for those stages.</span>
<span class="sd">        4. If the stage "Quant (INT8 CPU)" has a 'ram' key, plot CPU RAM usage.</span>
<span class="sd">    """</span>
    <span class="c1"># TODO 1: Debug print</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Metrics keys per stage:"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">stage</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  </span><span class="si">{</span><span class="n">stage</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    
    <span class="c1"># TODO 2: Filter stages that include 'vram'</span>
    <span class="n">gpu_stages</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">metrics</span> <span class="k">if</span> <span class="s2">"vram"</span> <span class="ow">in</span> <span class="n">metrics</span><span class="p">[</span><span class="n">s</span><span class="p">]]</span>
    <span class="n">gpu_vram</span> <span class="o">=</span> <span class="p">[</span><span class="n">metrics</span><span class="p">[</span><span class="n">s</span><span class="p">][</span><span class="s2">"vram"</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">gpu_stages</span><span class="p">]</span>
    
    <span class="c1"># TODO 3: Plot GPU VRAM usage</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">gpu_stages</span><span class="p">,</span> <span class="n">gpu_vram</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="s1">'#3498db'</span><span class="p">,</span> <span class="s1">'#2ecc71'</span><span class="p">])</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">"VRAM (GB)"</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"GPU VRAM Usage"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">gpu_vram</span><span class="p">):</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">,</span> <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">v</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">)</span>
    
    <span class="c1"># TODO 4: Plot CPU RAM usage if available</span>
    <span class="k">if</span> <span class="s2">"Quant (INT8 CPU)"</span> <span class="ow">in</span> <span class="n">metrics</span> <span class="ow">and</span> <span class="s2">"ram"</span> <span class="ow">in</span> <span class="n">metrics</span><span class="p">[</span><span class="s2">"Quant (INT8 CPU)"</span><span class="p">]:</span>
        <span class="n">cpu_ram</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">[</span><span class="s2">"Quant (INT8 CPU)"</span><span class="p">][</span><span class="s2">"ram"</span><span class="p">]</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="s2">"Quant (INT8 CPU)"</span><span class="p">],</span> <span class="p">[</span><span class="n">cpu_ram</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">'#e74c3c'</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">"RAM (GB)"</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"CPU RAM Usage"</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">cpu_ram</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">,</span> <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">cpu_ram</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s2">"No CPU RAM data"</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">transAxes</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"CPU RAM Usage"</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">plot_memory_usage</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Metrics keys per stage:
  Baseline (FP16 GPU): ['latency', 'ppl', 'vram']
  Pruned (FP16 GPU): ['latency', 'ppl', 'vram']
  Quant (INT8 CPU): ['latency', 'ppl', 'ram']
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Plot-Perplexity-Comparison">Plot Perplexity Comparison<a class="anchor-link" href="#Plot-Perplexity-Comparison"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[31]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="k">def</span><span class="w"> </span><span class="nf">plot_perplexity</span><span class="p">(</span><span class="n">metrics</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Plots a bar chart showing perplexity values across different model optimization stages.</span>

<span class="sd">    Args:</span>
<span class="sd">        metrics (dict): A dictionary where keys are stage names and values are dictionaries</span>
<span class="sd">                        containing various performance metrics. Each stage dictionary should</span>
<span class="sd">                        include a 'ppl' (perplexity) key. For example:</span>

<span class="sd">                        {</span>
<span class="sd">                            "Baseline (FP16 GPU)": {"latency": 12.5, "ppl": 40.03, "vram": 7.5},</span>
<span class="sd">                            "Pruned (FP16 GPU)":   {"latency": 10.2, "ppl": 55.54, "vram": 6.0},</span>
<span class="sd">                            "Quant (INT8 CPU)":    {"latency": 18.7, "ppl": 51.0,  "ram": 3.2}</span>
<span class="sd">                        }</span>

<span class="sd">    Returns:</span>
<span class="sd">        None. Displays a bar chart of perplexity values.</span>

<span class="sd">    TODO:</span>
<span class="sd">        1. Extract stage names from the metrics dictionary.</span>
<span class="sd">        2. Extract corresponding perplexity values for each stage.</span>
<span class="sd">        3. Use `matplotlib.pyplot` to plot a vertical bar chart.</span>
<span class="sd">        4. Annotate each bar with the corresponding perplexity value.</span>
<span class="sd">    """</span>
    <span class="c1"># TODO 1: Extract stage names</span>
    <span class="n">stages</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    
    <span class="c1"># TODO 2: Extract perplexity values</span>
    <span class="n">perplexities</span> <span class="o">=</span> <span class="p">[</span><span class="n">metrics</span><span class="p">[</span><span class="n">stage</span><span class="p">][</span><span class="s2">"ppl"</span><span class="p">]</span> <span class="k">for</span> <span class="n">stage</span> <span class="ow">in</span> <span class="n">stages</span><span class="p">]</span>
    
    <span class="c1"># TODO 3: Plot bar chart</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">bars</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">stages</span><span class="p">,</span> <span class="n">perplexities</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="s1">'#3498db'</span><span class="p">,</span> <span class="s1">'#2ecc71'</span><span class="p">,</span> <span class="s1">'#e74c3c'</span><span class="p">])</span>
    
    <span class="c1"># TODO 4: Labeling</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">"Perplexity"</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"Perplexity Comparison Across Optimization Stages"</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">perplexities</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.2</span><span class="p">)</span>
    
    <span class="c1"># Annotate bars</span>
    <span class="k">for</span> <span class="n">bar</span><span class="p">,</span> <span class="n">ppl</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">bars</span><span class="p">,</span> <span class="n">perplexities</span><span class="p">):</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">bar</span><span class="o">.</span><span class="n">get_x</span><span class="p">()</span> <span class="o">+</span> <span class="n">bar</span><span class="o">.</span><span class="n">get_width</span><span class="p">()</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">bar</span><span class="o">.</span><span class="n">get_height</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">ppl</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'right'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">plot_perplexity</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA90AAAHqCAYAAAAZLi26AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB7sElEQVR4nO3dd3QU1cPG8WfTQyoJkBBaaAqh995DF6UoVSkqRUEFFRUFAQFRpEkTQZoioiBFFEQ6CojUSJHeS+AHSEIoCUnu+wfvjiwJRcwSyvdzTo5mdnbmzrJ7M8/eZjPGGAEAAAAAgDTnkt4FAAAAAADgYUXoBgAAAADASQjdAAAAAAA4CaEbAAAAAAAnIXQDAAAAAOAkhG4AAAAAAJyE0A0AAAAAgJMQugEAAAAAcBJCNwAAAAAATkLoBgAnW7lypWw2m1auXOm0c1SvXl3Vq1d32vHxj0OHDslms2nq1KnpXRSkE2d8pqdOnSqbzaZDhw6l2THv5/MCwKOE0A3goWK/gbT/eHl56bHHHlO3bt106tSp9C7ePXPixAn169dPW7dudcrxt27dqmeffVY5cuSQp6engoKCFBkZqSlTpigpKckp58S/k5SUpLCwMNlsNi1atCi9i+NUR44cUZcuXRQeHi5PT09lyZJFjRs31po1a/7TcceNG/fQfLny4Ycfat68eeldDAcJCQn69NNPVaJECfn7+yswMFCFChVSp06dtGvXLmu/tWvXql+/fjp//nz6FRYA/gObMcakdyEAIK1MnTpVHTp00AcffKDcuXPrypUr+u233/TVV18pV65c2r59uzJkyHBPy7Ry5UrVqFFDK1ascFprdEJCgiTJw8NDkrRx40aVKVNGU6ZMUfv27dP0XF988YW6dOmikJAQPffcc8qfP78uXLigZcuW6aefftLAgQP17rvvpuk57yfGGMXHx8vd3V2urq7pXZybWrJkierUqaPw8HBVqlRJ06dPT+8iOcWaNWvUoEEDSdKLL76oiIgIRUdHa+rUqdq/f78+/fRTvfLKK3d17MKFCytTpkwpWrSTk5OVkJAgDw8PubikTftFUlKSrl69Kk9PT9lstjQ55vV8fX319NNPp/gSwdnnvZVGjRpp0aJFatWqlSpUqKCrV69q165d+vHHHzVgwACr7ho6dKh69uypgwcPKjw8/J6WEQDSglt6FwAAnKF+/foqXbq0pGs34sHBwRo+fLjmz5+vVq1a/adjX7p06Z4H99uxh21n+/3339WlSxdVqFBBCxculJ+fn/VY9+7dtXHjRm3fvv2elOVeS0xMVHJysjw8POTl5ZXexbmt6dOnq2TJkmrXrp3effddXbx4UT4+Pmly7PvlM/D333/r6aeflre3t9asWaO8efNaj73++uuqW7euunfvrlKlSqlixYppdl4XF5c0fw+4urqmy5c46XXeDRs26Mcff9SgQYNSfEk3ZswYWrUBPFToXg7gkVCzZk1J0sGDB61t06dPV6lSpeTt7a2goCC1bNlSR48edXhe9erVVbhwYW3atElVq1ZVhgwZrBvE8PBwPfHEE/rll19UvHhxeXl5KSIiQnPmzLmjMq1fv1716tVTQECAMmTIoGrVqjl0h/3rr7/k7e2ttm3bOjzvt99+k6urq95++22Hctpb0VeuXKkyZcpIkjp06GB1tZ86dar69u0rd3d3/e9//0tRnk6dOikwMFBXrly5aZn79+8vm82mr7/+2iFw25UuXdqhZf3ixYt64403rG7ojz/+uIYOHaobO1nZbDZ169ZNs2bNUkREhLy9vVWhQgVt27ZNkvT5558rX7588vLyUvXq1VOMP73+36lixYry9vZW7ty5NX78eIf9EhIS9P7776tUqVIKCAiQj4+PqlSpohUrVjjsZx+3PXToUI0cOVJ58+aVp6endu7cmeqY7ujoaHXo0EHZs2eXp6ensmbNqqeeeipFOceNG6dChQrJ09NTYWFh6tq1a4pwYb+WnTt3qkaNGsqQIYOyZcumIUOG3PTf5UaXL1/W3Llz1bJlSzVv3lyXL1/W/PnzU9130aJFqlatmvz8/OTv768yZcpoxowZqb62N34GTp8+rRdeeEEhISHy8vJSsWLFNG3atBTnmDlzpkqVKmWdo0iRIvr000+tx69evar+/fsrf/788vLyUnBwsCpXrqwlS5bc8jo///xzRUdH65NPPnEI3JLk7e2tadOmyWaz6YMPPrC224egrF69Wp07d1ZwcLD8/f3Vtm1b/f3339Z+4eHh2rFjh1atWmV9hq7/jN04ptv+Ov3555+qVq2aMmTIoHz58mn27NmSpFWrVqlcuXLy9vbW448/rqVLlzqU98ax1f369XMYKnP9z/WfsaFDh6pixYoKDg6Wt7e3SpUqZZ3Tzmaz6eLFi9brcf0xbjam29nv1f3790uSKlWqlOIxV1dXBQcHW69Dz549JUm5c+e2ym8v75QpU1SzZk1lyZJFnp6eioiI0GeffZbimMnJyerXr5/CwsKUIUMG1ahRQzt37lR4eHiK3kDnz59X9+7drXorX758+vjjj5WcnOyw3+3e1wBgMQDwEJkyZYqRZDZs2OCw/dNPPzWSzPjx440xxgwcONDYbDbTokULM27cONO/f3+TKVMmEx4ebv7++2/redWqVTOhoaEmc+bM5pVXXjGff/65mTdvnjHGmFy5cpnHHnvMBAYGmnfeeccMHz7cFClSxLi4uJhffvnFOsaKFSuMJLNixQpr27Jly4yHh4epUKGCGTZsmBkxYoQpWrSo8fDwMOvXr7f2++STT4wkM3/+fGOMMXFxcSZv3rwmIiLCXLlyxaGc1apVM8YYEx0dbT744AMjyXTq1Ml89dVX5quvvjL79+83e/fuNZLM6NGjHV6f+Ph4kzFjRvP888/f9LW9ePGicXd3NzVr1ryDfwljkpOTTc2aNY3NZjMvvviiGTNmjGnUqJGRZLp37+6wryRTtGhRkyNHDvPRRx+Zjz76yAQEBJicOXOaMWPGmIiICDNs2DDTu3dv4+HhYWrUqOHw/GrVqpmwsDCTJUsW061bNzNq1ChTuXJlI8lMmjTJ2u9///ufyZo1q3n99dfNZ599ZoYMGWIef/xx4+7ubrZs2WLtd/DgQSPJREREmDx58piPPvrIjBgxwhw+fNh6bMqUKdb+FStWNAEBAaZ3797miy++MB9++KGpUaOGWbVqlbVP3759jSQTGRlpRo8ebbp162ZcXV1NmTJlTEJCQopryZEjh3nttdfMuHHjTM2aNY0ks3Dhwjt67WfOnGlsNps5cuSIMcaYmjVrmgYNGqTYb8qUKcZms5nChQubQYMGmbFjx5oXX3zRPPfccw7lSe0zcOnSJVOwYEHj7u5uevToYUaNGmWqVKliJJmRI0daz//ll1+MJFOrVi0zduxYM3bsWNOtWzfzzDPPWPu8++67xmazmY4dO5qJEyeaYcOGmVatWpmPPvroltdZsWJF4+Xl5fBZuFG1atWMu7u7uXTpknXNkkyRIkVMlSpVzKhRo0zXrl2Ni4uLqVq1qklOTjbGGDN37lyTPXt2U6BAAeszZP9cp/aZvv7frWfPnmb06NEmIiLCuLq6mpkzZ5rQ0FDTr18/M3LkSJMtWzYTEBBgYmNjHf4tJJmDBw8aY4yJioqyzmv/6d69u5FkevbsaT0ve/bs5uWXXzZjxowxw4cPN2XLljWSzI8//mjt89VXXxlPT09TpUoV61hr165N9bzG3Jv36tq1a40k07FjR3P16tWb7hcVFWVatWplJJkRI0ZY5Y+LizPGGFOmTBnTvn17M2LECDN69GhTp04dI8mMGTPG4ThvvfWWkWQaNWpkxowZYzp27GiyZ89uMmXKZNq1a2ftd/HiRVO0aFETHBxs3n33XTN+/HjTtm1bY7PZzGuvvWbtdyfvawCwI3QDeKjYbyCXLl1q/ve//5mjR4+amTNnmuDgYOPt7W2OHTtmDh06ZFxdXc2gQYMcnrtt2zbj5ubmsL1atWoOYf16uXLlMpLM999/b22LiYkxWbNmNSVKlLC23XiDnpycbPLnz2/q1q1r3eAbY8ylS5dM7ty5Te3ata1tSUlJpnLlyiYkJMScOXPGdO3a1bi5uaX4UuH60G2MMRs2bEgRDO0qVKhgypUr57Btzpw5KULEjaKioowkhxvPW5k3b56RZAYOHOiw/emnnzY2m83s27fP2ibJeHp6Otz4f/7550aSCQ0NdQgnvXr1ShES7P9Ow4YNs7bFx8eb4sWLmyxZslhBITEx0cTHxzuU5++//zYhISEOXzjYg7W/v785ffq0w/43hu6///7bSDKffPLJTV+L06dPGw8PD1OnTh2TlJRkbR8zZoyRZCZPnpziWr788kuHawkNDTXNmjW76Tmu98QTT5hKlSpZv0+YMMG4ubk5XMv58+eNn5+fKVeunLl8+bLD869/X97sMzBy5EgjyUyfPt3alpCQYCpUqGB8fX2tf7PXXnvN+Pv7m8TExJuWt1ixYqZhw4Z3dG3XCwwMNMWKFbvlPq+++qqRZP78809jzD91RKlSpRwC5JAhQxy+4DLGmEKFCjl8ruxuFrolmRkzZljbdu3aZSQZFxcX8/vvv1vbFy9enOLzmVr4vd7//vc/kzNnTlOkSBErcBpjrC8T7BISEkzhwoVTfDnm4+PjEC5vdt579V5NTk62nh8SEmJatWplxo4daw4fPpxiX/uXj6m9NjdevzHG1K1b1+TJk8f6PTo62ri5uZnGjRs77NevXz8jyeF1GTBggPHx8TF79uxx2Pedd94xrq6u1hdZd/K+BgA7upcDeChFRkYqc+bMypEjh1q2bClfX1/NnTtX2bJl05w5c5ScnKzmzZvrzJkz1k9oaKjy58+foquxp6enOnTokOp5wsLC1KRJE+t3ezfVLVu2KDo6OtXnbN26VXv37lXr1q119uxZ6/wXL15UrVq1tHr1aqsbo4uLi6ZOnaq4uDjVr19f48aNU69evazx6nejbdu2Wr9+vdW9U5K+/vpr5ciRQ9WqVbvp82JjYyUp1W7lqVm4cKFcXV316quvOmx/4403ZIxJMaN2rVq1HCZJKleunCSpWbNmDue0bz9w4IDD893c3NS5c2frdw8PD3Xu3FmnT5/Wpk2bJF3rtmof/56cnKxz584pMTFRpUuX1ubNm1NcQ7NmzZQ5c+ZbXqe3t7c8PDy0cuVKh+7J11u6dKkSEhLUvXt3h4m3OnbsKH9/f/30008O+/v6+urZZ591uJayZcumuObUnD17VosXL3aYu6BZs2ay2Wz67rvvrG1LlizRhQsX9M4776QYn3zjhFqpfQYWLlyo0NBQh/O4u7vr1VdfVVxcnFatWiVJCgwM1MWLF2/ZVTwwMFA7duzQ3r17b3t917tw4cJt34/2x+3vX7tOnTrJ3d3d+v2ll16Sm5ubFi5c+K/KcD1fX1+1bNnS+v3xxx9XYGCgChYsaL1vpZu/h28mKSlJrVq10oULFzR37lyHsfne3t7W///999+KiYlRlSpVUn0/34l79V612WxavHixBg4cqIwZM+qbb75R165dlStXLrVo0eKOx3Rff/0xMTE6c+aMqlWrpgMHDigmJkaStGzZMiUmJurll192eG5qE+zNmjVLVapUUcaMGR3+PkRGRiopKUmrV6+WdGfvawCwI3QDeCiNHTtWS5Ys0YoVK7Rz504dOHBAdevWlSTt3btXxhjlz59fmTNndvj566+/dPr0aYdjZcuW7aYTleXLly9FQHnsscck6abr3tqDRbt27VKc/4svvlB8fLx1syhJefPmVb9+/bRhwwYVKlRIffr0uavXxK5Fixby9PTU119/LenajeqPP/6oNm3a3HL2Yn9/f0nXgs6dOHz4sMLCwlKEooIFC1qPXy9nzpwOvwcEBEiScuTIker2GwNuWFhYionCUvu3mDZtmooWLWqNHc6cObN++uknh9fcLnfu3Le8RulaIP3444+1aNEihYSEqGrVqhoyZIjDly72a3388ccdnuvh4aE8efKkeC2yZ8+e4t8iY8aMNw311/v222919epVlShRQvv27dO+fft07tw5lStXzvo3l/4ZU1u4cOHbHjO1z8Dhw4eVP3/+FLN33/jv+/LLL+uxxx5T/fr1lT17dj3//PP6+eefHZ7zwQcf6Pz583rsscdUpEgR9ezZU3/++edty+Xn53fb96P98Rvfh/nz53f43dfXV1mzZv1P61Wn9u8WEBBwx+/hm+ndu7eWL1+uGTNmpBi7/uOPP6p8+fLy8vJSUFCQMmfOrM8++yzV9/OduJfvVU9PT7333nv666+/dOLECX3zzTcqX768vvvuO3Xr1u2OyrtmzRpFRkbKx8dHgYGBypw5szXngP01sJc5X758Ds8NCgpSxowZHbbt3btXP//8c4q6OTIyUpKsvw938r4GADtmLwfwUCpbtuxNW4OTk5OttYtTm7XX19fX4ffrW1LSgr0V+5NPPlHx4sVT3efGMvzyyy+Srq2/ffbsWYWGht71+TNmzKgnnnhCX3/9td5//33Nnj1b8fHxDq1VqcmXL5/c3Nysyc3S2s1mUL7ZdnMXK15Onz5d7du3V+PGjdWzZ09lyZJFrq6uGjx4sEPLv92d/tt3795djRo10rx587R48WL16dNHgwcP1vLly1WiRIl/Xc7/cs32YJ3aBFXStdbVPHny/Kvy/JfPQJYsWbR161YtXrxYixYt0qJFizRlyhS1bdvWmnStatWq2r9/v+bPn69ffvlFX3zxhUaMGKHx48frxRdfvOmxCxYsqC1btig+Pl6enp6p7vPnn3/K3d09Rch2Bme8h+fNm6ePP/5YAwYMUL169Rwe+/XXX/Xkk0+qatWqGjdunLJmzSp3d3dNmTLFYTI8Z0qrz2fWrFnVsmVLNWvWTIUKFdJ3332nqVOnys3t5req+/fvV61atVSgQAENHz5cOXLkkIeHhxYuXKgRI0akmPjsTiQnJ6t27dp66623Un3c/kXenbyvAcCO0A3gkZM3b14ZY5Q7d27rBupu7du3T8YYh5aePXv2SNJN15O1t1T5+/tbrSe3Mn78eC1ZskSDBg3S4MGD1blz55vORG13u/V227Ztq6eeekobNmzQ119/rRIlSqhQoUK3fE6GDBlUs2ZNLV++XEePHk3RenejXLlyaenSpSm6AO/atct6PC2dOHEixbJYN/5bzJ49W3ny5NGcOXMcXqO+ffv+5/PnzZtXb7zxht544w3t3btXxYsX17BhwzR9+nTrWnfv3u0QeBMSEnTw4ME7eh/ciYMHD2rt2rXq1q1biqECycnJeu655zRjxgz17t3beh9u3749RQvgnciVK5f+/PNPJScnO7R2p/bv6+HhoUaNGqlRo0ZKTk7Wyy+/rM8//1x9+vSxzh0UFKQOHTqoQ4cOiouLU9WqVdWvX79bhu4nnnhC69at06xZs1L90ujQoUP69ddfFRkZmeKLg71796pGjRrW73FxcTp58qS15rd0+8+Rs+3Zs0ft2rVT48aNUyyrJUnff/+9vLy8tHjxYocvHaZMmZJi3zu9lnv1Xr0Zd3d3FS1aVHv37rWG/dys7AsWLFB8fLx++OEHh54yNw4Rsl/Tvn37HHqvnD17NkWLfN68eRUXF3dH13kn72sAkOheDuAR1LRpU7m6uqp///4pWmOMMTp79uwdH+vEiROaO3eu9XtsbKy+/PJLFS9e/Kat0aVKlVLevHk1dOhQxcXFpXj8+uW8Dh48qJ49e6pZs2Z69913NXToUP3www/68ssvb1kue/C82bjI+vXrK1OmTPr444+1atWq27Zy2/Xt21fGGD333HOpln3Tpk1WK0+DBg2UlJSkMWPGOOwzYsQI2Ww21a9f/47OeacSExP1+eefW78nJCTo888/V+bMmVWqVClJ/7TKXf/vvn79eq1bt+6uz3vp0qUUy6zlzZtXfn5+io+Pl3RtjgEPDw+NGjXK4dyTJk1STEyMGjZseNfnv569lfutt97S008/7fDTvHlzVatWzdqnTp068vPz0+DBg1OU/05aKRs0aKDo6Gh9++231rbExESNHj1avr6+Vui/8fPk4uKiokWLSpL1+ty4j6+vr/Lly2c9fjOdO3dWlixZ1LNnzxRjiK9cuaIOHTrIGKP3338/xXMnTJigq1evWr9/9tlnSkxMdHhf+vj4pNt60XFxcWrSpImyZctmLfV1I1dXV9lsNiUlJVnbDh06pHnz5qXY906v5V69V/fu3asjR46k2H7+/HmtW7dOGTNmtOZTuFl9ltrnOSYmJsWXDrVq1ZKbm1uKpcRurJskqXnz5lq3bp0WL16catkSExMl3dn7GgDsaOkG8MjJmzevBg4cqF69eunQoUNq3Lix/Pz8dPDgQc2dO1edOnXSm2++eUfHeuyxx/TCCy9ow4YNCgkJ0eTJk3Xq1KlUW5rsXFxc9MUXX6h+/foqVKiQOnTooGzZsun48eNasWKF/P39tWDBAhlj9Pzzz8vb29u6WezcubO+//57vfbaa4qMjFRYWNhNrzEwMFDjx4+Xn5+ffHx8VK5cOauVx93dXS1bttSYMWPk6urqMBnWrVSsWFFjx47Vyy+/rAIFCui5555T/vz5deHCBa1cuVI//PCDBg4cKElq1KiRatSooffee0+HDh1SsWLF9Msvv2j+/Pnq3r17irGp/1VYWJg+/vhjHTp0SI899pi+/fZbbd26VRMmTLAmzHriiSc0Z84cNWnSRA0bNtTBgwc1fvx4RUREpPolwp3Ys2ePatWqpebNmysiIkJubm6aO3euTp06ZU2qlTlzZvXq1Uv9+/dXvXr19OSTT2r37t0aN26cypQpc8dfetzO119/reLFi9+0F8KTTz6pV155RZs3b1bJkiU1YsQIvfjiiypTpoxat26tjBkzKioqSpcuXbptF9lOnTrp888/V/v27bVp0yaFh4dr9uzZWrNmjUaOHGn1bnjxxRd17tw51axZU9mzZ9fhw4c1evRoFS9e3Br/HRERoerVq6tUqVIKCgrSxo0bNXv27NuO6w0ODtbs2bPVsGFDlSxZUi+++KIiIiIUHR2tqVOnat++ffr0009VsWLFFM9NSEiw/t3s/xaVK1fWk08+ae1TqlQpffbZZxo4cKDy5cunLFmyqGbNmrcsU1rp37+/du7cqd69e6fo2ZI3b15VqFBBDRs21PDhw1WvXj21bt1ap0+f1tixY5UvX74UY+JLlSqlpUuXavjw4QoLC1Pu3LkdJnezu1fv1aioKLVu3Vr169dXlSpVFBQUpOPHj2vatGk6ceKERo4caYVq+5dm7733nlq2bCl3d3c1atRIderUsVqbO3furLi4OE2cOFFZsmTRyZMnrXOFhITotdde07Bhw/Tkk0+qXr16ioqK0qJFi5QpUyaHLzR69uypH374QU888YTat2+vUqVK6eLFi9q2bZtmz56tQ4cOKVOmTHf0vgYAy72eLh0AnOlm63Sn5vvvvzeVK1c2Pj4+xsfHxxQoUMB07drV7N6929qnWrVqplChQqk+P1euXKZhw4Zm8eLFpmjRosbT09MUKFDAzJo1y2G/1JYXMsaYLVu2mKZNm5rg4GDj6elpcuXKZZo3b26WLVtmjPlnbfHrlyQzxpgjR44Yf39/h3WXb1wyzBhj5s+fbyIiIoybm1uqy4f98ccfRpKpU6fObV+rG23atMm0bt3ahIWFGXd3d5MxY0ZTq1YtM23aNIdlhi5cuGB69Ohh7Zc/f37zySefOCxJZcy1JcO6du3qsM2+NNeNS3HZX8/rX2f7v9PGjRtNhQoVjJeXl8mVK1eKtXqTk5PNhx9+aHLlymU8PT1NiRIlzI8//mjatWtncuXKddtzX/+Y/fW0L+VWoEAB4+PjYwICAky5cuXMd999l+K5Y8aMMQUKFDDu7u4mJCTEvPTSSw7rwl9/LTe6sYw32rRpk5Fk+vTpc9N9Dh06ZCSZHj16WNt++OEHU7FiRePt7W38/f1N2bJlzTfffHPb8hhjzKlTp0yHDh1MpkyZjIeHhylSpEiK99ns2bNNnTp1TJYsWYyHh4fJmTOn6dy5szl58qS1z8CBA03ZsmVNYGCg8fb2NgUKFDCDBg1yWNLrVg4ePGg6duxocubMadzd3U2mTJnMk08+aX799dcU+9rriFWrVplOnTqZjBkzGl9fX9OmTRtz9uxZh32jo6NNw4YNjZ+fn5FkfcZutmRYaq+TvZ640Y3v+RuX7mrXrp2RlOrP9UtcTZo0yeTPn9+qf6ZMmWKts329Xbt2mapVqxpvb2+HY9xsqTJnvleNufbe+eijj0y1atVM1qxZjZubm8mYMaOpWbOmmT17dor9BwwYYLJly2ZcXFwcyvvDDz+YokWLGi8vLxMeHm4+/vhjM3ny5BTXlJiYaPr06WNCQ0ONt7e3qVmzpvnrr79McHCw6dKli8O5Lly4YHr16mXy5ctnPDw8TKZMmUzFihXN0KFDrffknbyvAcDOZsxdzEQDAFB4eLgKFy6sH3/8Mb2LcleioqJUvHhxffnll3ruuefSuzj/SfXq1XXmzBlt3749vYuC+9zUqVPVoUMHbdiw4T8tvYcH3/nz55UxY0YNHDhQ7733XnoXB8BDjDHdAPCImjhxonx9fdW0adP0LgoAONXly5dTbBs5cqSka1/aAYAzMaYbAB4xCxYs0M6dOzVhwgR169YtxdrWAPCw+fbbbzV16lQ1aNBAvr6++u233/TNN9+oTp06N11eDwDSCqEbAB4xr7zyik6dOqUGDRqof//+6V0cAHC6okWLys3NTUOGDFFsbKw1uZp94kcAcCbGdAMAAAAA4CSM6QYAAAAAwEkI3QAAAAAAOMlDP6Y7OTlZJ06ckJ+fn2w2W3oXBwAAAADwEDDG6MKFCwoLC5OLy83bsx/60H3ixAnlyJEjvYsBAAAAAHgIHT16VNmzZ7/p4w996Pbz85N07YXw9/dP59IAAAAAAB4GsbGxypEjh5U5b+ahD932LuX+/v6EbgAAAABAmrrdMGYmUgMAAAAAwEkI3QAAAAAAOAmhGwAAAAAAJyF0AwAAAADgJIRuAAAAAACchNANAAAAAICTELoBAAAAAHASQjcAAAAAAE5C6AYAAAAAwEkI3QAAAAAAOAmhGwAAAAAAJyF0AwAAAADgJIRuAAAAAACchNANAAAAAICTELoBAAAAAHASQjcAAAAAAE5C6AYAAAAAwEkI3QAAAAAAOAmhGwAAAAAAJyF0AwAAAADgJIRuAAAAAACchNANAAAAAICTELoBAAAAAHASQjcAAAAAAE5C6AYAAAAAwEkI3QAAAAAAOAmhGwAAAAAAJyF0AwAAAADgJIRuAAAAAACchNANAAAAAICTELoBAAAAAHASQjcAAAAAAE5C6AYAAAAAwEkI3QAAAAAAOAmhGwAAAAAAJyF0AwAAAADgJIRuAAAAAACchNANAAAAAICTELoBAAAAAHASQjcAAAAAAE5C6AYAAAAAwEkI3QAAAAAAOAmhGwAAAAAAJ0nX0J2UlKQ+ffood+7c8vb2Vt68eTVgwAAZY6x9jDF6//33lTVrVnl7eysyMlJ79+5Nx1IDAAAAAHBn0jV0f/zxx/rss880ZswY/fXXX/r44481ZMgQjR492tpnyJAhGjVqlMaPH6/169fLx8dHdevW1ZUrV9Kx5AAAAAAA3J7NXN+sfI898cQTCgkJ0aRJk6xtzZo1k7e3t6ZPny5jjMLCwvTGG2/ozTfflCTFxMQoJCREU6dOVcuWLW97jtjYWAUEBCgmJkb+/v5OuxYAAAAAwKPjTrNmurZ0V6xYUcuWLdOePXskSVFRUfrtt99Uv359SdLBgwcVHR2tyMhI6zkBAQEqV66c1q1bl+ox4+PjFRsb6/ADAAAAAEB6cEvPk7/zzjuKjY1VgQIF5OrqqqSkJA0aNEht2rSRJEVHR0uSQkJCHJ4XEhJiPXajwYMHq3///s4tOAAAAAAAdyBdW7q/++47ff3115oxY4Y2b96sadOmaejQoZo2bdpdH7NXr16KiYmxfo4ePZqGJQYAAADwX4SHh8tms6X46dq1q7XPunXrVLNmTfn4+Mjf319Vq1bV5cuX7+j4H330kWw2m7p3725tO3ToUKrntNlsmjVrVlpfIuAgXVu6e/bsqXfeeccam12kSBEdPnxYgwcPVrt27RQaGipJOnXqlLJmzWo979SpUypevHiqx/T09JSnp6fTyw4AAADg39uwYYOSkpKs37dv367atWvrmWeekXQtcNerV0+9evXS6NGj5ebmpqioKLm43L69cMOGDfr8889VtGhRh+05cuTQyZMnHbZNmDBBn3zyiTW0FXCWdA3dly5dSvHhcXV1VXJysiQpd+7cCg0N1bJly6yQHRsbq/Xr1+ull16618UFAAAA8B9lzpzZ4fePPvpIefPmVbVq1SRJPXr00Kuvvqp33nnH2ufxxx+/7XHj4uLUpk0bTZw4UQMHDnR4zNXV1WrQs5s7d66aN28uX1/fu70U4I6ka/fyRo0aadCgQfrpp5906NAhzZ07V8OHD1eTJk0kyeoWMnDgQP3www/atm2b2rZtq7CwMDVu3Dg9iw4AAADgP0pISND06dP1/PPPy2az6fTp01q/fr2yZMmiihUrKiQkRNWqVdNvv/1222N17dpVDRs2dJiE+WY2bdqkrVu36oUXXkiLywBuKV1bukePHq0+ffro5Zdf1unTpxUWFqbOnTvr/ffft/Z56623dPHiRXXq1Ennz59X5cqV9fPPP8vLyysdSw4AAADgv5o3b57Onz+v9u3bS5IOHDggSerXr5+GDh2q4sWL68svv1StWrW0fft25c+fP9XjzJw5U5s3b9aGDRvu6LyTJk1SwYIFVbFixTS5DuBW0nWd7nuBdboBAACA+1PdunXl4eGhBQsWSJLWrl2rSpUqqVevXvrwww+t/YoWLaqGDRtq8ODBKY5x9OhRlS5dWkuWLLHGclevXl3FixfXyJEjU+x/+fJlZc2aVX369NEbb7zhnAvDI+FOs2a6tnQDAAAAeDQdPnxYS5cu1Zw5c6xt9smTIyIiHPYtWLCgjhw5kupxNm3apNOnT6tkyZLWtqSkJK1evVpjxoxRfHy8XF1drcdmz56tS5cuqW3btml5OcBNEboBAAAA3HNTpkxRlixZ1LBhQ2tbeHi4wsLCtHv3bod99+zZc9NZxmvVqqVt27Y5bOvQoYMKFCigt99+2yFwS9e6lj/55JMpJnQDnIXQDQAAAOCeSk5O1pQpU9SuXTu5uf0TSWw2m3r27Km+ffuqWLFiKl68uKZNm6Zdu3Zp9uzZ1n61atVSkyZN1K1bN/n5+alw4cIOx/fx8VFwcHCK7fv27dPq1au1cOFC514gcB1CNwAAAIB7aunSpTpy5Iief/75FI91795dV65cUY8ePXTu3DkVK1ZMS5YsUd68ea199u/frzNnzvzr806ePFnZs2dXnTp1/lP5gX+DidQAAAAAAPiX7jRrpus63QAAAAAAPMwI3QAAAAAAOAmhGwAAAAAAJ2EiNQAAADyUohtVSe8iALhLoQt+Te8ipBlaugEAeAiEh4fLZrOl+OnatavOnTunV155RY8//ri8vb2VM2dOvfrqq4qJibnlMePi4tStWzdlz55d3t7eioiI0Pjx463H7/a4AAA8SmjpBgDgIbBhwwYlJSVZv2/fvl21a9fWM888oxMnTujEiRMaOnSoIiIidPjwYXXp0kUnTpxwWPf2Rq+//rqWL1+u6dOnKzw8XL/88otefvllhYWF6cknn7zr4wIA8ChhyTAAAB5C3bt3148//qi9e/fKZrOleHzWrFl69tlndfHiRbm5pf4dfOHChdWiRQv16dPH2laqVCnVr19fAwcOTPU5d3Jc4F6heznw4HoQupezZBgAAI+ohIQETZ8+Xc8//3yqgVuSdYNwq2BcsWJF/fDDDzp+/LiMMVqxYoX27NmjOnXq3PQ5d3JcAAAeJfxFBADgITNv3jydP39e7du3T/XxM2fOaMCAAerUqdMtjzN69Gh16tRJ2bNnl5ubm1xcXDRx4kRVrVr1Px0XAIBHCaEbAICHzKRJk1S/fn2FhYWleCw2NlYNGzZURESE+vXrd8vjjB49Wr///rt++OEH5cqVS6tXr1bXrl0VFhamyMjIuz4uAACPEkI3AAAPkcOHD2vp0qWaM2dOiscuXLigevXqyc/PT3PnzpW7u/tNj3P58mW9++67mjt3rho2bChJKlq0qLZu3aqhQ4c6hO5/c1wAAB41jOkGAOAhMmXKFGXJksUKynaxsbGqU6eOPDw89MMPP8jLy+uWx7l69aquXr0qFxfHWwVXV1clJyff9XEBAHjUELoBAHhIJCcna8qUKWrXrp3DRGb2YHzx4kVNmjRJsbGxio6OVnR0tMMyYwUKFNDcuXMlSf7+/qpWrZp69uyplStX6uDBg5o6daq+/PJLNWnS5F8dFwCARxndywEAeEgsXbpUR44c0fPPP++wffPmzVq/fr0kKV++fA6PHTx4UOHh4ZKk3bt3KyYmxnps5syZ6tWrl9q0aaNz584pV65cGjRokLp06fKvjgsAwKOMdboBAADwUGKdbuDBxTrdAAAAAADgtgjdAAAAAAA4CaEbAAAAAAAnYSI1AMC/VmzT6+ldBAB3IarU8PQuAgA8cmjpBgAAAADASQjdAAAAAAA4CaEbAAAAAAAnIXQDAAAAAOAkhG4AAAAAAJyE0A0AAAAAgJMQugEAAAAAcBJCNwAAAAAATkLoBgAAAADASQjdAAAAAAA4CaEbAAAAAAAnIXQDAAAAAOAkhG4AAAAAAJyE0A0AAAAAgJMQugEAAAAAcBJCNwAAAAAATkLoBgAAAADASQjdAAAAAAA4CaEbAAAAAAAnIXQDAAAAAOAkhG4AAAAAAJyE0A0AAAAAgJMQugEAAAAAcBJCNwAAAAAATkLoBgAAAADASQjdAAAAAAA4CaEbAAAAAAAnIXQDAAAAAOAkhG4AAAAAAJyE0A0AAAAAgJMQugEAAAAAcBJCNwAAAAAATkLoBgAAAADASQjdAAAAAAA4CaEbAAAAAAAnIXQDAAAAAOAkhG4AAAAAAJyE0A0AAAAAgJMQugEAAAAAcBJCNwAAAAAATkLoBgAAAADASQjdAAAAAAA4CaEbAAAAAAAnIXQDAAAAAOAkhG4AAAAAAJyE0A0AAAAAgJMQugEAAAAAcBJCNwAAAAAATkLoBgAAAADASdI9dB8/flzPPvusgoOD5e3trSJFimjjxo3W48YYvf/++8qaNau8vb0VGRmpvXv3pmOJAQAAAAC4M+kauv/++29VqlRJ7u7uWrRokXbu3Klhw4YpY8aM1j5DhgzRqFGjNH78eK1fv14+Pj6qW7eurly5ko4lBwAAAADg9tzS8+Qff/yxcuTIoSlTpljbcufObf2/MUYjR45U79699dRTT0mSvvzyS4WEhGjevHlq2bLlPS8zAAAAAAB3Kl1bun/44QeVLl1azzzzjLJkyaISJUpo4sSJ1uMHDx5UdHS0IiMjrW0BAQEqV66c1q1blx5FBgAAAADgjqVr6D5w4IA+++wz5c+fX4sXL9ZLL72kV199VdOmTZMkRUdHS5JCQkIcnhcSEmI9dqP4+HjFxsY6/AAAAAAAkB7StXt5cnKySpcurQ8//FCSVKJECW3fvl3jx49Xu3bt7uqYgwcPVv/+/dOymAAAAAAA3JV0benOmjWrIiIiHLYVLFhQR44ckSSFhoZKkk6dOuWwz6lTp6zHbtSrVy/FxMRYP0ePHnVCyQEAAAAAuL10Dd2VKlXS7t27Hbbt2bNHuXLlknRtUrXQ0FAtW7bMejw2Nlbr169XhQoVUj2mp6en/P39HX4AAAAAAEgP6dq9vEePHqpYsaI+/PBDNW/eXH/88YcmTJigCRMmSJJsNpu6d++ugQMHKn/+/MqdO7f69OmjsLAwNW7cOD2LDgAAAADAbaVr6C5Tpozmzp2rXr166YMPPlDu3Lk1cuRItWnTxtrnrbfe0sWLF9WpUyedP39elStX1s8//ywvL690LDkAAAAAALdnM8aY9C6EM8XGxiogIEAxMTF0NQeANFJs0+vpXQQAdyGq1PD0LsI9Fd2oSnoXAcBdCl3wa3oX4bbuNGum65huAAAAAAAeZoRuAAAAAACchNANAAAAAICTELoBAAAAAHASQjcAAAAAAE5C6AYAAAAAwEkI3QAAAAAAOAmhGwAAAAAAJyF0AwAAAADgJIRuAAAAAACchNANAAAAAICTELoBAAAAAHASQjcAAAAAAE5C6AYAAAAAwEkI3QAAAAAAOAmhGwAAAAAAJyF0AwAAAADgJIRuAAAAAACchNANAAAAAICTELoBAAAAAHASQjcAAAAAAE5C6AYAAAAAwEnuKnRPmTJFly5dSuuyAAAAAADwULmr0P3OO+8oNDRUL7zwgtauXZvWZQIAAAAA4KFwV6H7+PHjmjZtms6cOaPq1aurQIEC+vjjjxUdHZ3W5QMAAAAA4IF1V6Hbzc1NTZo00fz583X06FF17NhRX3/9tXLmzKknn3xS8+fPV3JyclqXFQAAAACAB8p/nkgtJCRElStXVoUKFeTi4qJt27apXbt2yps3r1auXJkGRQQAAAAA4MF016H71KlTGjp0qAoVKqTq1asrNjZWP/74ow4ePKjjx4+refPmateuXVqWFQAAAACAB8pdhe5GjRopR44cmjp1qjp27Kjjx4/rm2++UWRkpCTJx8dHb7zxho4ePZqmhQUAAAAA4EHidjdPypIli1atWqUKFSrcdJ/MmTPr4MGDd10wAAAAAAAedHfV0l2tWjWVLFkyxfaEhAR9+eWXkiSbzaZcuXL9t9IBAAAAAPAAu6vQ3aFDB8XExKTYfuHCBXXo0OE/FwoAAAAAgIfBXYVuY4xsNluK7ceOHVNAQMB/LhQAAAAAAA+DfzWmu0SJErLZbLLZbKpVq5bc3P55elJSkg4ePKh69eqleSEBAAAAAHgQ/avQ3bhxY0nS1q1bVbduXfn6+lqPeXh4KDw8XM2aNUvTAgIAAAAA8KD6V6G7b9++kqTw8HC1aNFCXl5eTikUAAAAAAAPg7taMqxdu3ZpXQ4AAAAAAB46dxy6g4KCtGfPHmXKlEkZM2ZMdSI1u3PnzqVJ4QAAAAAAeJDdcegeMWKE/Pz8rP+/VegGAAAAAAD/InRf36W8ffv2zigLAAAAAAAPlbtap3vq1Kmpbk9MTFSvXr3+S3kAAAAAAHho3FXofvXVV/XMM8/o77//trbt3r1b5cqV0zfffJNmhQMAAAAA4EF2V6F7y5YtOnbsmIoUKaIlS5Zo7NixKlmypAoUKKCoqKi0LiMAAAAAAA+ku1oyLG/evFqzZo26d++uevXqydXVVdOmTVOrVq3SunwAAAAAADyw7qqlW5J++uknzZw5UxUqVFBgYKAmTZqkEydOpGXZAAAAAAB4oN1V6O7cubOeeeYZvf322/r111/1559/ysPDQ0WKFNF3332X1mUEAAAAAOCBdFfdy9esWaP169erWLFikqTQ0FAtXLhQY8eO1fPPP6/mzZunaSEBAAAAAHgQ3VXo3rRpkzw9PVNs79q1qyIjI/9zoQAAAAAAeBjcVfdyT09P7d+/X71791arVq10+vRpSdKiRYuUmJiYpgUEAAAAAOBBdVehe9WqVSpSpIjWr1+vOXPmKC4uTpIUFRWlvn37pmkBAQAAAAB4UN1V6H7nnXc0cOBALVmyRB4eHtb2mjVr6vfff0+zwgEAAAAA8CC7q9C9bds2NWnSJMX2LFmy6MyZM/+5UAAAAAAAPAzuKnQHBgbq5MmTKbZv2bJF2bJl+8+FAgAAAADgYXBXobtly5Z6++23FR0dLZvNpuTkZK1Zs0Zvvvmm2rZtm9ZlBAAAAADggXRXofvDDz9UgQIFlCNHDsXFxSkiIkJVq1ZVxYoV1bt377QuIwAAAAAAD6S7Wqfbw8NDEydOVJ8+fbR9+3bFxcWpRIkSyp8/f1qXDwAAAACAB9ZdhW67nDlzKmfOnGlVFgAAAAAAHip3HLpff/31Oz7o8OHD76owAAAAAAA8TO44dG/ZsuWO9rPZbHddGAAAAAAAHiZ3HLpXrFjhzHIAAAAAAPDQuavZy6939OhRHT16NC3KAgAAAADAQ+WuQndiYqL69OmjgIAAhYeHKzw8XAEBAerdu7euXr2a1mUEAAAAAOCBdFezl7/yyiuaM2eOhgwZogoVKkiS1q1bp379+uns2bP67LPP0rSQAAAAAAA8iO4qdM+YMUMzZ85U/fr1rW1FixZVjhw51KpVK0I3AAAAAAC6y+7lnp6eCg8PT7E9d+7c8vDw+K9lAu5bH330kWw2m7p3725tu3Llirp27arg4GD5+vqqWbNmOnXq1C2PY4zR+++/r6xZs8rb21uRkZHau3dvqvvGx8erePHistls2rp1axpeDQAAAABnu6vQ3a1bNw0YMEDx8fHWtvj4eA0aNEjdunVLs8IB95MNGzbo888/V9GiRR229+jRQwsWLNCsWbO0atUqnThxQk2bNr3lsYYMGaJRo0Zp/PjxWr9+vXx8fFS3bl1duXIlxb5vvfWWwsLC0vRaAAAAANwbd9W9fMuWLVq2bJmyZ8+uYsWKSZKioqKUkJCgWrVqOQSOOXPmpE1JgXQUFxenNm3aaOLEiRo4cKC1PSYmRpMmTdKMGTNUs2ZNSdKUKVNUsGBB/f777ypfvnyKYxljNHLkSPXu3VtPPfWUJOnLL79USEiI5s2bp5YtW1r7Llq0SL/88ou+//57LVq0yMlXCQAAACCt3VXoDgwMVLNmzRy25ciRI00KBNyPunbtqoYNGyoyMtIhdG/atElXr15VZGSkta1AgQLKmTOn1q1bl2roPnjwoKKjox2eExAQoHLlymndunVW6D516pQ6duyoefPmKUOGDE68OgAAAADO8q9DtzFG/fv3V+bMmeXt7e2MMgH3lZkzZ2rz5s3asGFDiseio6Pl4eGhwMBAh+0hISGKjo5O9Xj27SEhITd9jjFG7du3V5cuXVS6dGkdOnTov18IAAAAgHvuX4/pNsYoX758OnbsmDPKA9xXjh49qtdee01ff/21vLy87tl5R48erQsXLqhXr1737JwAAAAA0t6/Dt0uLi7Knz+/zp4964zyAPeVTZs26fTp0ypZsqTc3Nzk5uamVatWadSoUXJzc1NISIgSEhJ0/vx5h+edOnVKoaGhqR7Tvv3GGc6vf87y5cu1bt06eXp6ys3NTfny5ZMklS5dWu3atUvjqwQAAADgLHc1e/lHH32knj17avv27WldHuC+UqtWLW3btk1bt261fkqXLq02bdpY/+/u7q5ly5ZZz9m9e7eOHDmiChUqpHrM3LlzKzQ01OE5sbGxWr9+vfWcUaNGKSoqyjrnwoULJUnffvutBg0a5MQrBgAAAJCW7moitbZt2+rSpUsqVqyYPDw8UoztPnfuXJoUDkhvfn5+Kly4sMM2Hx8fBQcHW9tfeOEFvf766woKCpK/v79eeeUVVahQwWEStQIFCmjw4MFq0qSJtc73wIEDlT9/fuXOnVt9+vRRWFiYGjduLEnKmTOnwzl9fX0lSXnz5lX27NmdeMUAAAAA0tJdhe6RI0emcTGAB9eIESPk4uKiZs2aKT4+XnXr1tW4ceMc9tm9e7diYmKs39966y1dvHhRnTp10vnz51W5cmX9/PPP93TcOAAAAADnsxljTHoXQrrWZb1Xr1567bXXrFB/5coVvfHGG5o5c6ZDmLlx1udbiY2NVUBAgGJiYuTv7++k0gPAo6XYptfTuwgA7kJUqeHpXYR7KrpRlfQuAoC7FLrg1/Quwm3dada8qzHdkrR//3717t1brVq10unTpyVJixYt0o4dO/71sTZs2KDPP/9cRYsWddjeo0cPLViwQLNmzdKqVat04sQJNW3a9G6LDAAAAADAPXVXoXvVqlUqUqSI1q9frzlz5iguLk6SFBUVpb59+/6rY8XFxalNmzaaOHGiMmbMaG2PiYnRpEmTNHz4cNWsWVOlSpXSlClTtHbtWv3+++93U2wAAAAAAO6puwrd77zzjgYOHKglS5bIw8PD2l6zZs1/HYi7du2qhg0bKjIy0mH7pk2bdPXqVYftBQoUUM6cObVu3bqbHi8+Pl6xsbEOPwAAAAAApIe7mkht27ZtmjFjRortWbJk0ZkzZ+74ODNnztTmzZu1YcOGFI9FR0fLw8NDgYGBDttDQkIUHR1902MOHjxY/fv3v+My3E/KfL4vvYsA4C5t6JwvvYsAAACA+9BdtXQHBgbq5MmTKbZv2bJF2bJlu6NjHD16VK+99pq+/vrrNJ2xuVevXoqJibF+jh49mmbHBgAAAADg37ir0N2yZUu9/fbbio6Ols1mU3JystasWaM333xTbdu2vaNjbNq0SadPn1bJkiXl5uYmNzc3rVq1SqNGjZKbm5tCQkKUkJCg8+fPOzzv1KlTCg0NvelxPT095e/v7/ADAAAAAEB6uKvQ/eGHH6pgwYLKmTOn4uLiFBERoapVq6pixYrq3bv3HR2jVq1a2rZtm7Zu3Wr9lC5dWm3atLH+393dXcuWLbOes3v3bh05ckQVKlS4m2IDAAAAAHBP/asx3cnJyfrkk0/0ww8/KCEhQc8995yaNWumuLg4lShRQvnz57/jY/n5+alw4cIO23x8fBQcHGxtf+GFF/T6668rKChI/v7+euWVV1ShQgWVL1/+3xQbAAAAAIB08a9C96BBg9SvXz9FRkbK29tbM2bMkDFGkydPdkrhRowYIRcXFzVr1kzx8fGqW7euxo0b55RzAQAAAACQ1v5V6P7yyy81btw4de7cWZK0dOlSNWzYUF988YVcXO6qp7qDlStXOvzu5eWlsWPHauzYsf/52AAAAAAA3Gv/KikfOXJEDRo0sH6PjIyUzWbTiRMn0rxgAAAAAAA86P5V6E5MTEyxvJe7u7uuXr2apoUCAAAAAOBh8K+6lxtj1L59e3l6elrbrly5oi5dusjHx8faNmfOnLQrIQAAAAAAD6h/FbrbtWuXYtuzzz6bZoUBAAAAAOBh8q9C95QpU5xVDgAAAAAAHjr/fcpxAAAAAACQKkI3AAAAAABOQugGAAAAAMBJCN0AAAAAADgJoRsAAAAAACchdAMAAAAA4CSEbgAAAAAAnITQDQAAAACAkxC6AQAAAABwEkI3AAAAAABOQugGAAAAAMBJCN0AAAAAADgJoRsAAAAAACchdAMAAAAA4CSEbgAAAAAAnITQDQAAAACAkxC6AQAAAABwEkI3AAAAAABOQugGAAAAAMBJCN0AAAAAADgJoRsAAAAAACchdAMAAAAA4CSEbgAAAAAAnITQDQAAAACAkxC6AQAAAABwEkI3AAAAAABOQugGAAAAAMBJCN0AAAAAADgJoRsAAAAAACchdAMAAAAA4CSEbgAAAAAAnITQDQAAAACAkxC6AQAAAABwEkI3AAAAAABOQugGAAAAAMBJCN0AAAAAADgJoRsAAAAAACchdAMAAAAA4CSEbgAAAAAAnITQDQAAAACAkxC6AQAAAABwEkI3AAAAAABOQugGAAAAAMBJCN0AAAAAADgJoRsAAAAAACchdAMAAAAA4CSEbgAAAAAAnITQDQAAAACAkxC6AQAAAABwEkI3AAAAAABOQugGAAAAAMBJCN0AAAAAADgJoRsAAAAAACchdAMAAAAA4CSEbgAAAAAAnITQDQAAAACAkxC6AQAAAABwEkI3AAAAAABOQugGAAAAAMBJCN0AAAAAADgJoRsAAAAAACchdAMAAAAA4CSEbgAAAAAAnITQDQAAAACAkxC6AQAAAABwEkI3AAAAAABOQugGAAAAAMBJCN0AAAAAADhJuobuwYMHq0yZMvLz81OWLFnUuHFj7d6922GfK1euqGvXrgoODpavr6+aNWumU6dOpVOJAQAAAAC4c+kauletWqWuXbvq999/15IlS3T16lXVqVNHFy9etPbp0aOHFixYoFmzZmnVqlU6ceKEmjZtmo6lBgAAAADgzril58l//vlnh9+nTp2qLFmyaNOmTapatapiYmI0adIkzZgxQzVr1pQkTZkyRQULFtTvv/+u8uXLp0exAQAAAAC4I/fVmO6YmBhJUlBQkCRp06ZNunr1qiIjI619ChQooJw5c2rdunXpUkYAAAAAAO5UurZ0Xy85OVndu3dXpUqVVLhwYUlSdHS0PDw8FBgY6LBvSEiIoqOjUz1OfHy84uPjrd9jY2OdVmYAAAAAAG7lvmnp7tq1q7Zv366ZM2f+p+MMHjxYAQEB1k+OHDnSqIQAAAAAAPw790Xo7tatm3788UetWLFC2bNnt7aHhoYqISFB58+fd9j/1KlTCg0NTfVYvXr1UkxMjPVz9OhRZxYdAAAAAICbStfQbYxRt27dNHfuXC1fvly5c+d2eLxUqVJyd3fXsmXLrG27d+/WkSNHVKFChVSP6enpKX9/f4cfAAAAAADSQ7qO6e7atatmzJih+fPny8/PzxqnHRAQIG9vbwUEBOiFF17Q66+/rqCgIPn7++uVV15RhQoVmLkcAAAAAHDfS9fQ/dlnn0mSqlev7rB9ypQpat++vSRpxIgRcnFxUbNmzRQfH6+6detq3Lhx97ikAAAAAAD8e+kauo0xt93Hy8tLY8eO1dixY+9BiQAAAAAASDv3xURqAAAAAAA8jAjdAAAAAAA4CaEbAAAAAAAnIXQDAAAAAOAkhG4AAAAAAJyE0A0AAAAAgJMQugEAAAAAcBJCNwAAAAAATkLoBgAAAADASQjdAAAAAAA4CaEbAAAAAAAnIXQDAAAAAOAkhG4AAAAAAJyE0A0AAAAAgJMQugEAAAAAcBJCNwAAAAAATkLoBgAAAADASQjdAAAAAAA4CaEbAAAAAAAnIXQDAAAAAOAkhG4AAAAAAJyE0A0AAAAAgJMQugEAAAAAcBJCNwAAAAAATkLoBgAAAADASQjdAAAAAAA4CaEbAAAAAAAnIXQDAAAAAOAkhG4AAAAAAJyE0A0AAAAAgJMQugEAAAAAcBJCNwAAAAAATkLoBgAAAADASQjdAAAAAAA4CaEbAAAAAAAnIXQDAAAAAOAkhG4AAAAAAJyE0A0AAAAAgJMQugEAAAAAcBJCNwAAAAAATkLoBgAAAADASQjdAAAAAAA4CaEbAAAAAAAnIXQDAAAAAOAkhG4AAAAAAJyE0A0AAAAAgJMQugEAAAAAcBJCNwAAAAAATkLoBgAAAADASQjdAAAAAAA4CaEbAAAAAAAnIXQDAAAAAOAkhG4AAAAAAJyE0A0AAAAAgJMQugEAAAAAcBJCNwAAAAAATkLoBgAAAADASQjdAAAAAAA4CaEbAAAAAAAnIXQDAAAAAOAkhG4AAAAAAJyE0A0AAAAAgJMQugEAAAAAcBJCNwAAAAAATkLoBgAAAADASQjdAAAAAAA4CaEbAAAAAAAnIXQDAAAAAOAkhG4AAAAAAJyE0A0AAAAAgJMQugEAAAAAcBJCNwAAAAAATkLoBgAAAADASQjdAAAAAAA4yQMRuseOHavw8HB5eXmpXLly+uOPP9K7SAAAAAAA3NZ9H7q//fZbvf766+rbt682b96sYsWKqW7dujp9+nR6Fw0AAAAAgFu670P38OHD1bFjR3Xo0EEREREaP368MmTIoMmTJ6d30QAAAAAAuCW39C7ArSQkJGjTpk3q1auXtc3FxUWRkZFat25dqs+Jj49XfHy89XtMTIwkKTY21rmFTQNJly+kdxEA3KUHoY5JS0lx8bffCcB951Grqy5cTUzvIgC4SxkegPrKXqcaY265330dus+cOaOkpCSFhIQ4bA8JCdGuXbtSfc7gwYPVv3//FNtz5MjhlDICgCQF9EjvEgDA7QVoXHoXAQDuTEBAepfgjl24cEEBtyjvfR2670avXr30+uuvW78nJyfr3LlzCg4Ols1mS8eS4VEWGxurHDly6OjRo/L390/v4gBAqqirADwoqK9wPzDG6MKFCwoLC7vlfvd16M6UKZNcXV116tQph+2nTp1SaGhoqs/x9PSUp6enw7bAwEBnFRH4V/z9/fnDAOC+R10F4EFBfYX0dqsWbrv7eiI1Dw8PlSpVSsuWLbO2JScna9myZapQoUI6lgwAAAAAgNu7r1u6Jen1119Xu3btVLp0aZUtW1YjR47UxYsX1aFDh/QuGgAAAAAAt3Tfh+4WLVrof//7n95//31FR0erePHi+vnnn1NMrgbczzw9PdW3b98UQx8A4H5CXQXgQUF9hQeJzdxufnMAAAAAAHBX7usx3QAAAAAAPMgI3QAAAAAAOAmhGwAAAAAAJyF0A2mIKRIAAADSRnx8vDZs2JDexQD+M0I3cJeuD9iXLl3S9OnTZbPZ0rFEAJC65ORk6///97//6eWXX9b8+fPTsUQAcHubNm1S69atNWHCBEk0buDBRegG7tL1AfvixYt699139emnnyomJiYdSwUAKbm4/PPnPnPmzMqVK5dGjhypJUuWSOJGFsC9d/2XgdfbtWuXli1bJkmqWLGiJk+erPfee0/r16+ncQMPLEI3cBs3+6Pw66+/6uuvv9bly5eVOXNmTZw4UfPnz9cXX3whiZtYAOnnxvpn6dKlKlSokM6dOydJevXVV1W5cmW98cYbMsZwIwvAqYwxKeql678MvN5bb72lQYMG6fjx45KkKlWqqHbt2hoyZIi2b9/u9LICzkDoBq5zuz8KxhglJSVJkmbPnq3XX3/duomtW7euWrVqpaFDh2r37t3cxAJwmuTkZIcvBO31VmJiorZu3SqbzeZQl2XPnl1//fWX9u/fL0ny9vbWW2+9pWPHjmncuHFKTEy8txcA4KF3fT1ls9kc7ouMMXrttdc0ceJEa5u9Hqpdu7aSkpKs+kq69kXhhQsXNH369HtUeiBtEbrxyEtKSrJuTm/8o2DvNt62bVtrX/vj7du3V2xsrPVNrCQ9//zzCgkJ0dSpU7mJBeA0Li4u1heCly5dsuqlwYMHq169eoqNjXWoywoUKKBcuXJp+fLlkq7dDPv5+al9+/aaNWuWdu3ade8vAsBDzV5PJSQkaNGiRRo3bpy2bdtm9a7ZvXu3Zs6c6bC/JFWoUEEXLlxwaNUuXry4ypUrpx9++OGeXweQFgjdeOS5urrKZrPpxIkTmjBhgnr37q2FCxdKktzd3ZWUlKQVK1ZIktzc3Kw/CiVKlJCLi4s2bdpkhXZXV1fVq1dPGzZs4CYWwF0zxtx0aMvevXs1YMAAVahQQY8//ri6dOmilStXSpKKFi2qzJkz648//pAkq2eOJFWvXl2//PKLQ3fypk2b6ty5c8wODOCu3KyeSkhI0LfffqvHH39cPj4+eumllzR16lTVq1dPH3zwgSSpdevWioqK0tmzZyX9E7qLFy8uf39/7dq1y6rDvLy8VKFCBZ05c0Zbtmy5B1cGpC1CNx56t7p5vXr1qsaNG6fs2bMrd+7cGjdunKKiotSsWTO9+eabcnNzU40aNRQTE6N9+/ZZx7O3YpcvX14rV67UpUuXrGNWqVJFly5d0ubNm51/cQAeGtfXVTabLdXxjgMGDNDjjz+uWbNmqXXr1nr33Xe1adMmdezYUZs3b1bJkiUVGBhoTUJ0vQYNGmjjxo06ffq0FbrLli0rHx8fHThw4Kb1JADcjL2eOnTokBYuXGi1Tl+5ckWLFi3SyZMndf78eR06dEjffvutKleurCFDhujq1auqUaOGzp8/79CinZycLDc3NxUsWFD79+/X4cOHrceyZcumXLly6ffff7+3FwmkAUI3HnrX37xGRUXp999/V0JCgqRrLdkbNmyQv7+//vrrL23dulVz5szRs88+q2+++UYbNmxQsWLFlDlzZqv1Ozk52bphfeqpp7R27VqdOXPGOl+hQoXk4uLisA0AbsdeV129elU//fSTevbsqffff1+//fabNXdEeHi4SpcurZEjR+qVV15Ru3btNH36dF26dElz585Vjhw59Nhjj1kt3a6urtbxq1atqsuXL2vbtm2SrtVlHh4e8vPz07lz53T16tV7f9EAHljR0dF6++23lS1bNqteevvttzVlyhT5+/urVq1a8vDwsOqh3Llzq3Pnzrp8+bLWrFmjHDlyKE+ePFq6dKl1THvPwbJly+rMmTMOodvHx0eZMmXSxYsX7+2FAmmA0I2H2pUrV/Ttt9+qRo0aypgxo9q1a6dPPvlEb775pg4ePCjp2nIUGTNm1IEDByRdC+KtWrWSzWbTli1blDVrVpUsWVKLFi2yjmsP8Q0bNtTJkyd1+vRp67Hw8HCdOXNGGTJkuIdXCuBBFxcXp3fffVfZs2dXt27dFBsbq8uXL2vChAlWS1ClSpWUnJysdevWWc97/PHHlZycrAsXLkiSihQpopMnT1rzTdgniMyUKZPy5MljdSW3h+xcuXLpyJEj8vT0ZNUF4BGX2oSyqbl69aoGDRqk9evXa8CAAdq3b5++/fZb9erVSzVr1pQkPfbYY3Jzc9PixYut5x04cEDu7u6Ki4uTJEVGRmrJkiUpvvQrX768Dh8+7NCTMFeuXDp8+LBy5syZFpcK3FNu6V0A4N+y/0G42VIT0rVxjK6urpo6daomTZqkKlWqaOjQocqXL5927NghFxcXZcuWTdK1sUOurq7asGGDIiMjJV27+f3f//6nnDlzyhijSpUq6cMPP5Tk2HKUJ08eubm56dSpU5Kuzbzp5uYmDw8P65tYluMBHk3X37zeqr6SrrU6f/zxx5o1a5bGjRun+vXrK0OGDLpw4YL8/Pys/fLkyaOQkBAdOXLE2rZixQrFx8ercuXKkq6FcDc3N61cuVJt2rRRUlKSNR9Fnjx5tGfPHknXvmCUrnXZPHnyZJpeO4AHx80mk72Vr776SpMnT9aECRPUpk0ba7u9HpKkHDlyqECBAlq6dKmeeuopjRkzRkOHDlXTpk1Vr149SdIzzzyjSZMmadeuXSpSpIh1j2Wz2XT69Gnlzp1b0rX7Ond3d124cEFBQUFpct3AvURLNx4Y1/9RuN0NrKurq5YvX67u3burXr16GjRokEqVKqWAgABVrFhR5cuXl4eHh6Rr38SGhIRo586d+vPPP/Xuu++qY8eOatSokWrXri2bzaayZcsqLi7OmqzIXpY1a9YoKCjIGuPt5uammJgYFSxYUN7e3k56JQA8COx1lYuLiy5fvnzLffft26cPP/xQvXr1UrNmzayeMvbAvXv3bmuyoSJFimjjxo1q2bKlChUqpEaNGqlFixZW61LRokWVJ08effPNN5Ku1UuS9Ouvv2rr1q2qUaOGpH++CNi2bZuefPJJq8wAHl72uSOun8PBHraPHDmiCRMmaPjw4Tp69OhNny9J8+fPV5kyZRwCt/1x+z5BQUGqWrWqxo4dq6CgIE2ZMkXdunXTuHHjrHqpRo0aCgkJ0bBhw6yhLydPnlS/fv3UuHFjq4HE3jhSuHBh+fv7p+2LAtwDhG48EK5vLV6/fr369Omj0aNH33RcjzFGixYtUubMmTVgwAArAMfExGjy5Mlq2bKl6tSpowsXLiggIED58+fX/PnzVa1aNUVFRWnIkCH65ptvrJagMmXKqEaNGnrvvfe0bNkyJSUlae/evRo3bpyqVq2qyMhI6w/YuXPntHHjRj3xxBOSuIkFHlVbt25V165d9dhjj6l27do3vYmVpG+//Vb+/v6qWrWqtW3dunWqXr26AgMDVblyZS1YsEDStVnIT548qYMHD6p37946ffq0PvvsM6v1J1u2bOrSpYsWL16s9u3ba/Hixfrkk0/Uv39/PfHEE2rZsqWkf2YdPnnypHLlyuWslwFAOrtxvWz7l4H2Lt2xsbHq3LmzihUrpqlTp2rWrFl64okn9N1330lyXAXBZrPpzJkzOn/+vBWcr18i9frWci8vLxUtWlQ+Pj5aunSpNm3apDfffFMZM2Z0OO64ceO0c+dOvfzyyypfvrwKFy6sM2fOqE+fPgoICHDoMVSwYEGVLVvWmS8X4BSEbtwX7N+83mwckc1m09GjR1WrVi01atRIa9euVXx8vGJjY2+6/59//qm8efM6tDANHjxYEyZM0Llz57Rr1y799ttvkqTChQsrX758GjVqlH766Se1a9dO7u7uVnnc3d01ZMgQBQQE6M0331SpUqVUokQJXbp0SW+99ZZ8fX2tVqPAwEC1aNFCWbJkScuXCMB94lZ1ld2RI0f09ttv6/Dhw+rdu7f69OljfYl3PftN5+XLl+Xr6+vwRaKHh4caNGigCRMmqHjx4lYrUIkSJZQzZ041aNBArVq1UqZMmZSUlGTdVBtjVK9ePX3zzTdKTk5Wz549NWfOHDVs2FCDBg2Sh4eHNUTn/PnzGjx4sCpWrJhWLw+A+4w9ZEvSypUr9dJLLykwMFCdOnVSYmKivv32Wy1dulTLly/X2rVrNWXKFBUoUECTJ0+WlLLxIDAwUD4+Pjp37pwuX75shW+761vRH3vsMQUHB2vr1q2S5DB2296V/IknntCiRYvUrVs3denSRVu3btXSpUtVokQJh/OXKFFCAwcOTMNXBrh3GNON+8L134wmJyen6D5+9epV9ejRQ1mzZtWsWbOsFp3Ubnzt47ntY62PHz+ufPnySZL69Omjjz76SLt27dLLL7+slStXqn79+ipUqJAyZsyov/76y+EY1/+hKVSokBYuXKilS5fKxcVFFStWlJeXV4rz+/r6asCAAQ5jvwE8POz108mTJxUXF6e8efNa2+y9crp27aqAgACrpeh2xypZsqQ++eQTHT9+XMWKFZMklSpVSqVKlZIkLVmyRPv27dOlS5cUEhKinDlzas+ePTpz5owyZcrkUN/YbDYZY/T000+rQYMGqU7qaK/bAgMDVa1atf/4igC4X23dulXz5s3TwoUL9eeff+rq1atq3bq1NbbaZrNp7969CgwMtEJugQIFdPHiRRUqVEiS45wUxhi5ubmpUKFC2rBhg6KiolS+fHnrvsm+f2Jioi5fvqzcuXOrRIkS+vHHH/X888/ftPdfcHCwWrRo4XAeyTHwu7i4MEktHli0dOOeudV62du2bVOvXr1UqlQpff755ykeP3bsmP744w+9//778vT01FdffaWFCxfectmIyMhI7du3z5r1NzExUT4+PpKuzYBZqFAha1mdggULKkeOHNq+fbsSExNvGZgjIyNVs2ZNeXl5pdri5e7uTuAGHmA3jne83uXLl621ZrNly6ZevXpZs4bbA/euXbsUGxurZs2aacGCBapdu7aee+45zZw5M8Vx7TeUVatWlc1m0+rVqxUfH289bm8Jz5s3r/bt22e1FhUtWlR//vmnVb/dWA/Zj2u/Qb3VNQF48BhjrPrh+s9/fHy8FixYoAMHDmjs2LEqWbKk1q5dq4YNG6p8+fJ6/vnn9dVXX+nFF19UUFCQXF1dVbJkSW3ZskWTJ0/W4sWL1alTJ506dUodO3Z0ON/1/33iiSfk5+enjz/+WMYYh/uezZs3q127dlq1apX8/PwUERGhX3/9VZJStIqndl3Sv5vUDXgQELrhdKlNgHZ996IDBw6od+/eioqK0oEDB7Rz506r27j9JvGXX35RwYIF9f3336tcuXL69NNP9f7776tRo0bavHmzw772czRu3FgBAQGaNGmSJMeK3hijEydO6NixYzpz5ow8PDwUFham2NhYHTt27I6vzcXFhT8KwAPuxsB6fVfMjRs36s8//7TGLJ47d06bN29W9erV9eqrr2rr1q06f/68w3Hc3Ny0bds2bd++XSNGjFCFChWUPXt2q3XpxqVxkpOTlSVLFjVt2lQTJ050WLPW1dVVFy5c0IEDB5QlSxYFBARIkmrXrq169epZkwzdrh66/poAPHhubLiw2WxydXVVUlKSbDab9diZM2f01FNPae3atWrbtq0SEhL0yy+/qG/fvipdurT279+vEydOSPrnvqlFixZavHixpk+frqZNm+rYsWPKmDGjnn76aY0aNcqhHPZ6pEqVKhowYIBWrFihMmXKaNKkSVq4cKEGDhyod999VyEhIdbkjq+99pq1LOvtcE+Fh5YB0khycrJJSkoySUlJKR47evSoGT58uKlZs6YpVqyY6dGjh9m8ebMxxpgTJ06YL774wkRHR5uePXuaKlWqmF27dhljjLl69aoxxpg5c+YYd3d3U6RIEfPll1+a+Ph48+uvv5ratWub2rVr37RMI0eONG5ubqZly5Zm5syZJioqysybN8907tzZVK9e3SxatMja9/z582n5cgC4TyUnJ5vExESTnJyc4rGzZ8+aDz74wJQpU8Z4enqarFmzmgIFCpiOHTsaY4y5cuWK+fPPP82lS5fM0aNHjc1mM8uWLXM4RmJiogkODjY2m83MmDHD2j5kyBBTokQJs3LlSmOMsepK+393795tmjVrZmw2m6lXr5758MMPTbNmzUyePHlM1apVzZIlS5zyegB48Ozdu9eULVvWREREmNOnTxtjjFWnFS5c2LzzzjvmypUrxhhjEhISjDHGTJo0yZQrV84sXLjQGGMc7td++uknU6BAAbN161ZjzLW6cNiwYcbHx8d6fmp+/PFH07p1a1O5cmWTNWtWU7VqVfP555+bc+fOpf1FAw8wQjf+s9RCdmxsrFXhvvXWW8Zms5mIiAjz4Ycfmk8++cRkz57dFCtWzOzcudPhecuWLTO5cuVK8Qfh7NmzxmazmcKFCzvsP3PmTBMSEmIOHTpkjDGp3kRPnjzZVKlSxZQqVcqEhISYLFmymLZt25pff/011f1T2wbg4XT8+HEzbtw4M2HCBGOMMatWrTI2m810797d7Nu3zxw/ftwMHDjQ2Gw2M3ny5BTPz5IlixkwYIBJTEw0xvxTfzRo0MCEhoaaPXv2WPtu3LjRVK1a1XzyySfGmNTrzosXL5rZs2ebLl26mFq1apnOnTubxYsXp1r25ORk6ivgIXXx4kXz7LPPmsuXLxtjjDl9+rRp2LCh+euvv4wxxuzYscOEhIQYm81m2rRpY3bs2GE9t1OnTqZ69erm2LFjxph/GjA2bdpkqlataj744ANjzD91UEJCgunevbtp1aqVQxl27txp3NzczIEDB25Z1uTkZBMdHZ0GVw08vOhrhrtmrlvCQZJWrFihLl26KE+ePAoICNDs2bMlSfny5VOBAgX0zTffqFevXnrzzTc1d+5c7dq1S4sWLZL0Txcn+wy6u3btsmbXTU5OVlBQkIoXLy4/Pz8dP37cKkNISIhCQkK0b9++m5azQ4cOWr16tSZPnqytW7fq1KlTmjZtmipXrpxqNya6NgEPB3sd9eeffzqMu16wYIHatWunLFmyKGfOnBo/frxVj1WtWlXe3t6qWLGi8ubNq6xZs+q9995TwYIFtXz5cmseiYSEBElSzZo1tXLlSsXFxUn6py5r1KiR4uLidPDgQas8QUFBOnbsmPLmzStJqXb39vb2VrNmzTRmzBgtXbpU48ePV506dRyux44xj8DDa/v27dq3b5/+97//SbpWt6xZs0Y//PCDJCksLEwVK1ZU8eLFlZSUpK5du1rLEjZo0EB//fWX9bt9vPXjjz+u0NBQay4Iex3k7u6uU6dOWUNZ7MaOHavHHnvstvWMzWZTSEiIVc4b6yoAjOnGXfjxxx/14osv6tSpU5Kk5cuXy83NTU8++aTOnz+vfv366cSJE9YEHHXq1FFMTIw2btyopKQkGWNUsmRJ2Ww2xcfHO4RrLy8vFShQQFu2bNHZs2cl/TORUKtWrXT27FktW7bMKsvy5ct15coVa4bNm/1hMMaoaNGiCg0NtSYf4Y8C8HCz2Ww6fPiwIiMjdenSJWvbU089pZ07d+qLL77Q33//raioKL3wwgtWYC5atKgWLFigCxcuONQply9ftiZjtN/ENmvWTJs2bdLJkycl/XMT+8wzzyh//vwaOnSoDh06pMTERC1evFjGGGtG8puV2fz/pETmhqUUCdjAg81c62F6y33s9dCcOXOUP39+5ciRQ9K12b0bN26shQsXSpJ8fHxUvHhxXb58WUOHDtWFCxfUtm1bSdfmfLhy5Yq1Iou9XvHx8dFjjz2mkydPWo0V9vkq2rZtq127dqlt27Z69913FRkZqSVLlqhv374KDw+/42tkrhsgdYRu3DH7H4L9+/fr2LFjCg0NlXRtJvCgoCB9/vnnmjlzptq2bWs9Zn88S5Ys2r9/v7UM1+zZs5UhQwYVLVrU+mNg/0NUvXp17dixw5row34T2759e9WvX1+dO3dW//799corr+inn35Sr169HM6Xmuv/ANgnH+GPAvDw++OPP1S+fHn5+vpa28qWLaty5cqpYcOG8vPzS/GcJ554Qps3b5abm5vi4+PVp08fnTt3Tq1bt7b2sYfu+vXrKyYmRrt375b0T10THByscePGKTo6Wq1atVLevHk1YMAADR06VDlz5rxlme3HsE8+SV0FPBxu7J2S2ooC9sd9fHyslmrz/8t01ahRQxs2bFBSUpLc3d1VrVo1q+75/vvvtWvXLnXq1EkZMmRQsWLFtG7dOquXj/1cxYoVU2JiorZs2eJw3nr16mn27NmqWrWqdu7cqcjISC1atEjNmzdP+xcCeASxTjfumH3dxV27dqlMmTLW9rx58yosLMzqrmR3/Phx+fr6KiAgQGXLltUvv/yiv//+W+vXr9eWLVv08ssvq0qVKpIcZzavW7euxo4dq4MHD6po0aK6cOGCAgMDlTlzZg0ePFhlypTR9OnT5e3trT59+uiJJ564dy8CgPtG//795e/vr65du8rDw8PhseTkZLm4uGjNmjUKDg6Wj4+Prl69Knd3d9WvX1+zZ8+26pzVq1dr3bp1atSokSIiItS0aVP16dNHEREROnPmjHLmzKkPPvhADRs2THEOHx8fPf744/rtt99UqFAhHT16VPny5VOOHDlUvnx5LVu2TCtXrpSPj49q164td3f3e/b6ALi/HDp0SKNGjVLlypXVtGnTVIeY2Gw2JSYm6vz588qSJYu1TZJKlSqlxMRErVu3TpUrV1a+fPmUJUsWLViwQF26dNGkSZPUvXt3DRgwQCVKlNDGjRsVHR3t8OVi0aJF5eLiouXLl+uZZ55xWOqrWLFiKlasmJNfBeDRREs37pj9m9Z169ZZLcv2pW/KlCmjNWvWaPDgwWrSpIl8fHzUvn17a/x106ZNtWXLFm3dulWdOnXSsWPHNGbMGPn7+1vHt/9RsY8fGjp0qCpVqqTIyEir66a3t7fatGmjRYsWac6cOWrcuPFt13wE8HCxDznZsGGDfv75Z2vM4/XdNu31iZeXl/bv3+/weNOmTbVjxw6VLl1aGTNmVPPmzfX777/L29tbklSwYEEFBwerfPny2rp1q3bs2KGOHTvK09PToRx///23tm7dKldXVw0bNkyPPfaYOnbsqL1791r7ZM6cWc8884waNGggd3d31soGHiE3jm8ODg7WkiVLtGvXLh0+fFjDhg1TdHS0w3Ps91r2FurrH8+RI4cKFixojesOCgpShQoVrC7nDRo00MiRI7V48WKrbjxy5Iikf3rn5M2bV5UqVVLx4sVljEm1J01ycjJ1FZDGCN1QcnKyNabnTgQGBloTbdhvfhs3bqxff/1V06ZNU0REhObPn6/vv/9eERERkqRy5copa9asat++vTp37qywsLAU46qNMXr11VeVNWtWRUdH6+rVq6pYsaLGjx+vrFmzplpuxmUDjxZ7nSNdm+fh6NGjOnz4cIr9bDabkpKS5OfnpytXrkiS1RpepEgRBQUFKSQkRD///LMOHTqkuXPnKnfu3FZdWKZMGcXHx1uTA91YRyYmJmrixIkqWbKkgoKCNHbsWO3cuVP79u2z1qa1u374DGtlAw+368PqjcNDDhw4oLi4OPXr108RERH64osvdO7cuVSfny9fPh09etSaP0eSfH19VaNGDWsSWk9PT0VGRmrNmjXWPg0aNNBHH32kQ4cOae/evdqyZYtDmVxdXfXxxx+rc+fONx264uLiQl0FpDGaCOFQuUZHR8vX11e+vr4pvgG12WyKi4tTvnz5rK7k9lbm8uXLKywsTD169FDnzp0djm+MUWBgoPLkyaMtW7YoJiZGAQEBDl2a7McvW7as1e3qdi3Y/EEAHj32euPw4cMqVKiQLl68qN27d6tixYopbiBdXV3l5eUlm82mAwcOKE+ePEpISJCHh4dKliwpX19fFS1aVF5eXlZ9Zz/G008/rb59++r06dPy9fVNUR+5ubmpc+fOeuedd1KUMbW6E8Cj4fp7kyVLlujQoUOqW7eucubMqUOHDilfvnzy9fXV2LFjVbVq1RTPt9cX1apV0xdffKFt27ZZXb5dXFxUo0YNjR49WrGxsfL391eFChV0/vx5RUVFWeO1K1eurGnTpunkyZNq2bJlqvdL9iE4AO4NPm2PiKSkJIcWousdO3ZMzz//vDJnzqyaNWuqS5cuWrlypWw2W4ruRRkyZFCePHl0/PhxXb16VW5ubkpOTlZwcLBy5cqlrVu3KiYmxuE59mNUqlRJq1ev1qFDhySlXP5Gkp599lk1b97cOi6t2cCjJSkpyaHeufHzP2zYMAUFBalGjRoaN26czp8/r7/++staysvOfoxcuXLJZrNp48aNDsdr2rSpfvvtN4dWJMlxgrTjx49r165dNy1rxowZrXNdX2ZCNvDwsvcOTO3e5OLFi5oxY4a+//57de3aVe3atdMnn3yiNm3aaPny5XrqqafUr18/eXp6WsNebrw3swfhsmXL6vHHH9cvv/yiy5cvW48XLVpUvr6+WrJkiSQpW7ZsypEjhzZv3izpn8aQFi1aqHv37jedaJbADdxbfOIeAvabvU6dOql58+bW0jg3dieyL0FzvYSEBA0ZMkSxsbH68ssv9d133yljxoxq3769Ll++nKJSdnFxUeHChXXp0iWtWrVK0j/juqtWraodO3ZY469vXOamYcOGKl26tAIDAx223+j6bpjM3As8WlxdXeXi4qLY2Fjt2LHD4fO/bds2TZw4UW+99Zb27t2ryMhIhYWFafXq1Tp9+rSklPVOiRIlFBYWZo2BtIfqJ598UmfOnLGWzbn+PMYYZc2aVd9//72qV69+2zLTFRN4dLi4uMjNzU02m03nz593CMSHDh3SmDFj1KVLFwUGBurEiROaNWuWPDw8NHr0aElSoUKF5OnpaS3ndWOvP+mf3jLt27fXli1b9Msvv1iPZc6cWfnz59e6deskSVmyZNGePXvUoUOHFMdhXDZw/+Au4QE2Z84c1atXz1r2oVOnTho0aJAyZMgg6Z9vMePj4zVq1CgVL15cVapU0TfffGMd49SpU5ozZ45GjBih+vXrKzw8XFWqVNGRI0c0bdo0h/PZb2YrVKigAgUKaMKECZL++Va1bt262rVrl8O6kNeXo1KlSpo2bZpy5cp1y+siZAMPr+Tk5Jv2upGk2bNnq1ChQsqVK5fatGmj7t27a9u2bZKk+fPny9XVVZ06dZKrq6uaN2+uDz74QPv379fBgwclOS63JUl58uRR06ZNNW/ePJ05c0Zubm4yxigsLEyJiYlasmRJivLYe/k0adLEqk8BwBijDRs26MUXX1SOHDlUtWpVvfLKK9Z9T3h4uMqVK6eEhAS9+eabkq7NCN6iRQtt2rRJJ0+etIbb7du3z1oa9cZwbK+/mjVrprp162ro0KHWXDpeXl5asWKFhg4dau3r4eGRasDmy0Dg/sGn8QFkr1gzZcqkLVu2WJV26dKllT9/fsXHx0uSzpw5o6CgII0cOVKbNm1Sp06dVLRoUbVt21YLFiyQdO0mNnfu3Prggw9UrFgxZc2aVf369dMLL7yg8uXLO5zX/kcgc+bMeuONN7RixQqtWrXK+pa2YsWKioiIcJiRPLWy010cePRc34PFXmfYe+XYRUVFadSoUXr22We1a9cujR49WkePHrVuXj09PXXhwgUFBQVZE5vVq1dPiYmJ2rlzZ6rntdlsevbZZ5U/f34NGzZM586ds+qymTNnql27dqm2NHGzCjxcbnf/cbPHtmzZYs0AHhsbq2HDhskYo08//VQjR47U3r179dZbb+nixYvy8fFRwYIF5eXlpTNnzljHKFCggLy8vLRs2TJJ1yZqPH36tPWFYmr1jb08vXr1UkREhFUPurq6WvPuXI86C7i/8Ql9QBhjrNm+7RVr1apV5e/vr+3bt1s3oMWLF9fAgQN19epVZcqUSXny5NF7772npk2b6uWXX9bYsWPVuHFjjR07VtK1b2WjoqK0d+9e9ejRQ5s2bdL27ds1ceJEFS9e/KblqVWrltq0aaNBgwZZLUweHh5auXKlatWqddPn0V0ceDTceENon4hx//79atKkiTJnzqy2bdtq8eLF1j4rVqyQj4+PevXqpZCQEHl7e8vNzU1LlizR/v37lTdvXp0+fVoXLlyw5n3w8/NTYGCgNm7cmGI+Cemf8ZJDhw7Vjh071LdvX0nXbsCbN29urbAA4OFmv/84deqUFi1aZE0IK12rD+z3JvaGC+na8LlSpUpp7ty5Sk5OVkBAgJo1a6ZJkyapadOmqlmzprV6y+rVqyVd612TPXt2rVixwjpOrly5lC9fPi1dulSSVKNGDbm5uWnIkCF68803VbVqVcXGxjqU116e4OBgjRo1StWrV9fZs2dTPA7gwUDofkDYbDa5urqmqGQLFSqkrVu3WuOow8PD9fvvv1uTClWtWlV58uRRtWrVrOM0b95c69at0+nTp1W8eHFlzpxZtWvXVvv27fXYY4/JxcVF586d07Bhw1JMTnS9kSNHysvLS19++aXi4uIkXbvRZgwR8Gi5cSIx+3jEK1euWHXIpEmTFBYWZi0rOHHiRCUkJKhVq1a6ePGikpKStHbtWiUkJCgyMlIZM2ZUo0aNlJCQoHHjxilbtmwqWbKkAgMDNXHiREnXbqKXL1+u8+fP69ChQ9YXgNcHfnsrdq1atdSnTx9duXJFBw4csL68pOcN8Gj44osvVLBgQeXOnVvvvvuunn76adWvX1/R0dFWfRAeHq5x48ZZy/y5u7urcuXK2rlzp3Wf88wzz2jt2rWqV6+egoODNXLkSLm4uGjOnDmSroXunDlzWiFckkJCQlSyZEn9/vvvkq4tWzhy5EgFBQXp8OHDatOmjXx8fFIttzFGnp6eevXVVxUcHOzMlwiAExG67yO3Guu4bds2ffDBB3rzzTe1du1a65vYGjVq6K+//tLx48clXVu3duPGjYqOjpYk1axZU8eOHdOFCxesY9WqVUtxcXHauHGjsmfPrrZt2+rTTz9Vnz59tHXrVv3444966623tHLlSus4N7LfqE6YMEFt2rSxbmxtNhtdnIAH3PU9a272+I1r0V7/ubfZbDp48KCCg4OtCYDKly+vuLg4LVu2TD169FDjxo311VdfKTk5Wd98841cXV0VEBCgHTt2qHjx4lq+fLn27NmjuXPnqkuXLvLy8lJ4eLheffVVDRkyRF27dtXMmTM1Y8YMNWvWTCdPnrRuim/WAlSmTBmNHj1auXPndigrgIfbjz/+qFGjRqlTp046cuSIli5dqg8//FBRUVFq1KiR1c07LCxM69ev16VLl6y6ITIyUuvXr7dWOti9e7feeust5cmTR8uWLdOOHTvUokULa3LZ7Nmzq3DhwtqzZ491T+fl5aW8efMqOTnZul8rXry4Zs2apVmzZqlz586pDnORqKOAhwXp6D6Q2ljH633++edq0KCBfv31V504cUIdOnTQe++9J+naH4Nz585ZE2w0bNhQMTEx2r17t6Rrk5clJydbS0kYYxQUFKSIiAitXLlSktS3b1+98cYb2rJlixo2bKgXX3xRycnJ6t27t/LkyZNqme1/BEJDQ5UvXz55e3un3QsCIF1d37MmNjbWoSeL/XF7yN67d6+Sk5MVGRnpMMNu7ty5lTFjRu3evVsJCQmKiIhQzpw5VbVqVWXKlEmSFBAQoMqVK1tzTJQsWVKZMmVSnTp1VKJECfn5+UmSfv31Vw0bNkyS1L17d3366afauHGj3nnnHYWEhGjEiBHatWuXKleufNtrs6/bDeDhZ4zR1atX1b17dxUrVkzdu3dXUFCQgoKC1LRpU40bN05Hjx7VuHHjJF1bZuu3335zGI/9xBNP6NChQzp8+LCka3NPbNq0SQMGDFDx4sXl5uamnTt36tChQzp+/Lg8PDyULVs27d+/X5s2bbKO07JlS+3Zs0fZsmVz+EKTuW6ARwOh+x66Wddrm82mS5cuadasWXr++efVo0cPa3K07du3q1evXvr666+1ZMkSzZgxQ+PGjdPw4cN19OhRFSpUSIGBgdq2bZsuXrwoX19f5c2bV6tXr1Z8fLwyZsyoYsWKWeOI7CpVqqSZM2daYyDffvttffnll9q8ebOio6M1efJklStXjptT4BGTmJion376Sa1atVKuXLlUrlw5dezYUevXr7fGZa9fv15LlixR0aJFVb58ebm4uGjTpk1atWqVw/q1FSpU0Nq1a/X333/LZrOpQoUK2rJli9V1U5IaNWqk9evXKzY2Vk2aNFGpUqXUqlUrTZgwQStXrlTfvn3Vr18/nT17VsYYZciQQS1atNDq1at16NAhDRo0SH5+frLZbNy4AnBgs9m0aNEiHT9+XE2aNJHNZnO4r6lWrZpq165tffH35JNP6sSJE9Ya2tK1LwONMdZKMTabTb6+vlq1apUuXbqkr776Sn5+fkpMTNT3338v6doEj4sXL1aZMmWs49gbJ64fPy4x1w3wqCB0/0e364Yp/TPb+M26Xu/cuVMVKlTQe++9J2OMQkNDdf78eUnShg0bVKdOHeXLl0/Tp09X06ZN1b59e7m6ulqTgJQpU0ZRUVFWV/C6devq119/tSblqFu3rn744QdduXLFqtg7d+6s7t27O7RQBwUFKSQk5I6uCcDDJykpSe3bt1ejRo3k4eGhUaNGadCgQVqxYoVeeeUV/f333/rss8/UokULDRw4UK+//rpVDzVt2lS//vqrLly4YNUzDRs2VFRUlDXnRIMGDfTHH3/o7Nmz1j716tXT33//rT///FOhoaEaPXq0OnXqpG+//VYtWrTQihUr1KpVK/Xs2dPhxtTT0zPFWHJuXAHcyMPDQ/Hx8VYPm+uDd8aMGVW+fHmdOHFCJ0+eVO7cuZUpUyatX7/e6hp+5coVBQUF6c8//1RsbKzq1aunRo0a6Y033lBwcLDGjx+vbt26adOmTerQoYOMMQoPD1fp0qVTrZMYggc8mtzSuwAPOns3TEk6e/as/v77b+XLl89hH3sFu3PnTq1Zs0bZsmVTgwYNrMc//vhj5c6dW7NmzZK7u7uuXr0qd3d3Sde6bv78889asGCB8uTJoxo1aqhz584qVaqU9QekTp066t+/v44ePaq8efOqWbNmGjdunA4dOqTMmTOrbt26mj9/vuLi4uTl5SVJKlGihEqUKHHbawLw6HB1dVXBggVVtWpVffDBB8qVK5ekazedb7zxhlatWqU6depo9OjR8vb2Vvv27a35JZo0aaJWrVrpxIkTypgxo6Rrgbpz587at2+fihcvrho1aiguLk47d+5U1apVZYyxzrFw4UJVqlRJ/v7+Gjx4sM6cOWPVcTfDzSuA2wkNDZWrq6uOHTtmTfIoXWsQcXFxkbe3t/z8/LR7925lzZpVTZo00ffff68yZcooMjJSkyZN0pUrV7Rs2TLt3btXpUqV0pgxY7R+/XqFhoaqYMGC6XyFAB4E3LH8B/ZumC1btlRoaKgiIiLUqlUrvfHGGw77zZ07V2XLllWlSpU0bdo0vfzyy3r11Vd17NgxSdLBgwfl4eGhP/74QytXrtSxY8esMZRFihSRn5+fJkyYoG3btmnUqFGqW7eugoKCtGvXLknXJlM7f/68NRFIjRo1lDNnTiUkJEi61pU8KioqxQ0ss4wDuFGxYsV05coVLVmyxNqWPXt2Xbp0SadOnVJ4eLjCw8OtL/DsXxDWqVNHly5d0o4dO6znhYaGysfHR1u2bNGlS5eUPXt2Zc+e3Zrl127KlCl6+umnHVqF7PUV4x0B/Bf2Omvx4sX6+++/JTmuWhAdHa2MGTMqb968kqSuXbsqc+bMevHFF5UvXz4tWLBA8+fPV7du3ax9MmTIoBo1aliBmzoKwO0Quu/S9d0wPT099cUXX2j9+vVq3bq1RowY4TCG+siRI3rmmWd08uRJ/fbbb/riiy+0bds2ff3115KkPn366Pjx43rqqac0ZMgQNWnSRCVKlNDq1atVp04dhYSEaP78+dYfi6tXr2r+/Pnq37+/4uLiFBoaqgIFCsjDw8MK2ocOHVKlSpWsMlw/htKOViIANypSpIgCAwO1b98+a9uqVavk7++vWrVqKSAgQIUKFdLly5d1/vx5ubi4KDExUR4eHipfvrzmzZunI0eOSLq2rGBcXJx+++03a/hLixYtFBAQIOmf7uCtW7dWyZIlUy0P4x0B/BeBgYFq3bq1Zs+ebY25tg/327ZtmyZNmqR69eopR44ckqSiRYvq22+/1bvvvqtPPvnEajh59913FRgYmOo5qKMA3I7N8PXcXRs0aJCWLFmiyZMnW7N8X7lyRUWKFFH79u2tGcZPnTqlzJkzW8vlfPvtt5o7d64qV66sZcuWKTExUVeuXFF8fLzVej169GidOXNGP//8szZu3KinnnpKjz/+uDJlyqStW7dKujYu+6WXXpK/v3+q5bN3nQKAf6Nz585au3atQkJCtHnzZtlsNg0cOFAdO3aUm5ubxowZo+nTp2vo0KGqXLmyEhIS5OHhoZkzZ+r9999X9uzZFRwcLD8/P5UpU0arV6/WiBEjFBoaetNzXt/tEwDS0unTp9WtWzfNnj1bXbp0UdOmTbVt2zbNmTNH/v7+mjVrljJkyHDLY1BHAfgvSGT/QbFixZSQkKCoqChr27Rp05QtWza1bt3a2hYSEqLVq1erWrVq6tu3r/z9/dW5c2dt3LhRFy9elJubm3x9fZUxY0ZVqlRJlSpV0uXLlxUSEqKLFy+qfPny2rx5szp06KC8efNq5MiR2r17t95++22HwH1jd3ECN4C7UaxYMZ07d04hISFasmSJzp49q5deeklubtemASlevLg8PT2t5XDsdc0zzzyjGTNmKGfOnAoLC9Mrr7yil156Sd98841D4LZPUHQ9bmYBOEuWLFk0Y8YMDR8+XKdPn9ZLL72kr7/+Wp6enlq5cqUGDx6ss2fPOjznxh6C1FEA/gtauv+Dw4cPq1OnToqNjVWGDBm0adMmXb16VTlz5lRERISGDx+uXLly6eLFiypXrpxq1Kih999/X5kzZ9asWbPUqlUrLVy4UHXq1NHXX3+tvXv3ytPTU4sXL9a5c+c0atQoVa9e/abnty87wR8CAGlp1apVeu+999S6dWu9/PLLVki2d8k8e/asnnnmGfn5+Wn+/Pm3PR51FYD7xYULF+Tj42N9WbhkyRLt2LFDkZGRKly4cDqXDsDDiqbQ/yBXrlzKnTu39u3bp3LlymnZsmU6cuSIpk6dqg0bNuill17SiRMndO7cOcXHx6tMmTLKnDmzEhMTtWTJEiUnJ2v27NmSrk04tGrVKi1fvlyRkZGaN2+eqlevnmIc9vXfvDLWEYAzREREKHPmzNa6tK6urnJ1dbVuUoODg9W+fXt169btphMIXT8BGnUVgPuFn5+fXFxcrC8Ta9eure7duxO4ATgVS4b9RxEREYqKilLTpk1VqlQpXblyReXKldPbb7+tvn37Kjo6WuHh4SpUqJAGDhyohIQEbdiwQVeuXFGPHj2syYpq1KihWrVqpTj+jTeq3LgCcLbMmTMrNDRU69at08mTJ5U1a9YU+7Rt2/aWx2B4C4D7GUujAriXuCv6j4oWLSoXFxf99ttvkiQPDw9J17qeJyQkKCQkREFBQRo+fLgqVKigYcOG6fLly3rttdc0dOhQq2um/QY1OTmZpbwApLu6deuqc+fO8vb2vuk+jE4CAAC4PVq6/6NChQopS5Ys2rt3ryRp//79+v777/XTTz/p/fffV7Zs2SRJefLk0cSJE61QbnfjWEdahwDcDxo3bnzbfeh5AwAAcHtMpJYGXn75ZU2ZMkVeXl66cOGCSpQooeeff17PPvus/Pz8HPY1xlhLeXHDCuB+xhI5AAAA/x0t3WmgQYMGCgsLU/ny5RUZGXnLfW02G+OIADwQCNwAAAD/HS3dTmAfk01XcQAAAAB4tBG604j9ZaRlCAAAAABgR/fyNELYBgAAAADciP7PAAAAAAA4CaEbAAAAAAAnIXQDAAAAAOAkhG4AAAAAAJyE0A0AAAAAgJMQugEAAAAAcBJCNwAAAAAATkLoBgAAAADASQjdAAAAAAA4yf8BzN2/teeO3hwAAAAASUVORK5CYII="/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Generate-FLAME-graphs-using-Tensorboard">Generate FLAME graphs using Tensorboard<a class="anchor-link" href="#Generate-FLAME-graphs-using-Tensorboard"></a></h4>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Run-inference-on-CPU-to-predict-next-word">Run inference on CPU to predict next word<a class="anchor-link" href="#Run-inference-on-CPU-to-predict-next-word"></a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[32]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>

<span class="k">def</span><span class="w"> </span><span class="nf">get_next_token_suggestions</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">top_k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Returns the top_k most likely nexttoken suggestions for a given prompt.</span>

<span class="sd">    Args:</span>
<span class="sd">      model (INCModelForCausalLM or HF model): model on CPU</span>
<span class="sd">      tokenizer (AutoTokenizer): matching tokenizer</span>
<span class="sd">      prompt (str): the input text so far</span>
<span class="sd">      top_k (int): how many token suggestions to return</span>

<span class="sd">    Returns:</span>
<span class="sd">      List of (token_str, probability) tuples, sorted by descending probability.</span>
<span class="sd">    """</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="c1"># Ensure tokenizer is properly set for padding</span>
    <span class="k">if</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
    <span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">=</span> <span class="s2">"left"</span>

    <span class="c1"># Tokenize the prompt with padding</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Get model logits (no cache to avoid shape issues)</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">,</span> <span class="n">use_cache</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">logits</span>

    <span class="c1"># Logits for the last token</span>
    <span class="n">last_token_logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>

    <span class="c1"># Probabilities and top-k</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">last_token_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">top_probs</span><span class="p">,</span> <span class="n">top_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">top_k</span><span class="p">)</span>

    <span class="c1"># Convert to list of (token_string, probability)</span>
    <span class="n">suggestions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">prob</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">top_probs</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">top_indices</span><span class="o">.</span><span class="n">tolist</span><span class="p">()):</span>
        <span class="n">token_str</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">([</span><span class="n">idx</span><span class="p">])</span>
        <span class="n">suggestions</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">token_str</span><span class="p">,</span> <span class="n">prob</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">suggestions</span>


<span class="n">prompt_text</span> <span class="o">=</span> <span class="s2">"Chelsea Football Club will win the Champions League and"</span>
<span class="k">try</span><span class="p">:</span>
    <span class="c1"># Try quantized model + its tokenizer</span>
    <span class="n">suggestions</span> <span class="o">=</span> <span class="n">get_next_token_suggestions</span><span class="p">(</span>
        <span class="n">quant_model_cpu</span><span class="p">,</span>
        <span class="n">quant_tokenizer_cpu</span><span class="p">,</span>
        <span class="n">prompt_text</span><span class="p">,</span>
        <span class="n">top_k</span><span class="o">=</span><span class="mi">3</span>
    <span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Quantized model failed, falling back to FP16 model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="n">suggestions</span> <span class="o">=</span> <span class="n">get_next_token_suggestions</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">prompt_text</span><span class="p">,</span>
        <span class="n">top_k</span><span class="o">=</span><span class="mi">3</span>
    <span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Prompt: </span><span class="si">{</span><span class="n">prompt_text</span><span class="si">!r}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Next-word suggestions (token  probability):"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">token_str</span><span class="p">,</span> <span class="n">prob</span> <span class="ow">in</span> <span class="n">suggestions</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  </span><span class="si">{</span><span class="n">token_str</span><span class="si">!r}</span><span class="s2">  </span><span class="si">{</span><span class="n">prob</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Quantized model failed, falling back to FP16 model: shape '[1, 9, 768]' is invalid for input of size 5760
Prompt: 'Chelsea Football Club will win the Champions League and'

Next-word suggestions (token  probability):
  ' the'  0.3530
  ' Europa'  0.1126
  ' FA'  0.0496
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[33]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#  Alternative INT8 path: dynamic quantization that supports generation</span>
<span class="c1"># This creates a dynamic-quantized GPT-2 (PyTorch native) that works with `generate()` on CPU.</span>
<span class="c1"># It uses weight-only int8 for Linear layers; activations remain FP32.</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="n">DYN_INT8_DIR</span> <span class="o">=</span> <span class="s2">"gpt2_dynamic_int8"</span>

<span class="c1"># Load fp32 base on CPU</span>
<span class="n">base_tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>  <span class="c1"># reuse existing tokenizer</span>
<span class="n">base_model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"gpt2"</span><span class="p">)</span>
<span class="n">base_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">"cpu"</span><span class="p">)</span>
<span class="n">base_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">base_model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_cache</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># disable cache to avoid shape issues</span>

<span class="c1"># Dynamic quantization on Linear layers (weight-only int8)</span>
<span class="n">quantized_dyn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">quantize_dynamic</span><span class="p">(</span>
    <span class="n">base_model</span><span class="p">,</span>
    <span class="p">{</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">},</span>
    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">qint8</span>
<span class="p">)</span>

<span class="c1"># NOTE: quantize_dynamic returns a plain nn.Module; saving with save_pretrained hits dtype issues.</span>
<span class="c1"># We'll use the quantized model directly without saving.</span>

<span class="n">dyn_int8_model</span> <span class="o">=</span> <span class="n">quantized_dyn</span>
<span class="c1"># Ensure tokenizer has pad token</span>
<span class="k">if</span> <span class="n">base_tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">base_tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">base_tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
<span class="n">base_tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">=</span> <span class="s2">"left"</span>
<span class="n">dyn_int8_tokenizer</span> <span class="o">=</span> <span class="n">base_tokenizer</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="s2">"Chelsea Football Club will win the Champions League and"</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">dyn_int8_tokenizer</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">out_ids</span> <span class="o">=</span> <span class="n">dyn_int8_model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
        <span class="o">**</span><span class="n">inputs</span><span class="p">,</span>
        <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
        <span class="n">do_sample</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">pad_token_id</span><span class="o">=</span><span class="n">dyn_int8_tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">,</span>
        <span class="n">use_cache</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>
<span class="n">text_out</span> <span class="o">=</span> <span class="n">dyn_int8_tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">out_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">text_out</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Chelsea Football Club will win the Champions League and Citizenship Dialogue Management Awards Online Football Method Exam Next Regions Online Opportunibaba Competition Opportuniversal
</pre>
</div>
</div>
</div>
</div>
</div>
</main>
</body>
</html>
